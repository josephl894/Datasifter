{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a4fff5-d992-4807-ab9c-d21e71de35af",
   "metadata": {
    "id": "4c132caa",
    "tags": []
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3112f90c-9b25-43ee-89b6-be8e00bf3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_clean(text, control):\n",
    "    text = text.copy()\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i in range(len(text)):\n",
    "        text[i] = extract_word(text[i])\n",
    "        if control['lemmatize']:\n",
    "            for j in range(len(text[i])):\n",
    "                text[i][j] = lemmatizer.lemmatize(text[i][j])\n",
    "\n",
    "    if control['stop_words']:\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                if text[i][j] in stop_words:\n",
    "                    text[i][j] = \"\"\n",
    "\n",
    "    if control['remove_number']:\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                if text[i][j].isnumeric():\n",
    "                    text[i][j] = \"\"\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        text[i] = ' '.join(text[i])\n",
    "\n",
    "    vectorizer = CountVectorizer(max_df=0.8, min_df=3, ngram_range=(1,control['gram']))\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    return vectorizer.get_feature_names(), X.toarray()\n",
    "\n",
    "def generate_model(X, y, num_class):\n",
    "    x_train_all, x_predict, y_train_all, y_predict = train_test_split(X, y, test_size=0.10, random_state=100)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=100)\n",
    "    train_data = lgb.Dataset(data=x_train, label=y_train)\n",
    "    test_data = lgb.Dataset(data=x_test, label=y_test)\n",
    "    param = {'num_leaves': 31, 'objective': 'multiclass', 'num_class':num_class}\n",
    "    param['metric'] = 'multi_logloss'\n",
    "    num_round = 10\n",
    "    bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "    # dd = bst.trees_to_dataframe()\n",
    "    # print(dd)\n",
    "    # graph = lgb.create_tree_digraph(bst)\n",
    "    # graph.render()\n",
    "    # return [\"awd\", \"adw\"]\n",
    "    return bst\n",
    "\n",
    "def get_features(aims, df):\n",
    "    titles = df.columns.values.tolist()\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    new_aims = aims.copy()\n",
    "    curr_feature = titles[0]\n",
    "    for i in range(len(aims)):\n",
    "        aim = word_pp(aims[i])\n",
    "        doc1 = nlp(aim)\n",
    "        best_sim = 0\n",
    "        for title in titles:\n",
    "            temp_t = word_pp(title)\n",
    "            doc2 = nlp(temp_t)\n",
    "            curr_sim = doc1.similarity(doc2)\n",
    "            if curr_sim > best_sim:\n",
    "                best_sim = curr_sim\n",
    "                curr_feature = title\n",
    "        new_aims[i] = curr_feature\n",
    "    return new_aims\n",
    "\n",
    "\n",
    "def word_pp(word):\n",
    "    word = list(word)\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in string.punctuation:\n",
    "            word[i] = ' '\n",
    "    return ''.join(word)\n",
    "\n",
    "def extract_word(input_string):\n",
    "    pu = string.punctuation\n",
    "    for p in pu:\n",
    "        input_string = input_string.replace(p, ' ')\n",
    "    return input_string.lower().split()\n",
    "\n",
    "\n",
    "# TODO: percentage way\n",
    "def split_class(y, n):\n",
    "    m = np.mean(y)\n",
    "    y[y > m * 2] = m * 2\n",
    "    sd = max(y) / n\n",
    "    for i in range(len(y)):\n",
    "        for j in range(n):\n",
    "            if y[i] >= j * sd and y[i] <= (j + 1)*sd:\n",
    "                y[i] = j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c132caa",
   "metadata": {
    "id": "4c132caa",
    "tags": []
   },
   "source": [
    "# Step 1: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa29706-c161-4646-aff5-b728a3f7ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_clean(text, control):\n",
    "    text = text.copy()\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i in range(len(text)):\n",
    "        text[i] = extract_word(text[i])\n",
    "        if control['lemmatize']:\n",
    "            for j in range(len(text[i])):\n",
    "                text[i][j] = lemmatizer.lemmatize(text[i][j])\n",
    "\n",
    "    if control['stop_words']:\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                if text[i][j] in stop_words:\n",
    "                    text[i][j] = \"\"\n",
    "\n",
    "    if control['remove_number']:\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                if text[i][j].isnumeric():\n",
    "                    text[i][j] = \"\"\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        text[i] = ' '.join(text[i])\n",
    "\n",
    "    vectorizer = CountVectorizer(max_df=0.8, min_df=3, ngram_range=(1,control['gram']))\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    return vectorizer.get_feature_names(), X.toarray()\n",
    "\n",
    "def generate_model(X, y, num_class):\n",
    "    x_train_all, x_predict, y_train_all, y_predict = train_test_split(X, y, test_size=0.10, random_state=100)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=100)\n",
    "    train_data = lgb.Dataset(data=x_train, label=y_train)\n",
    "    test_data = lgb.Dataset(data=x_test, label=y_test)\n",
    "    param = {'num_leaves': 31, 'objective': 'multiclass', 'num_class':num_class}\n",
    "    param['metric'] = 'multi_logloss'\n",
    "    num_round = 10\n",
    "    bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "    # dd = bst.trees_to_dataframe()\n",
    "    # print(dd)\n",
    "    # graph = lgb.create_tree_digraph(bst)\n",
    "    # graph.render()\n",
    "    # return [\"awd\", \"adw\"]\n",
    "    return bst\n",
    "\n",
    "def get_features(aims, df):\n",
    "    titles = df.columns.values.tolist()\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    new_aims = aims.copy()\n",
    "    curr_feature = titles[0]\n",
    "    for i in range(len(aims)):\n",
    "        aim = word_pp(aims[i])\n",
    "        doc1 = nlp(aim)\n",
    "        best_sim = 0\n",
    "        for title in titles:\n",
    "            temp_t = word_pp(title)\n",
    "            doc2 = nlp(temp_t)\n",
    "            curr_sim = doc1.similarity(doc2)\n",
    "            if curr_sim > best_sim:\n",
    "                best_sim = curr_sim\n",
    "                curr_feature = title\n",
    "        new_aims[i] = curr_feature\n",
    "    return new_aims\n",
    "\n",
    "\n",
    "def word_pp(word):\n",
    "    word = list(word)\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in string.punctuation:\n",
    "            word[i] = ' '\n",
    "    return ''.join(word)\n",
    "\n",
    "def extract_word(input_string):\n",
    "    pu = string.punctuation\n",
    "    for p in pu:\n",
    "        input_string = input_string.replace(p, ' ')\n",
    "    return input_string.lower().split()\n",
    "\n",
    "\n",
    "# TODO: percentage way\n",
    "def split_class(y, n):\n",
    "    m = np.mean(y)\n",
    "    y[y > m * 2] = m * 2\n",
    "    sd = max(y) / n\n",
    "    for i in range(len(y)):\n",
    "        for j in range(n):\n",
    "            if y[i] >= j * sd and y[i] <= (j + 1)*sd:\n",
    "                y[i] = j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82afe337",
   "metadata": {
    "id": "82afe337"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b16228",
   "metadata": {
    "id": "36b16228"
   },
   "outputs": [],
   "source": [
    "#pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ZUVH369kiZDZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUVH369kiZDZ",
    "outputId": "af506d13-133e-4d39-a6ec-1ff921f76fc7"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "#from google.colab import drive\n",
    "#import os\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "#os.chdir('/content/drive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bskaOFzNlsSd",
   "metadata": {
    "id": "bskaOFzNlsSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "veVmkzVPlsbT",
   "metadata": {
    "id": "veVmkzVPlsbT"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "-A5xjAUplc-x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-A5xjAUplc-x",
    "outputId": "956e6fc9-225e-4594-ce16-f7418909fff7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joseph/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f9aa90",
   "metadata": {
    "id": "37f9aa90"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "import re\n",
    "#!pip install sdv gensim unidecode contractions\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3332d8b3-43b9-48cd-ace8-82774bdce4b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d72fe3e",
    "outputId": "0ff3382e-21ff-403c-ac20-bc27348708c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joseph/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joseph/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/joseph/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/joseph/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')# for the tokenize test\n",
    "nltk.download('stopwords')# stopwords dict\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') #Open Multilingual WordNet version 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b43617",
   "metadata": {
    "id": "76b43617"
   },
   "outputs": [],
   "source": [
    "#path = \"/content/drive/My Drive/mimic3.csv\"\n",
    "raw = pd.read_csv('data/mimi3.csv')['TEXT']\n",
    "raw_df = raw.copy() #just dealing with the TEXT column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48aa5ddd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48aa5ddd",
    "outputId": "d9b1051a-23a9-4f21-ce1a-7c3e0a3973b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18517 entries, 0 to 18516\n",
      "Series name: TEXT\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "18517 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 144.8+ KB\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() #word lemmatizer\n",
    "proterstemmer = PorterStemmer() # word stemmer\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de1a2b",
   "metadata": {
    "id": "e5de1a2b"
   },
   "source": [
    "check for null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf315c1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf315c1f",
    "outputId": "ef9cf46c-fa87-4291-e486-d3391764bc0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e53446a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e53446a",
    "outputId": "cc4b073e-4c3c-4ee8-bf17-8ae6fea8276d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)  ...\n",
       "1    [**2157-10-21**] 3:31 PM\\n CT HEAD W/O CONTRAS...\n",
       "2    4:30p-7a\\nneuro: pt remained sedated on fent/v...\n",
       "3    [**2131-5-24**] 9:45 AM\\n PICC LINE PLACMENT S...\n",
       "4    Respiratory Care\\nPt intubated on ventilatory ...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23df427",
   "metadata": {
    "id": "e23df427"
   },
   "outputs": [],
   "source": [
    "# replace the non-character with \" \"\n",
    "raw_df = raw_df.apply(lambda x:\n",
    "             \" \".join(re.sub(r'[^a-zA-Z]', \" \", w).lower() for w in x.split()\n",
    "             if re.sub(r'^a-zA-Z', ' ', w).lower() not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e98405",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "f3e98405",
    "outputId": "a03890c0-f71b-4145-d349-d978b4edf955"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest tubes removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest tubes removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the right IJ\\n sheath remains in place.  Both left chest tubes have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ff84113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "5ff84113",
    "outputId": "09365743-3d49-4d5c-a05d-be9d7167b7fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                    chest  portable ap  clip      clip number  radiology           reason  assess lung expansion admitting diagnosis  coronary artery disease coronary artery bypass graft sda                                                                                   hospital      medical condition     year old man s p cabg w chest tubes removed reason examination  assess lung expansion                                                                                final report indications  chest tubes removed  portable ap chest       comparisons made                 patient extubated  swan ganz catheter removed right ij sheath remains place  left chest tubes removed  pneumothorax  bilateral lower lobe atelectasis  improvement pulmonary edema '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dccefb1",
   "metadata": {
    "id": "6dccefb1"
   },
   "outputs": [],
   "source": [
    "# deal with contraction\n",
    "def decontracted(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def expand_contractions(phrase):\n",
    "    \"\"\"use contractions package to do decontraction\"\"\"\n",
    "    phrase = contractions.fix(phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "# print(expand_contractions('won\\'t')) -> will not\n",
    "# print(decontracted('won\\'t')) -> will not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0c602",
   "metadata": {
    "id": "85b0c602"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ab5d3c",
   "metadata": {
    "id": "f2ab5d3c"
   },
   "outputs": [],
   "source": [
    "def preprocessing(notes):\n",
    "    \"\"\"\n",
    "    preprocess notes including lemmatization, decontraction, stemming, lowercase,\n",
    "    return notes(preprocessed notes), tokenized_notes(list)\n",
    "    \"\"\"\n",
    "    tokenized_notes = []\n",
    "    for i, text in enumerate(notes):\n",
    "        notes[i] = decontracted(text) # here we use the decontracted function\n",
    "        text_word_list = word_tokenize(text)\n",
    "\n",
    "        # expand contraction\n",
    "        text_word_list = [expand_contractions(word) for word in text_word_list]\n",
    "        # lemmatization\n",
    "        text_word_list = [lemmatizer.lemmatize(word) for word in text_word_list]\n",
    "        # stemming\n",
    "        text_word_list = [proterstemmer.stem(word) for word in text_word_list]\n",
    "        # to lower\n",
    "        text_word_list = [word.lower() for word in text_word_list]\n",
    "\n",
    "        tokenized_notes.append(text_word_list)\n",
    "        notes[i] = \" \".join(text_word_list)\n",
    "    return notes, tokenized_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc66895",
   "metadata": {
    "id": "dcc66895"
   },
   "outputs": [],
   "source": [
    "notes_list, tokenized_notes = preprocessing(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "998cdd84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "998cdd84",
    "outputId": "bef170f8-118e-4f4d-c3a8-c28a1b33fcd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18517 notes\n"
     ]
    }
   ],
   "source": [
    "print(len(notes_list), \"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76175ea8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "76175ea8",
    "outputId": "a6cb84f8-1151-489d-cdab-a92e40e71dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chest portabl ap clip clip number radiolog reason ass lung expans admit diagnosi coronari arteri diseas coronari arteri bypass graft sda hospit medic condit year old man s p cabg w chest tube remov reason examin ass lung expans final report indic chest tube remov portabl ap chest comparison made patient extub swan ganz cathet remov right ij sheath remain place left chest tube remov pneumothorax bilater lower lobe atelectasi improv pulmonari edema'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7dd91",
   "metadata": {
    "id": "89b7dd91"
   },
   "source": [
    "# Step 2: sensitive factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2b5fb4",
   "metadata": {
    "id": "6d2b5fb4"
   },
   "outputs": [],
   "source": [
    "outcomes = ['length_of_stay_avg', 'Religion', 'Gender'] # selected these three predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee33e5",
   "metadata": {
    "id": "e8ee33e5"
   },
   "source": [
    "# Step3: Identify sensitive outcome(s) to protect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "WYsV8rLq8LsY",
   "metadata": {
    "id": "WYsV8rLq8LsY"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/joseph/Desktop/Datasifter') #to use the function that we made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57dbcf26",
   "metadata": {
    "id": "57dbcf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from lightgbm) (1.26.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from lightgbm) (1.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "049ecd79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "049ecd79",
    "outputId": "42ac50a2-1e33-421d-db6f-02c5d37f50f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./venv/lib/python3.11/site-packages (from en-core-web-lg==3.7.0) (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (57.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.24.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in ./venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg # had a problem with jupyter, but I used virtual env. so if you are not using vitual env, you may try in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26a69fc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a69fc6",
    "outputId": "1c3fd57f-c3cf-4460-bdf2-8f0ccada6b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18517 entries, 0 to 18516\n",
      "Data columns (total 33 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   SUBJECT_ID                   18517 non-null  int64  \n",
      " 1   length_of_stay_avg           18517 non-null  float64\n",
      " 2   Platelet.Count               18517 non-null  float64\n",
      " 3   Prothrombin.time             18517 non-null  float64\n",
      " 4   WBC                          18517 non-null  float64\n",
      " 5   Hemoglobin                   18517 non-null  float64\n",
      " 6   PTT                          18517 non-null  float64\n",
      " 7   GCS...Verbal.Response        18517 non-null  int64  \n",
      " 8   Language                     18517 non-null  int64  \n",
      " 9   GCS...Motor.Response         18517 non-null  int64  \n",
      " 10  GCS...Eye.Opening            18517 non-null  int64  \n",
      " 11  INR                          18517 non-null  float64\n",
      " 12  Religion                     18517 non-null  int64  \n",
      " 13  Patient.Location             18517 non-null  int64  \n",
      " 14  Race                         18517 non-null  int64  \n",
      " 15  Glucose..serum.              18517 non-null  float64\n",
      " 16  Gender                       18517 non-null  int64  \n",
      " 17  Hematocrit..serum.           18517 non-null  float64\n",
      " 18  Calcium.non.ionized          18517 non-null  float64\n",
      " 19  Phosphorous                  18517 non-null  float64\n",
      " 20  BUN                          18517 non-null  float64\n",
      " 21  O2.saturation.pulseoxymetry  18517 non-null  float64\n",
      " 22  Admission.Weight..Kg.        18517 non-null  float64\n",
      " 23  Heart.Rate                   18517 non-null  float64\n",
      " 24  HCO3..serum.                 18517 non-null  float64\n",
      " 25  Anion.gap                    18517 non-null  float64\n",
      " 26  Potassium..serum.            18517 non-null  float64\n",
      " 27  Chloride..serum.             18517 non-null  float64\n",
      " 28  Sodium..serum.               18517 non-null  float64\n",
      " 29  Creatinine                   18517 non-null  float64\n",
      " 30  Magnesium                    18517 non-null  float64\n",
      " 31  Respiratory.Rate             18517 non-null  float64\n",
      " 32  TEXT                         18517 non-null  int64  \n",
      "dtypes: float64(23), int64(10)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "consider_text = True # consider text OR features\n",
    "num_keywords = 10 # num keywords generated\n",
    "drop_list = [0, 2, 4, 5, 6] # useless df features\n",
    "num_class = 5 # for continuous outcomes\n",
    "control = {'remove_number': True, 'lemmatize': True, 'normalize': True, 'stop_words': True, 'gram': 1, 'remove_name': True}\n",
    "# read data frame\n",
    "df = pd.read_csv('data/mimi3.csv')\n",
    "df = df.drop(df.columns[drop_list], axis=1)\n",
    "# get all categorical columns\n",
    "cat_columns = df.select_dtypes(['object']).columns\n",
    "# convert all categorical columns to numeric\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1535704",
   "metadata": {
    "id": "f1535704"
   },
   "outputs": [],
   "source": [
    "# change text to preprocessed text\n",
    "df['TEXT'] = notes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35e2ff99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "35e2ff99",
    "outputId": "8a4f4d4f-7463-4120-dda1-7a32cd6872be",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: import\n",
      "Collecting en-core-web-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from en-core-web-lg==3.7.0) (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.1.3)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# detect outcome column\n",
    "\n",
    "import functions\n",
    "#import en_core_web_sm\n",
    "\n",
    "#nlp = en_core_web_sm.load()\n",
    "import spacy.cli\n",
    "\n",
    "spacy.cli.download(\"en_core_web_lg\")\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "outcomes = functions.get_features(outcomes, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9599e95d",
   "metadata": {
    "id": "9599e95d"
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge spacy-model-en_core_web_lg--y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0a1c453",
   "metadata": {
    "id": "d0a1c453"
   },
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d5a54e",
   "metadata": {
    "id": "90d5a54e"
   },
   "outputs": [],
   "source": [
    "#pip install en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8adf31cd",
   "metadata": {
    "id": "8adf31cd"
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg\n",
    "#!/Users/suhyunjung/.pyenv/versions/3.9.16/lib/python3.9 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72562d6",
   "metadata": {
    "id": "c72562d6"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.examples import sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c077732",
   "metadata": {
    "id": "2c077732"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bace448",
   "metadata": {
    "id": "0bace448"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73467c",
   "metadata": {
    "id": "9e73467c"
   },
   "source": [
    "### Implementing lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06ada7d2",
   "metadata": {
    "id": "06ada7d2"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cf83fd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cf83fd4",
    "outputId": "782eeca6-5d71-4663-f892-688e588d6a29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.13229167,  6.13229167, 10.36388889, ..., 17.75      ,\n",
       "        7.67291667,  7.67291667])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df[outcomes[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb3d44b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fb3d44b6",
    "outputId": "6f952985-2471-4aab-824d-373b674a7361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 12591, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.831300\n",
      "[LightGBM] [Info] Start training from score -6.396215\n",
      "[LightGBM] [Info] Start training from score -4.866027\n",
      "[LightGBM] [Info] Start training from score -4.051666\n",
      "[LightGBM] [Info] Start training from score -3.802383\n",
      "[LightGBM] [Info] Start training from score -3.356238\n",
      "[LightGBM] [Info] Start training from score -3.500566\n",
      "[LightGBM] [Info] Start training from score -3.398105\n",
      "[LightGBM] [Info] Start training from score -3.370000\n",
      "[LightGBM] [Info] Start training from score -3.256589\n",
      "[LightGBM] [Info] Start training from score -3.281642\n",
      "[LightGBM] [Info] Start training from score -3.309511\n",
      "[LightGBM] [Info] Start training from score -3.232148\n",
      "[LightGBM] [Info] Start training from score -3.372312\n",
      "[LightGBM] [Info] Start training from score -3.383954\n",
      "[LightGBM] [Info] Start training from score -3.427022\n",
      "[LightGBM] [Info] Start training from score -3.527235\n",
      "[LightGBM] [Info] Start training from score -3.591413\n",
      "[LightGBM] [Info] Start training from score -3.543584\n",
      "[LightGBM] [Info] Start training from score -3.527235\n",
      "[LightGBM] [Info] Start training from score -3.733627\n",
      "[LightGBM] [Info] Start training from score -3.849751\n",
      "[LightGBM] [Info] Start training from score -3.446776\n",
      "[LightGBM] [Info] Start training from score -3.927309\n",
      "[LightGBM] [Info] Start training from score -3.923285\n",
      "[LightGBM] [Info] Start training from score -4.084151\n",
      "[LightGBM] [Info] Start training from score -4.074762\n",
      "[LightGBM] [Info] Start training from score -3.947676\n",
      "[LightGBM] [Info] Start training from score -3.981152\n",
      "[LightGBM] [Info] Start training from score -4.316774\n",
      "[LightGBM] [Info] Start training from score -4.334792\n",
      "[LightGBM] [Info] Start training from score -4.722239\n",
      "[LightGBM] [Info] Start training from score -4.198991\n",
      "[LightGBM] [Info] Start training from score -4.253352\n",
      "[LightGBM] [Info] Start training from score -4.074762\n",
      "[LightGBM] [Info] Start training from score -5.150278\n",
      "[LightGBM] [Info] Start training from score -4.815765\n",
      "[LightGBM] [Info] Start training from score -4.322744\n",
      "[LightGBM] [Info] Start training from score -4.777298\n",
      "[LightGBM] [Info] Start training from score -5.071290\n",
      "[LightGBM] [Info] Start training from score -4.687147\n",
      "[LightGBM] [Info] Start training from score -4.304939\n",
      "[LightGBM] [Info] Start training from score -5.397686\n",
      "[LightGBM] [Info] Start training from score -5.885389\n",
      "[LightGBM] [Info] Start training from score -5.178058\n",
      "[LightGBM] [Info] Start training from score -4.998086\n",
      "[LightGBM] [Info] Start training from score -5.329864\n",
      "[LightGBM] [Info] Start training from score -5.415386\n",
      "[LightGBM] [Info] Start training from score -5.266350\n",
      "[LightGBM] [Info] Start training from score -5.548917\n",
      "[LightGBM] [Info] Start training from score -4.876389\n",
      "[LightGBM] [Info] Start training from score -5.150278\n",
      "[LightGBM] [Info] Start training from score -6.182641\n",
      "[LightGBM] [Info] Start training from score -5.803151\n",
      "[LightGBM] [Info] Start training from score -6.349695\n",
      "[LightGBM] [Info] Start training from score -5.829820\n",
      "[LightGBM] [Info] Start training from score -6.550366\n",
      "[LightGBM] [Info] Start training from score -6.396215\n",
      "[LightGBM] [Info] Start training from score -5.777176\n",
      "[LightGBM] [Info] Start training from score -5.914377\n",
      "[LightGBM] [Info] Start training from score -7.138152\n",
      "[LightGBM] [Info] Start training from score -6.668149\n",
      "[LightGBM] [Info] Start training from score -7.138152\n",
      "[LightGBM] [Info] Start training from score -6.349695\n",
      "[LightGBM] [Info] Start training from score -5.975002\n",
      "[LightGBM] [Info] Start training from score -7.243513\n",
      "[LightGBM] [Info] Start training from score -7.831300\n",
      "[LightGBM] [Info] Start training from score -6.955831\n",
      "[LightGBM] [Info] Start training from score -7.648978\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -6.607524\n",
      "[LightGBM] [Info] Start training from score -6.607524\n",
      "[LightGBM] [Info] Start training from score -6.496299\n",
      "[LightGBM] [Info] Start training from score -8.054443\n",
      "[LightGBM] [Info] Start training from score -6.262684\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -8.342125\n",
      "[LightGBM] [Info] Start training from score -6.396215\n",
      "[LightGBM] [Info] Start training from score -8.054443\n",
      "[LightGBM] [Info] Start training from score -5.914377\n",
      "[LightGBM] [Info] Start training from score -7.243513\n",
      "[LightGBM] [Info] Start training from score -6.668149\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.138152\n",
      "[LightGBM] [Info] Start training from score -6.349695\n",
      "[LightGBM] [Info] Start training from score -8.342125\n",
      "[LightGBM] [Info] Start training from score -7.361296\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -6.496299\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -6.445005\n",
      "[LightGBM] [Info] Start training from score -7.831300\n",
      "[LightGBM] [Info] Start training from score -7.648978\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -5.885389\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.648978\n",
      "[LightGBM] [Info] Start training from score -7.042842\n",
      "[LightGBM] [Info] Start training from score -7.042842\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -8.342125\n",
      "[LightGBM] [Info] Start training from score -6.445005\n",
      "[LightGBM] [Info] Start training from score -8.342125\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.831300\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -9.440738\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.648978\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -6.396215\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.831300\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -8.054443\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.361296\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -6.221862\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.494827\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -8.747590\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -7.494827\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -8.054443\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 12591, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.681069\n",
      "[LightGBM] [Info] Start training from score -1.624321\n",
      "[LightGBM] [Info] Start training from score -2.213802\n",
      "[LightGBM] [Info] Start training from score -2.605553\n",
      "[LightGBM] [Info] Start training from score -3.644680\n",
      "[LightGBM] [Info] Start training from score -3.006191\n",
      "[LightGBM] [Info] Start training from score -5.136672\n",
      "[LightGBM] [Info] Start training from score -4.565540\n",
      "[LightGBM] [Info] Start training from score -7.648978\n",
      "[LightGBM] [Info] Start training from score -5.178058\n",
      "[LightGBM] [Info] Start training from score -8.342125\n",
      "[LightGBM] [Info] Start training from score -6.607524\n",
      "[LightGBM] [Info] Start training from score -5.885389\n",
      "[LightGBM] [Info] Start training from score -6.144901\n",
      "[LightGBM] [Info] Start training from score -4.940928\n",
      "[LightGBM] [Info] Start training from score -6.182641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 12591, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.344350\n",
      "[LightGBM] [Info] Start training from score -1.233336\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords = {} # to get a feture importance result (final result from LightGBM)\n",
    "for outcome in outcomes:\n",
    "    y = np.array(df[outcome])\n",
    "    num_class = len(np.unique(y))\n",
    "    X = np.array(df['TEXT'])\n",
    "    #vectorizer = CountVectorizer(max_df=0.8, min_df=3, ngram_range=(1,control['gram']))\n",
    "    vectorizer = CountVectorizer(min_df=0.2, ngram_range=(1,1)) # unigrams\n",
    "    X = vectorizer.fit_transform(notes_list).toarray() #This converts the text data into a matrix that machine learning algorithms can work with.\n",
    "    name= vectorizer.get_feature_names_out() # if your sklear version is diff use 'vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "    x_train_all, x_predict, y_train_all, y_predict = train_test_split(X, y, test_size=0.15, random_state=100)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=100)\n",
    "    train_data = lgb.Dataset(data=x_train, label=y_train)\n",
    "    test_data = lgb.Dataset(data=x_test, label=y_test)\n",
    "    param = {'num_leaves': 31, 'objective': 'multiclass', 'num_class':num_class}\n",
    "    param['metric'] = 'multi_logloss'\n",
    "    num_round = 10\n",
    "    evals = {}\n",
    "    model = lgb.train(param, train_data, num_round, valid_sets=[test_data], callbacks= [lgb.record_evaluation(evals)])\n",
    "    # dd = bst.trees_to_dataframe()\n",
    "    #     if consider_text:\n",
    "    #         name, X = text_clean(np.array(df['TEXT']), control)\n",
    "    #         print(X.shape)\n",
    "    #         break\n",
    "    #         if control['normalize']:\n",
    "    #             X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    #     else:\n",
    "    #         temp_df = df.drop(['TEXT'], axis=1)\n",
    "    #         X = np.array(temp_df.drop(outcome, axis=1))\n",
    "    #         name= np.array(temp_df.columns)\n",
    "\n",
    "    # model = generate_model(X, y, num_class)\n",
    "    feature_imp = pd.DataFrame({\"value\": model.feature_importance(), 'Feature': vectorizer.get_feature_names_out()})\n",
    "    keywords[outcome] = pd.DataFrame(feature_imp.sort_values(by=feature_imp.columns[0], ascending=False)[0:num_keywords])\n",
    "    lgb.plot_metric(evals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "043269bc",
   "metadata": {
    "id": "043269bc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('keywords.pkl', 'wb') as f:\n",
    "    pickle.dump(keywords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b4a778a",
   "metadata": {
    "id": "9b4a778a"
   },
   "outputs": [],
   "source": [
    "#with open('keywords.pkl', 'rb') as f:\n",
    "#    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2482d29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2482d29",
    "outputId": "60313a6d-d1cf-4520-f45f-b7130e831fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length_of_stay_avg', 'Religion', 'Gender']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81adc8de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "81adc8de",
    "outputId": "4f8715bf-ae0e-462d-a26f-f9b36c881719"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>36</td>\n",
       "      <td>tube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>assess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>30</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>histori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>continu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>18</td>\n",
       "      <td>remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>18</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18</td>\n",
       "      <td>impress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value  Feature\n",
       "69     36     tube\n",
       "4      36   assess\n",
       "71     30     year\n",
       "27     24  histori\n",
       "40     20       mg\n",
       "38     20      man\n",
       "14     18  continu\n",
       "60     18   remain\n",
       "59     18   reason\n",
       "30     18  impress"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words significantly predicts sensitive factor: Religion\n",
    "# before preprocessing\n",
    "keywords[outcomes[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39fa1391",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "39fa1391",
    "outputId": "2087883d-507f-4e44-8345-091dddd5bf02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>36</td>\n",
       "      <td>tube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>assess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>30</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>histori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>continu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>18</td>\n",
       "      <td>remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>18</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18</td>\n",
       "      <td>impress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value  Feature\n",
       "69     36     tube\n",
       "4      36   assess\n",
       "71     30     year\n",
       "27     24  histori\n",
       "40     20       mg\n",
       "38     20      man\n",
       "14     18  continu\n",
       "60     18   remain\n",
       "59     18   reason\n",
       "30     18  impress"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after preprocessing\n",
    "keywords[outcomes[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d1826",
   "metadata": {
    "id": "d70d1826"
   },
   "source": [
    "# Step 4: semantic radius, using word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89189c43",
   "metadata": {
    "id": "89189c43"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c536ac9c",
   "metadata": {
    "id": "c536ac9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/63/46/5feab9c524a380bfa9f9f1c0d065743280dca30b216ab4c7a231f22dbed7/gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/homebrew/lib/python3.11/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from gensim) (6.4.0)\n",
      "Using cached gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "from pyparsing import WordStart\n",
    "\n",
    "class MySentences(object): #It splits each sentence into words and yields them as separate tokens. The class also implements methods for length retrieval and item retrieval, which allows treating an instance of this class as a list-like object.\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in self.text:\n",
    "            yield line.split()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.text[i]\n",
    "\n",
    "    def __setitem__(self, index, item1):\n",
    "        self.text[index] = item1\n",
    "\n",
    "class W2V(object):\n",
    "    def __init__(self, sentences, cores, vec_size) -> None:\n",
    "        self.sentences = sentences\n",
    "        self.model = Word2Vec(min_count=10,\n",
    "                     window=10,\n",
    "                     vector_size=vec_size,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.build_vocab(self.sentences)\n",
    "        self.model.train(self.sentences, total_examples=self.model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "    def get_similar_word(self, keywords=[\"wife\"], start_radius=0, end_radius=100): # Returns a random similar word for each keyword within the specified radius range. It queries the model for the most similar words to each keyword.\n",
    "        word_list = [self.model.wv.most_similar(keywords[i], topn=end_radius)[start_radius:] for i in range(len(keywords))]\n",
    "        return [random.choice(words)[0] for words in word_list]\n",
    "\n",
    "    def get_similar_word_2(self, keywords=[\"wife\"], start_radius=0, end_radius=100): # it returns a list of lists of similar words for each keyword. It doesn't choose a random word from each list.\n",
    "        #print(len(keywords))\n",
    "        #print(self.model.wv.most_similar(keywords[i], topn=end_radius))\n",
    "        word_list = [self.model.wv.most_similar(keywords[i], topn=end_radius)[start_radius:] for i in range(len(keywords))]\n",
    "        return word_list\n",
    "\n",
    "\n",
    "    def get_similar_word_list(self, keywords, start_radius = 0, end_radius = 100):\n",
    "        if isinstance(keywords, list):\n",
    "            TypeError(\"keywords should be a list\")\n",
    "        else:\n",
    "            keywords = [keywords]\n",
    "            for keyword in keywords:\n",
    "                word_list = self.model.wv.most_similar(keyword, topn = end_radius)\n",
    "        return word_list\n",
    "\n",
    "\n",
    "    def save(self, route): #Saves the trained Word2Vec model\n",
    "        self.model.save(route)\n",
    "\n",
    "    def load(self, route): #loads the trained Word2Vec model\n",
    "        self.model = Word2Vec.load(route)\n",
    "\n",
    "    def find_word_idx(self, keywords=[\"wife\"]): #Finds the indices of sentences containing each keyword in the provided list of keywords.\n",
    "        return [[i for i in range(len(self.sentences)) if keywords[j] in self.sentences[i]] for j in range(len(keywords))]\n",
    "\n",
    "    def obfuscate(self, sentence, keywords=[\"wife\"]): #Replaces keywords in a sentence with similar words obtained from the model.\n",
    "        word_list = self.get_similar_word(keywords=keywords)\n",
    "        for i in range(len(keywords)):\n",
    "            sentence = sentence.replace(keywords[i], word_list[i])\n",
    "        return sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41161542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41161542",
    "outputId": "3fe9249b-ac9b-4ded-cf07-f1e6b9e41505"
   },
   "outputs": [],
   "source": [
    "sentences = MySentences(df.TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64aa2378",
   "metadata": {
    "id": "64aa2378"
   },
   "outputs": [],
   "source": [
    "w2v_model = W2V(sentences, 1, 300) # sentences , core, vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48910ee4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48910ee4",
    "outputId": "d19060e6-8412-49b3-e6af-8e604b3012a8"
   },
   "outputs": [],
   "source": [
    "w2v_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e60b56d",
   "metadata": {
    "id": "3e60b56d"
   },
   "outputs": [],
   "source": [
    "w2v_model.save(\"w2vmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ad8aab1",
   "metadata": {
    "id": "1ad8aab1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6327e121",
   "metadata": {
    "id": "6327e121"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('keywords.pkl', 'rb') as f:\n",
    "    keywords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99b4e3",
   "metadata": {
    "id": "5f99b4e3"
   },
   "source": [
    "---\n",
    "Now we want to find the maximum distance to determine the semantic radius, here we first find the statistics summary for each keywords in terms of one sensitive outcome\n",
    "\n",
    "E.g:\n",
    "\n",
    "when the most predictive words for the Religion is \"assessment\", then the most similiar words ranking list of assessment is stored in the \"similar_assessment\", we find the first 100 words and find the mean, median, 25%IQ .etc statistics summary, then cancanate them to the keywords for each sensitive outcome\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2cce99f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2cce99f",
    "outputId": "69668ff7-fc87-441f-d978-5f109ea14174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length_of_stay_avg', 'Religion', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60311eeb",
   "metadata": {
    "id": "60311eeb"
   },
   "outputs": [],
   "source": [
    "#store the first 10 most predictive words for each sensitive outcomes\n",
    "\n",
    "# length_of_stay_avg\n",
    "LOSA_keywords = keywords[outcomes[0]]\n",
    "# Gender\n",
    "Gender_keywords = keywords[outcomes[1]]\n",
    "# Religion\n",
    "Religion_keywords = keywords[outcomes[2]]\n",
    "\n",
    "LOSA_list = list(LOSA_keywords.Feature)\n",
    "Gender_list = list(Gender_keywords.Feature)\n",
    "Religion_list = list(Religion_keywords.Feature)\n",
    "# LOS_list = list(LOS_keywords.Feature)\n",
    "# LOS_list.pop(3)\n",
    "\n",
    "# Gender_list = list(Gender_keywords.Feature)\n",
    "# Gender_list.pop(-2)\n",
    "\n",
    "# Religion_list = list(Religion_keywords.Feature)\n",
    "# Religion_list.pop(6)\n",
    "# Religion_list.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b967546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b967546",
    "outputId": "946d05f1-67ff-4ed2-9aa8-763716f2041c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tube',\n",
       " 'assess',\n",
       " 'year',\n",
       " 'histori',\n",
       " 'mg',\n",
       " 'man',\n",
       " 'continu',\n",
       " 'remain',\n",
       " 'reason',\n",
       " 'impress']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict = {}\n",
    "keywords_dict.setdefault(outcomes[0], LOSA_list)\n",
    "keywords_dict.setdefault(outcomes[1], Gender_list)\n",
    "keywords_dict.setdefault(outcomes[2], Religion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fb4482d",
   "metadata": {
    "id": "3fb4482d"
   },
   "outputs": [],
   "source": [
    "def find_3levels_word(keyword_list, small = 33, mid = 66):\n",
    "    \"\"\"\"keywords is a list of predictive words of a certain outcome,\n",
    "    small is the percentile criteria for small level of obfuscation,\n",
    "    mid is the percentile criteria for mid level of obfuscation,\n",
    "\n",
    "    return are 3 word list: each derived by random sampling from the corresponding obfuscation level\"\"\"\n",
    "\n",
    "    small_level_list = []\n",
    "    mid_level_list = []\n",
    "    large_level_list = []\n",
    "    for word in keyword_list:\n",
    "        try:\n",
    "            similar_words = sorted(w2v_model.get_similar_word_list(keywords = word, end_radius = 100), key = lambda x: x[1], reverse = True)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            word_list, cos_list = list(zip(*similar_words)) #instead of spliting by the number use cdf // make it visible with some metrics //change the number of keywords 10 -> bigger\n",
    "            small_range = word_list[:small]# begin ~ small\n",
    "            mid_range = word_list[small:mid] #small ~ mid\n",
    "            large_range = word_list[mid:] # mid ~ end\n",
    "            small_level_list.append(random.sample(small_range,1)[0])\n",
    "            mid_level_list.append(random.sample(mid_range,1)[0])\n",
    "            large_level_list.append(random.sample(large_range,1)[0])\n",
    "\n",
    "    return small_level_list, mid_level_list, large_level_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c7b09dc",
   "metadata": {
    "id": "9c7b09dc"
   },
   "outputs": [],
   "source": [
    "def get_replace_word(keywords, level, small = 33, mid = 66):\n",
    "    if isinstance(level, str):\n",
    "        small, mid, large = find_3levels_word(keywords, small, mid)\n",
    "        level = level.lower()\n",
    "        if level == \"small\":\n",
    "            return small\n",
    "        elif level == \"mid\":\n",
    "            return mid\n",
    "        elif level == \"large\":\n",
    "            return large\n",
    "    else: NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "YaJOhJdL32F2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaJOhJdL32F2",
    "outputId": "a4142c1f-8a51-44fe-de1c-1badefe07f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tube',\n",
       " 'assess',\n",
       " 'year',\n",
       " 'histori',\n",
       " 'mg',\n",
       " 'man',\n",
       " 'continu',\n",
       " 'remain',\n",
       " 'reason',\n",
       " 'impress']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict['Gender'] #this is original 10 keywords from Gender that we are going to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "631c5a6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "631c5a6c",
    "outputId": "2297a361-1512-4275-c42d-8efe27abfb10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guiaic',\n",
       " 'vpace',\n",
       " 'met',\n",
       " 'shaft',\n",
       " 'orif',\n",
       " 'radio',\n",
       " 'dysynchron',\n",
       " 'coag',\n",
       " 'secreat',\n",
       " 'appendag']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_replace_word(keywords_dict['Gender'], 'small') # obfuscation with small_list words for Gender 10keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab51bb46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab51bb46",
    "outputId": "0fe33899-db63-4598-9cab-cf29ccff0d47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length_of_stay_avg', 'Religion', 'Gender']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b5ca9e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b5ca9e2",
    "outputId": "1f5c22af-2e68-4b6b-9767-add9623cd75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      " ['autolog', 'ect', 'lurt', 'both', 'avl', 'complain', 'bb', 'atr', 'calm', 'elev'] \n",
      "\n",
      " 10 \n",
      " ['fsb', 'cadaver', 'ceftaz', 'labetolol', 'urin', 'lobar', 'pot', 'lg', 'enterococcu', 'sacroiliac'] \n",
      "\n",
      " 10 \n",
      " ['sustain', 'pacu', 'abrupt', 'tremor', 'bore', 'some', 'vasopressor', 'caus', 'np', 'case']\n"
     ]
    }
   ],
   "source": [
    "print(len(get_replace_word(keywords_dict['Gender'], \"small\")), \"\\n\",\n",
    "      get_replace_word(keywords_dict['Gender'], \"small\"), \"\\n\\n\",\n",
    "     len(get_replace_word(keywords_dict['Gender'], \"mid\")), \"\\n\",\n",
    "      get_replace_word(keywords_dict['Gender'], \"mid\"), \"\\n\\n\",\n",
    "     len(get_replace_word(keywords_dict['Gender'], \"large\")), \"\\n\",\n",
    "      get_replace_word(keywords_dict['Gender'], \"large\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14f03f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "14f03f01",
    "outputId": "d0d06eae-17cd-4f6f-f58d-1c08e33a1091"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>small_level</th>\n",
       "      <th>mid_level</th>\n",
       "      <th>large_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>stabli</td>\n",
       "      <td>gate</td>\n",
       "      <td>unabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pt</td>\n",
       "      <td>wardnam</td>\n",
       "      <td>ing</td>\n",
       "      <td>exert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chang</td>\n",
       "      <td>flatten</td>\n",
       "      <td>reflect</td>\n",
       "      <td>cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effus</td>\n",
       "      <td>precaut</td>\n",
       "      <td>cathet</td>\n",
       "      <td>everyth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>glargin</td>\n",
       "      <td>laminectomi</td>\n",
       "      <td>grew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tube</td>\n",
       "      <td>nodular</td>\n",
       "      <td>sheath</td>\n",
       "      <td>goiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>right</td>\n",
       "      <td>copiu</td>\n",
       "      <td>mm</td>\n",
       "      <td>serosangin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pain</td>\n",
       "      <td>alkalot</td>\n",
       "      <td>valv</td>\n",
       "      <td>cardiomyopathi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hr</td>\n",
       "      <td>mvi</td>\n",
       "      <td>tuberculosi</td>\n",
       "      <td>sling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pm</td>\n",
       "      <td>aneursym</td>\n",
       "      <td>uffp</td>\n",
       "      <td>dk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords small_level    mid_level     large_level\n",
       "0     name      stabli         gate           unabl\n",
       "1       pt     wardnam          ing           exert\n",
       "2    chang     flatten      reflect            cyst\n",
       "3    effus     precaut       cathet         everyth\n",
       "4     left     glargin  laminectomi            grew\n",
       "5     tube     nodular       sheath          goiter\n",
       "6    right       copiu           mm      serosangin\n",
       "7     pain     alkalot         valv  cardiomyopathi\n",
       "8       hr         mvi  tuberculosi           sling\n",
       "9       pm    aneursym         uffp              dk"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'keywords':keywords_dict['Religion'],\n",
    "             'small_level':get_replace_word(keywords_dict['Religion'], \"small\"),\n",
    "             'mid_level':get_replace_word(keywords_dict['Religion'], \"mid\"),\n",
    "             'large_level':get_replace_word(keywords_dict['Religion'], \"large\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa7954ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "fa7954ff",
    "outputId": "868c840b-c786-4566-cfce-d99d0100fbcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>small_level</th>\n",
       "      <th>mid_level</th>\n",
       "      <th>large_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tube</td>\n",
       "      <td>osa</td>\n",
       "      <td>disku</td>\n",
       "      <td>lpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assess</td>\n",
       "      <td>averag</td>\n",
       "      <td>mucomyst</td>\n",
       "      <td>ucx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>colonoscopi</td>\n",
       "      <td>name</td>\n",
       "      <td>cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>histori</td>\n",
       "      <td>opioid</td>\n",
       "      <td>follw</td>\n",
       "      <td>inconsist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mg</td>\n",
       "      <td>process</td>\n",
       "      <td>with</td>\n",
       "      <td>pancytopenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>coffe</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>insuffici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continu</td>\n",
       "      <td>sulbactam</td>\n",
       "      <td>jet</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remain</td>\n",
       "      <td>confus</td>\n",
       "      <td>watch</td>\n",
       "      <td>remnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reason</td>\n",
       "      <td>anxieti</td>\n",
       "      <td>pill</td>\n",
       "      <td>compart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>impress</td>\n",
       "      <td>elev</td>\n",
       "      <td>accumul</td>\n",
       "      <td>endotrach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords  small_level  mid_level   large_level\n",
       "0     tube          osa      disku           lpm\n",
       "1   assess       averag   mucomyst           ucx\n",
       "2     year  colonoscopi       name          cont\n",
       "3  histori       opioid      follw     inconsist\n",
       "4       mg      process       with  pancytopenia\n",
       "5      man        coffe  uncertain     insuffici\n",
       "6  continu    sulbactam        jet           job\n",
       "7   remain       confus      watch       remnant\n",
       "8   reason      anxieti       pill       compart\n",
       "9  impress         elev    accumul     endotrach"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'keywords':keywords_dict['Gender'],\n",
    "             'small_level':get_replace_word(keywords_dict['Gender'], \"small\"),\n",
    "             'mid_level':get_replace_word(keywords_dict['Gender'], \"mid\"),\n",
    "             'large_level':get_replace_word(keywords_dict['Gender'], \"large\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "769ece06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "769ece06",
    "outputId": "8c37d89a-16a5-4b10-a59b-86ad9c28522d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10 10 10\n",
      "['pt', 'chang', 'tube', 'right', 'name', 'left', 'chest', 'failur', 'remain', 'hr']\n"
     ]
    }
   ],
   "source": [
    "print(len(keywords_dict['length_of_stay_avg']))\n",
    "print(len(get_replace_word(keywords_dict['length_of_stay_avg'], \"small\")),\n",
    "len(get_replace_word(keywords_dict['length_of_stay_avg'], \"mid\")),\n",
    "len(get_replace_word(keywords_dict['length_of_stay_avg'], \"large\")))\n",
    "print(keywords_dict['length_of_stay_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4921edfc",
   "metadata": {
    "id": "4921edfc"
   },
   "outputs": [],
   "source": [
    "# # ! pip install wikipedia2vec\n",
    "# from wikipedia2vec import Wikipedia2Vec\n",
    "# wiki2vec = Wikipedia2Vec.load(\"enwiki_20180420_100d.pkl\")\n",
    "# wiki2vec.most_similar(wiki2vec.get_word(\"tarch\"), 100)[1:]\n",
    "# keywords_dict['length_of_stay_avg']\n",
    "# sorted([(i[0].text, i[1]) for i in wiki2vec.most_similar(wiki2vec.get_word(\"tarch\"), 101)[1:]], key = lambda x:x[1], reverse = True)\n",
    "# # wiki2vec.most_similar(wiki2vec.get_word('yoda'), 5)\n",
    "# def find_3levels_word_pretrained(keyword_list, small = 33, mid = 66):\n",
    "#     \"\"\"\"keywords is a list of predictive words of a certain outcome,\n",
    "#     small is the percentile criteria for small level of obfuscation,\n",
    "#     mid is the percentile criteria for mid level of obfuscation,\n",
    "\n",
    "#     return are 3 word list: each derived by random sampling from the corresponding obfuscation level\"\"\"\n",
    "\n",
    "#     small_level_list = []\n",
    "#     mid_level_list = []\n",
    "#     large_level_list = []\n",
    "#     for word in keyword_list:\n",
    "# #         try:\n",
    "# #             similar_words = sorted([(i[0].text, i[1]) for i in wiki2vec.most_similar(wiki2vec.get_word(word), 100)[1:101]], key = lambda x:x[1], reverse = True)\n",
    "# #             similar_words = sorted(wiki2vec.get_similar_word_list(keywords = word, end_radius = 100), key = lambda x: x[1], reverse = True)\n",
    "# #         except:\n",
    "\n",
    "# #         else:\n",
    "#         similar_words = sorted([(i[0].text, i[1]) for i in wiki2vec.most_similar(wiki2vec.get_word(word), 100)[1:101]], key = lambda x:x[1], reverse = True)\n",
    "#         print(word)\n",
    "#         word_list, cos_list = list(zip(*similar_words))\n",
    "#         small_range = word_list[:small]\n",
    "#         mid_range = word_list[small:mid]\n",
    "#         large_range = word_list[mid:]\n",
    "\n",
    "#         small_level_list.append(random.sample(small_range,1)[0])\n",
    "#         mid_level_list.append(random.sample(mid_range,1)[0])\n",
    "#         large_level_list.append(random.sample(large_range,1)[0])\n",
    "#         print(small_level_list)\n",
    "\n",
    "#     return small_level_list, mid_level_list, large_level_list\n",
    "\n",
    "# def get_replace_word(keywords, level, small = 33, mid = 66):\n",
    "#     if isinstance(level, str):\n",
    "#         small, mid, large = find_3levels_word_pretrained(keywords, small, mid)\n",
    "#         level = level.lower()\n",
    "#         if level == \"small\":\n",
    "#             return small\n",
    "#         elif level == \"mid\":\n",
    "#             return mid\n",
    "#         elif level == \"large\":\n",
    "#             return large\n",
    "#     else: NotImplemented\n",
    "\n",
    "# # find_3levels_word_pretrained(keywords_dict['length_of_stay_avg'])\n",
    "# get_replace_word(keywords_dict['length_of_stay_avg'], \"small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5b502d42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "5b502d42",
    "outputId": "33e498aa-959a-4681-caba-50ddc69033a6"
   },
   "outputs": [],
   "source": [
    "# use google news trained w2v\n",
    "import gensim\n",
    "model = gensim.models.keyedvectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "387b40b7",
   "metadata": {
    "id": "387b40b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stls', 0.5360503792762756),\n",
       " ('rbds', 0.5249072909355164),\n",
       " ('w', 0.519607663154602),\n",
       " ('2pt', 0.513253927230835),\n",
       " ('rbs', 0.5095221996307373),\n",
       " ('pts', 0.5054894685745239),\n",
       " ('RPM_ASM', 0.5014232397079468),\n",
       " ('R.Williams', 0.49798235297203064),\n",
       " ('3pt', 0.49516722559928894),\n",
       " ('sv', 0.4927876889705658)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.similar_by_word(word = keywords_dict['length_of_stay_avg'][0], topn = 10),\n",
    "                                   key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9909bb4f",
   "metadata": {
    "id": "9909bb4f"
   },
   "outputs": [],
   "source": [
    "# wiki2vec.most_similar(wiki2vec.get_word(\"tarch\"), 100)[1:]\n",
    "# keywords_dict['length_of_stay_avg']\n",
    "\n",
    "def find_3levels_word_GN(keyword_list, small = 33, mid = 66):\n",
    "    \"\"\"\"keywords is a list of predictive words of a certain outcome,\n",
    "    small is the percentile criteria for small level of obfuscation,\n",
    "    mid is the percentile criteria for mid level of obfuscation,\n",
    "\n",
    "    return are 3 word list: each derived by random sampling from the corresponding obfuscation level\"\"\"\n",
    "\n",
    "    small_level_list = []\n",
    "    mid_level_list = []\n",
    "    large_level_list = []\n",
    "    for word in keyword_list:\n",
    "        try:\n",
    "            similar_words = sorted(model.similar_by_word(word = keywords_dict['length_of_stay_avg'][0], topn = 100),\n",
    "                                   key = lambda x: x[1], reverse = True)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            word_list, cos_list = list(zip(*similar_words))\n",
    "            small_range = word_list[:small]\n",
    "            mid_range = word_list[small:mid]\n",
    "            large_range = word_list[mid:]\n",
    "            small_level_list.append(random.sample(small_range,1)[0])\n",
    "            mid_level_list.append(random.sample(mid_range,1)[0])\n",
    "            large_level_list.append(random.sample(large_range,1)[0])\n",
    "\n",
    "    return small_level_list, mid_level_list, large_level_list\n",
    "\n",
    "\n",
    "def get_replace_word_GN(keywords, level, small = 33, mid = 66):\n",
    "    if isinstance(level, str):\n",
    "        small, mid, large = find_3levels_word_GN(keywords, small, mid)\n",
    "        level = level.lower()\n",
    "        if level == \"small\":\n",
    "            return small\n",
    "        elif level == \"mid\":\n",
    "            return mid\n",
    "        elif level == \"large\":\n",
    "            return large\n",
    "    else: NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb597f57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb597f57",
    "outputId": "1ba44e30-f16f-4981-cbea-818a63490e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pt',\n",
       " 'chang',\n",
       " 'tube',\n",
       " 'right',\n",
       " 'name',\n",
       " 'left',\n",
       " 'chest',\n",
       " 'failur',\n",
       " 'remain',\n",
       " 'hr']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict[outcomes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba088fcb",
   "metadata": {
    "id": "ba088fcb"
   },
   "outputs": [],
   "source": [
    "def generate_words_for_replacement(keywords_dictionary):\n",
    "    \"\"\"input:\n",
    "    keywords_dict: dictionary, with key = sensitive factor, value = predictive words of that factor\n",
    "    return the data frame containing the words for replacement of each sensitive factor\"\"\"\n",
    "    words_for_replacement = {}\n",
    "    for key, item in keywords_dictionary.items():\n",
    "        words_for_replacement[key] = pd.DataFrame({'keywords':keywords_dictionary[key],\n",
    "             'small_level':get_replace_word_GN(keywords_dictionary[key], \"small\"),\n",
    "             'mid_level':get_replace_word_GN(keywords_dictionary[key], \"mid\"),\n",
    "             'large_level':get_replace_word_GN(keywords_dictionary[key], \"large\")})\n",
    "\n",
    "\n",
    "\n",
    "    return words_for_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7be9b3f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "7be9b3f1",
    "outputId": "89d93202-e4d9-4f38-d3c5-c794d1a02504"
   },
   "outputs": [],
   "source": [
    "a = generate_words_for_replacement(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94ce5029",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "94ce5029",
    "outputId": "19c2e133-7853-40fb-947e-e524f9aaac54",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>small_level</th>\n",
       "      <th>mid_level</th>\n",
       "      <th>large_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tube</td>\n",
       "      <td>asts</td>\n",
       "      <td>..........</td>\n",
       "      <td>é_o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assess</td>\n",
       "      <td>asts</td>\n",
       "      <td>t8</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>lj</td>\n",
       "      <td>@_sportsguy##</td>\n",
       "      <td>coord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>histori</td>\n",
       "      <td>w/##</td>\n",
       "      <td>fg</td>\n",
       "      <td>supra_§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mg</td>\n",
       "      <td>sv</td>\n",
       "      <td>7r</td>\n",
       "      <td>cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>rbs</td>\n",
       "      <td>FIRST_PERIOD</td>\n",
       "      <td>Elmhurst_............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continu</td>\n",
       "      <td>sv</td>\n",
       "      <td>ECap</td>\n",
       "      <td>ht_ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remain</td>\n",
       "      <td>R.Williams</td>\n",
       "      <td>nxt</td>\n",
       "      <td>coord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reason</td>\n",
       "      <td>asts</td>\n",
       "      <td>3PA</td>\n",
       "      <td>Elmhurst_............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>impress</td>\n",
       "      <td>3pt</td>\n",
       "      <td>7r</td>\n",
       "      <td>J.Jones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords small_level      mid_level            large_level\n",
       "0     tube        asts     ..........                    é_o\n",
       "1   assess        asts             t8                      p\n",
       "2     year          lj  @_sportsguy##                  coord\n",
       "3  histori        w/##             fg                supra_§\n",
       "4       mg          sv             7r                     cg\n",
       "5      man         rbs   FIRST_PERIOD  Elmhurst_............\n",
       "6  continu          sv           ECap                  ht_ft\n",
       "7   remain  R.Williams            nxt                  coord\n",
       "8   reason        asts            3PA  Elmhurst_............\n",
       "9  impress         3pt             7r                J.Jones"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[outcomes[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40004729",
   "metadata": {
    "id": "40004729"
   },
   "source": [
    "# Step 5: Replace words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c13a96d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "c13a96d5",
    "outputId": "0c12fdf7-6f1a-4926-f97e-92e1e0e771dd"
   },
   "outputs": [],
   "source": [
    "wordsReplacement = generate_words_for_replacement(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95a42114",
   "metadata": {
    "id": "95a42114"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>small_level</th>\n",
       "      <th>mid_level</th>\n",
       "      <th>large_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pt</td>\n",
       "      <td>w/##</td>\n",
       "      <td>lk</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chang</td>\n",
       "      <td>srv</td>\n",
       "      <td>@_sportsguy##</td>\n",
       "      <td>Elmhurst_............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tube</td>\n",
       "      <td>:3</td>\n",
       "      <td>nxt</td>\n",
       "      <td>Long_Wittenham_Res</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>lj</td>\n",
       "      <td>3PA</td>\n",
       "      <td>Opp'n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name</td>\n",
       "      <td>rbds</td>\n",
       "      <td>qt</td>\n",
       "      <td>3PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>left</td>\n",
       "      <td>atts</td>\n",
       "      <td>pg</td>\n",
       "      <td>alt_Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chest</td>\n",
       "      <td>PM_CC</td>\n",
       "      <td>nxt</td>\n",
       "      <td>J.Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>failur</td>\n",
       "      <td>¼_l</td>\n",
       "      <td>,8</td>\n",
       "      <td>cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>remain</td>\n",
       "      <td>3pt</td>\n",
       "      <td>FIRST_PERIOD</td>\n",
       "      <td>#-##.#.#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hr</td>\n",
       "      <td>PM_CC</td>\n",
       "      <td>THIRD_PERIOD</td>\n",
       "      <td>+###,###_bbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords small_level      mid_level            large_level\n",
       "0       pt        w/##             lk                      p\n",
       "1    chang         srv  @_sportsguy##  Elmhurst_............\n",
       "2     tube          :3            nxt     Long_Wittenham_Res\n",
       "3    right          lj            3PA                  Opp'n\n",
       "4     name        rbds             qt                    3PT\n",
       "5     left        atts             pg                alt_Sec\n",
       "6    chest       PM_CC            nxt                J.Jones\n",
       "7   failur         ¼_l             ,8                     cg\n",
       "8   remain         3pt   FIRST_PERIOD               #-##.#.#\n",
       "9       hr       PM_CC   THIRD_PERIOD           +###,###_bbl"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsReplacement[outcomes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ea184ba6",
   "metadata": {
    "id": "ea184ba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>small_level</th>\n",
       "      <th>mid_level</th>\n",
       "      <th>large_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tube</td>\n",
       "      <td>dpa_db</td>\n",
       "      <td>:4</td>\n",
       "      <td>J.Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assess</td>\n",
       "      <td>dpa_ds</td>\n",
       "      <td>pg</td>\n",
       "      <td>INSTANT_VIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>dpa_db</td>\n",
       "      <td>Unassisted_..............................</td>\n",
       "      <td>lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>histori</td>\n",
       "      <td>gls</td>\n",
       "      <td>3PA</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mg</td>\n",
       "      <td>Sensex_dips</td>\n",
       "      <td>#.##pts</td>\n",
       "      <td>L_,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>dpa_cb</td>\n",
       "      <td>,8</td>\n",
       "      <td>cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continu</td>\n",
       "      <td>SECOND_PERIOD</td>\n",
       "      <td>FIRST_PERIOD</td>\n",
       "      <td>lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remain</td>\n",
       "      <td>SECOND_PERIOD</td>\n",
       "      <td>pk</td>\n",
       "      <td>jrw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reason</td>\n",
       "      <td>dpa_cb</td>\n",
       "      <td>Unassisted_..............................</td>\n",
       "      <td>ht_ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>impress</td>\n",
       "      <td>rbds</td>\n",
       "      <td>:4</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords    small_level                                  mid_level  \\\n",
       "0     tube         dpa_db                                         :4   \n",
       "1   assess         dpa_ds                                         pg   \n",
       "2     year         dpa_db  Unassisted_..............................   \n",
       "3  histori            gls                                        3PA   \n",
       "4       mg    Sensex_dips                                    #.##pts   \n",
       "5      man         dpa_cb                                         ,8   \n",
       "6  continu  SECOND_PERIOD                               FIRST_PERIOD   \n",
       "7   remain  SECOND_PERIOD                                         pk   \n",
       "8   reason         dpa_cb  Unassisted_..............................   \n",
       "9  impress           rbds                                         :4   \n",
       "\n",
       "    large_level  \n",
       "0       J.Jones  \n",
       "1  INSTANT_VIEW  \n",
       "2            lv  \n",
       "3            sl  \n",
       "4          L_,4  \n",
       "5            cg  \n",
       "6            lv  \n",
       "7           jrw  \n",
       "8         ht_ft  \n",
       "9             p  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsReplacement[outcomes[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e328f3ce",
   "metadata": {
    "id": "e328f3ce"
   },
   "outputs": [],
   "source": [
    "def obfuscate(notes, wordForReplacement, level, sensitive_factor):\n",
    "    \"\"\"wordForReplacement: dictionary containing all senstitive factors and their corresponding words for replacement\n",
    "    level: obfuscation level (small, mid, large)\n",
    "    sensitive_factor: obfuscation factor (outcomes)\"\"\"\n",
    "    wordForReplacement = wordsReplacement.copy()\n",
    "#     sensitive_factor = \"Religion\"\n",
    "    all_note = notes.copy()\n",
    "    for i, note in enumerate(all_note):\n",
    "        replace_dict = {}\n",
    "        for word in note.split():\n",
    "#             print(word)\n",
    "#             print(list(wordForReplacement[sensitive_factor]['keywords']))\n",
    "            curr_word = lemmatizer.lemmatize(word).lower()\n",
    "            if curr_word in list(wordForReplacement[sensitive_factor]['keywords']):\n",
    "                if level == \"small\":\n",
    "#                     print(\"curr_word:\", curr_word)\n",
    "                    potential_words = wordForReplacement[sensitive_factor]\n",
    "                    word_for_replace = potential_words[potential_words['keywords'] == curr_word]['small_level'].values[0]\n",
    "#                     print(\"word_for_replace\", word_for_replace)\n",
    "                    replace_dict[curr_word] = word_for_replace\n",
    "                if level == \"medium\":\n",
    "                    potential_words = wordForReplacement[sensitive_factor]\n",
    "                    word_for_replace = potential_words[potential_words['keywords'] == curr_word]['mid_level'].values[0]\n",
    "                    replace_dict[curr_word] = word_for_replace\n",
    "                if level == \"large\":\n",
    "                    potential_words = wordForReplacement[sensitive_factor]\n",
    "                    word_for_replace = potential_words[potential_words['keywords'] == curr_word]['large_level'].values[0]\n",
    "                    replace_dict[curr_word] = word_for_replace\n",
    "#       all_note[i] = re.sub(curr_word, word_for_replace, note)\n",
    "        #print(replace_dict)\n",
    "        for target, replace in replace_dict.items():\n",
    "            note = note.replace(target, replace)\n",
    "#             re.sub(target, replace, note)\n",
    "        all_note[i] = note\n",
    "\n",
    "    return all_note\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe4c07d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "fe4c07d3",
    "outputId": "129ed518-2a60-413f-ef77-dfe5988b836b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest tubes removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest tubes removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the right IJ\\n sheath remains in place.  Both left chest tubes have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "t_LxJAPvTWA4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "t_LxJAPvTWA4",
    "outputId": "cf5b335e-fbcf-4da1-f1ff-8ea68659b86e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest stlss removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest stlss removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the gls IJ\\n sheath remains in place.  Both lj chest stlss have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfuscate([raw[0]], wordsReplacement, \"small\", outcomes[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "439301f5",
   "metadata": {
    "id": "439301f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length_of_stay_avg', 'Religion', 'Gender']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d16bfb8",
   "metadata": {
    "id": "1d16bfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[**2153-9-4**] 9:16 AM\n",
      " CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\n",
      " Reason: assess lung expansion\n",
      " Admitting Diagnosis: CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS GRAFT/SDA\n",
      " ______________________________________________________________________________\n",
      " [**Hospital 2**] MEDICAL CONDITION:\n",
      "   71 year old man s/p CABG now w/chest tubes removed\n",
      "\n",
      " REASON FOR THIS EXAMINATION:\n",
      "  assess lung expansion\n",
      " ______________________________________________________________________________\n",
      "                                 FINAL REPORT\n",
      " INDICATIONS:  Chest tubes removed.\n",
      "\n",
      " PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\n",
      " has been extubated.  Swan-Ganz catheter has been removed and the right IJ\n",
      " sheath remains in place.  Both left chest tubes have been removed.  There is\n",
      " no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\n",
      " improvement in pulmonary edema.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9779f2f5",
   "metadata": {
    "id": "9779f2f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest stlss removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest stlss removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the gls IJ\\n sheath remains in place.  Both lj chest stlss have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "print(obfuscate([raw[0]], wordsReplacement, \"small\", outcomes[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "86aff11b",
   "metadata": {
    "id": "86aff11b"
   },
   "outputs": [],
   "source": [
    "arr_small =[]\n",
    "for r in raw:\n",
    "    arr_small.append(obfuscate([r], wordsReplacement, \"small\", outcomes[1]))\n",
    "df_small = pd.DataFrame(arr_small, columns=['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d011824a",
   "metadata": {
    "id": "d011824a"
   },
   "outputs": [],
   "source": [
    "arr_med =[]\n",
    "for r in raw:\n",
    "    arr_med.append(obfuscate([r], wordsReplacement, \"medium\", outcomes[1]))\n",
    "df_medium = pd.DataFrame(arr_med, columns=['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "59d66e52",
   "metadata": {
    "id": "59d66e52"
   },
   "outputs": [],
   "source": [
    "arr_large =[]\n",
    "for r in raw:\n",
    "    arr_large.append(obfuscate([r], wordsReplacement, \"large\", outcomes[1]))\n",
    "df_large = pd.DataFrame(arr_large, columns=['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1cf6ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.to_csv('mimi3_small.csv', index=False)\n",
    "df_medium.to_csv('mimi3_medium.csv', index=False)\n",
    "df_large.to_csv('mimi3_large.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69eea09b",
   "metadata": {
    "id": "69eea09b"
   },
   "outputs": [],
   "source": [
    "# def stat_summary(outcome_keywords_similar_list):\n",
    "#     #Religion_stat_summary\n",
    "#     Religion_stat_summary = pd.DataFrame()\n",
    "#     keywords_similarity = w2v_model.get_similar_word_2(keywords = outcome_keywords_similar_list)\n",
    "#     max_value, min_value, mean, median, IQ25, IQ75 = [], [], [], [], [], []\n",
    "#     for word_list in keywords_similarity:\n",
    "#         max_value.append(np.max(list(zip(*word_list))[1]))\n",
    "#         min_value.append(np.min(list(zip(*word_list))[1]))\n",
    "#         mean.append(np.mean(list(zip(*word_list))[1]))\n",
    "#         median.append(np.median(list(zip(*word_list))[1]))\n",
    "#         IQ25.append(np.percentile(list(zip(*word_list))[1],25))\n",
    "#         IQ75.append( np.percentile(list(zip(*word_list))[1],75))\n",
    "\n",
    "#     stat_summary = pd.DataFrame({\n",
    "#       \"min\": min_value,\n",
    "#       \"max\": max_value,\n",
    "#       \"median\": median,\n",
    "#       \"mean\": mean,\n",
    "#       \"IQ25\": IQ25,\n",
    "#       \"IQ75\": IQ75\n",
    "#     })\n",
    "#     stat_summary = pd.concat([pd.DataFrame({\"keywords\": outcome_keywords_similar_list}),\n",
    "#                                 stat_summary], axis = 1)\n",
    "#     return stat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "695a5970",
   "metadata": {
    "id": "695a5970"
   },
   "outputs": [],
   "source": [
    "# print(LOSA_list)\n",
    "# keywords_similarity = w2v_model.get_similar_word_2(keywords = LOSA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "898dbba0",
   "metadata": {
    "id": "898dbba0"
   },
   "outputs": [],
   "source": [
    "# outcome_stat_summary = {}\n",
    "# for outcome, keyword in keywords_dict.items():\n",
    "#     outcome_stat_summary.setdefault(outcome, stat_summary(keyword))\n",
    "# outcome_stat_summary['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EIiBgwuHN9ZS",
   "metadata": {
    "id": "EIiBgwuHN9ZS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gupZVGA7N9ml",
   "metadata": {
    "id": "gupZVGA7N9ml"
   },
   "source": [
    "**STEP 7 SDV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "PO5TWDnCGbTq",
   "metadata": {
    "id": "PO5TWDnCGbTq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_table():\\n    table = pd.DataFrame(columns=['metric', 'name', 'normalized_score_small', 'normalized_score_med', 'normalized_score_large'])\\n    eval = [evaluate(synthetic_data[i], real_data,  aggregate=False) for i in range(3)]\\n    eval_small = eval[0]\\n    eval_med = eval[1]\\n    eval_large = eval[2]\\n    metrics_list = list(eval_small.metric)\\n    print(metrics_list + ['privacy'])\\n    table.metric = metrics_list + ['privacy']\\n\\n    table.name = list(eval_small.name) + ['categorical']\\n\\n    privacy_score = [CategoricalCAP.compute(\\n        real_data.fillna(0),\\n        synthetic_data[i].fillna(0),\\n        key_fields=['TEXT'],\\n        sensitive_fields=['GENDER']\\n        ) for i in range(len(synthetic_data))]\\n    table.normalized_score_small = list(eval_small.normalized_score) + [privacy_score[0]]\\n    table.normalized_score_med = list(eval_med.normalized_score) + [privacy_score[1]]\\n    table.normalized_score_large = list(eval_large.normalized_score) + [privacy_score[2]]\\n    return table\\n\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_table():\n",
    "    table = pd.DataFrame(columns=['metric', 'name', 'normalized_score_small', 'normalized_score_med', 'normalized_score_large'])\n",
    "    eval = [evaluate(synthetic_data[i], real_data,  aggregate=False) for i in range(3)]\n",
    "    eval_small = eval[0]\n",
    "    eval_med = eval[1]\n",
    "    eval_large = eval[2]\n",
    "    metrics_list = list(eval_small.metric)\n",
    "    print(metrics_list + ['privacy'])\n",
    "    table.metric = metrics_list + ['privacy']\n",
    "\n",
    "    table.name = list(eval_small.name) + ['categorical']\n",
    "\n",
    "    privacy_score = [CategoricalCAP.compute(\n",
    "        real_data.fillna(0),\n",
    "        synthetic_data[i].fillna(0),\n",
    "        key_fields=['TEXT'],\n",
    "        sensitive_fields=['GENDER']\n",
    "        ) for i in range(len(synthetic_data))]\n",
    "    table.normalized_score_small = list(eval_small.normalized_score) + [privacy_score[0]]\n",
    "    table.normalized_score_med = list(eval_med.normalized_score) + [privacy_score[1]]\n",
    "    table.normalized_score_large = list(eval_large.normalized_score) + [privacy_score[2]]\n",
    "    return table\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ihK_JPIuGbuX",
   "metadata": {
    "id": "ihK_JPIuGbuX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = GaussianCopula()\\nreal_data_0 = real_data.iloc[0:50]\\n# real_data_1 = real_data.iloc[51:100]\\n# real_data_2 = real_data.iloc[101:150]\\nreal_data = real_data_0\\n# real_data\\nmodel.fit(real_data)\\nsynthetic_data_0 = model.sample()\\n# model.fit(real_data_1)\\nsynthetic_data_1 = model.sample()\\n# model.fit(real_data_2)\\nsynthetic_data_2 = model.sample()\\nsynthetic_data = [synthetic_data_0, synthetic_data_1, synthetic_data_2]\\n# metrics_list = ['CSTest', 'KSTest']\\ntable = create_table()\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = GaussianCopula()\n",
    "real_data_0 = real_data.iloc[0:50]\n",
    "# real_data_1 = real_data.iloc[51:100]\n",
    "# real_data_2 = real_data.iloc[101:150]\n",
    "real_data = real_data_0\n",
    "# real_data\n",
    "model.fit(real_data)\n",
    "synthetic_data_0 = model.sample()\n",
    "# model.fit(real_data_1)\n",
    "synthetic_data_1 = model.sample()\n",
    "# model.fit(real_data_2)\n",
    "synthetic_data_2 = model.sample()\n",
    "synthetic_data = [synthetic_data_0, synthetic_data_1, synthetic_data_2]\n",
    "# metrics_list = ['CSTest', 'KSTest']\n",
    "table = create_table()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8vACy7FLOvTh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8vACy7FLOvTh",
    "outputId": "31fb45e4-2a54-43c3-fa28-2f3e9b1c6729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sdv\n",
      "  Obtaining dependency information for sdv from https://files.pythonhosted.org/packages/bf/dc/584e1a86cb553fe4eb58cc04c35af7d37063491e670cc3b5872b8475afc2/sdv-1.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sdv-1.4.0-py2.py3-none-any.whl.metadata (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boto3<2,>=1.15.0 (from sdv)\n",
      "  Obtaining dependency information for boto3<2,>=1.15.0 from https://files.pythonhosted.org/packages/c0/67/4d23a38313d7b37892a6d9c9260809f1a2f5a37feaf6f13da0aa27f57d6d/boto3-1.28.63-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.28.63-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<2,>=1.18 (from sdv)\n",
      "  Obtaining dependency information for botocore<2,>=1.18 from https://files.pythonhosted.org/packages/24/0e/39117ec73ea22e700503b3af1dbab270563d6d6ca862cf572899824e4212/botocore-1.31.63-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.31.63-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting cloudpickle<3.0,>=2.1.0 (from sdv)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting Faker<15,>=10 (from sdv)\n",
      "  Using cached Faker-14.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting graphviz<1,>=0.13.2 (from sdv)\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.15 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (4.66.1)\n",
      "Collecting copulas<0.10,>=0.9.0 (from sdv)\n",
      "  Obtaining dependency information for copulas<0.10,>=0.9.0 from https://files.pythonhosted.org/packages/ba/51/6b3bca46fd410c3771cccc218bc940ba819019f71e0ed28f980371ac7507/copulas-0.9.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading copulas-0.9.2-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting ctgan<0.8,>=0.7.4 (from sdv)\n",
      "  Obtaining dependency information for ctgan<0.8,>=0.7.4 from https://files.pythonhosted.org/packages/cc/ad/577a9c231b7b40115bd252b260eca05ec1ce8e3a2299e462b39bf74c0265/ctgan-0.7.5-py2.py3-none-any.whl.metadata\n",
      "  Downloading ctgan-0.7.5-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting deepecho<0.5,>=0.4.2 (from sdv)\n",
      "  Obtaining dependency information for deepecho<0.5,>=0.4.2 from https://files.pythonhosted.org/packages/1f/69/55334c9ed0cf494c6fdc38cedca7a3a589962e0c488406d138e616b00c59/deepecho-0.4.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading deepecho-0.4.2-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rdt<2,>=1.7.0 (from sdv)\n",
      "  Obtaining dependency information for rdt<2,>=1.7.0 from https://files.pythonhosted.org/packages/24/2e/f4f711401c4f53baa57122428a253522da2327b06df378341de6329a23bb/rdt-1.7.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading rdt-1.7.0-py2.py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sdmetrics<0.12,>=0.11.0 (from sdv)\n",
      "  Obtaining dependency information for sdmetrics<0.12,>=0.11.0 from https://files.pythonhosted.org/packages/d4/f8/d9670479ba93556a31afaa0ffc430d62b9e9c83dd2c9de09b279f640caae/sdmetrics-0.11.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading sdmetrics-0.11.1-py2.py3-none-any.whl.metadata (35 kB)\n",
      "Collecting numpy<1.25.0,>=1.23.3 (from sdv)\n",
      "  Obtaining dependency information for numpy<1.25.0,>=1.23.3 from https://files.pythonhosted.org/packages/c0/bc/77635c657a3668cf652806210b8662e1aff84b818a55ba88257abf6637a8/numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from sdv) (2.1.1)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.15.0->sdv)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3<2,>=1.15.0->sdv)\n",
      "  Obtaining dependency information for s3transfer<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/5a/4b/fec9ce18f8874a96c5061422625ba86c3ee1e6587ccd92ff9f5bf7bd91b2/s3transfer-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/homebrew/lib/python3.11/site-packages (from botocore<2,>=1.18->sdv) (2.0.6)\n",
      "Requirement already satisfied: matplotlib<4,>=3.6.0 in /opt/homebrew/lib/python3.11/site-packages (from copulas<0.10,>=0.9.0->sdv) (3.8.0)\n",
      "Requirement already satisfied: scipy<2,>=1.9.2 in /opt/homebrew/lib/python3.11/site-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from ctgan<0.8,>=0.7.4->sdv) (1.3.1)\n",
      "Collecting torch>=2.0.0 (from ctgan<0.8,>=0.7.4->sdv)\n",
      "  Obtaining dependency information for torch>=2.0.0 from https://files.pythonhosted.org/packages/7b/7c/4d8728e6f8dbe2b8af054bd92c290d94c633270443514e3ee4b768125cf9/torch-2.1.0-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdv) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdv) (2023.3)\n",
      "Requirement already satisfied: psutil<6,>=5.7 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from rdt<2,>=1.7.0->sdv) (5.9.5)\n",
      "Collecting plotly<6,>=5.10.0 (from sdmetrics<0.12,>=0.11.0->sdv)\n",
      "  Obtaining dependency information for plotly<6,>=5.10.0 from https://files.pythonhosted.org/packages/df/79/c80174d711ee26ee5da55a9cc3e248f1ec7a0188b5e4d6bbbbcd09b974b0/plotly-5.17.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading plotly-5.17.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.1)\n",
      "Collecting tenacity>=6.2.0 (from plotly<6,>=5.10.0->sdmetrics<0.12,>=0.11.0->sdv)\n",
      "  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/opt/six/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (4.8.0)\n",
      "Collecting sympy (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.1.2)\n",
      "Collecting fsspec (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading sdv-1.4.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.28.63-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.31.63-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading copulas-0.9.2-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ctgan-0.7.5-py2.py3-none-any.whl (27 kB)\n",
      "Downloading deepecho-0.4.2-py2.py3-none-any.whl (29 kB)\n",
      "Downloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rdt-1.7.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.5/70.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sdmetrics-0.11.1-py2.py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.17.0-py2.py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tenacity, sympy, numpy, networkx, jmespath, graphviz, fsspec, cloudpickle, torch, plotly, Faker, botocore, s3transfer, deepecho, rdt, copulas, boto3, sdmetrics, ctgan, sdv\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Not uninstalling numpy at /opt/homebrew/lib/python3.11/site-packages, outside environment /opt/homebrew/Cellar/ipython/8.16.1/libexec\n",
      "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
      "Successfully installed Faker-14.2.1 boto3-1.28.63 botocore-1.31.63 cloudpickle-2.2.1 copulas-0.9.2 ctgan-0.7.5 deepecho-0.4.2 fsspec-2023.9.2 graphviz-0.20.1 jmespath-1.0.1 mpmath-1.3.0 networkx-3.1 numpy-1.24.4 plotly-5.17.0 rdt-1.7.0 s3transfer-0.7.0 sdmetrics-0.11.1 sdv-1.4.0 sympy-1.12 tenacity-8.2.3 torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "nIi-kRe2n1dy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIi-kRe2n1dy",
    "outputId": "1c9f4fd7-b2ac-4d4c-b9f8-8d83ace19cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sdmetrics in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (0.11.1)\n",
      "Requirement already satisfied: copulas<0.10,>=0.9.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdmetrics) (0.9.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.15 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdmetrics) (4.66.1)\n",
      "Requirement already satisfied: plotly<6,>=5.10.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdmetrics) (5.17.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.3 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdmetrics) (1.24.4)\n",
      "Requirement already satisfied: scipy<2,>=1.9.2 in /opt/homebrew/lib/python3.11/site-packages (from sdmetrics) (1.11.3)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from sdmetrics) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from sdmetrics) (1.3.1)\n",
      "Requirement already satisfied: matplotlib<4,>=3.6.0 in /opt/homebrew/lib/python3.11/site-packages (from copulas<0.10,>=0.9.0->sdmetrics) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from pandas>=1.5.0->sdmetrics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdmetrics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdmetrics) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from plotly<6,>=5.10.0->sdmetrics) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from plotly<6,>=5.10.0->sdmetrics) (23.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->sdmetrics) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->sdmetrics) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdmetrics) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/opt/six/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->sdmetrics) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sdmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3q12c_oxaRA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3q12c_oxaRA",
    "outputId": "c15271f4-7f51-4f3f-f530-f4e2b1602e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sdv in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: boto3<2,>=1.15.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (1.28.63)\n",
      "Requirement already satisfied: botocore<2,>=1.18 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (1.31.63)\n",
      "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (2.2.1)\n",
      "Requirement already satisfied: Faker<15,>=10 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (14.2.1)\n",
      "Requirement already satisfied: graphviz<1,>=0.13.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (0.20.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.15 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (4.66.1)\n",
      "Requirement already satisfied: copulas<0.10,>=0.9.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (0.9.2)\n",
      "Requirement already satisfied: ctgan<0.8,>=0.7.4 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (0.7.5)\n",
      "Requirement already satisfied: deepecho<0.5,>=0.4.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (0.4.2)\n",
      "Requirement already satisfied: rdt<2,>=1.7.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (1.7.0)\n",
      "Requirement already satisfied: sdmetrics<0.12,>=0.11.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (0.11.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.23.3 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdv) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from sdv) (2.1.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from boto3<2,>=1.15.0->sdv) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from boto3<2,>=1.15.0->sdv) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/homebrew/lib/python3.11/site-packages (from botocore<2,>=1.18->sdv) (2.0.6)\n",
      "Requirement already satisfied: matplotlib<4,>=3.6.0 in /opt/homebrew/lib/python3.11/site-packages (from copulas<0.10,>=0.9.0->sdv) (3.8.0)\n",
      "Requirement already satisfied: scipy<2,>=1.9.2 in /opt/homebrew/lib/python3.11/site-packages (from copulas<0.10,>=0.9.0->sdv) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from ctgan<0.8,>=0.7.4->sdv) (1.3.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from ctgan<0.8,>=0.7.4->sdv) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdv) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.5.0->sdv) (2023.3)\n",
      "Requirement already satisfied: psutil<6,>=5.7 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from rdt<2,>=1.7.0->sdv) (5.9.5)\n",
      "Requirement already satisfied: plotly<6,>=5.10.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sdmetrics<0.12,>=0.11.0->sdv) (5.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from plotly<6,>=5.10.0->sdmetrics<0.12,>=0.11.0->sdv) (8.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/opt/six/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sympy->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "l1FJ2-aOivhH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1FJ2-aOivhH",
    "outputId": "9db4b5d2-dfcc-4f5c-ea89-613224e8bf3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pomegranate\n",
      "  Obtaining dependency information for pomegranate from https://files.pythonhosted.org/packages/a7/6f/523c38b03df252cb5ea1e17c71e27ff7e0ca908194e6115280149b8063e8/pomegranate-1.0.3-py3-none-any.whl.metadata\n",
      "  Downloading pomegranate-1.0.3-py3-none-any.whl.metadata (479 bytes)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pomegranate) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6.2 in /opt/homebrew/lib/python3.11/site-packages (from pomegranate) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/homebrew/lib/python3.11/site-packages (from pomegranate) (1.3.1)\n",
      "Requirement already satisfied: torch>=1.9.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pomegranate) (2.1.0)\n",
      "Collecting apricot-select>=0.6.1 (from pomegranate)\n",
      "  Downloading apricot-select-0.6.1.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.8.4 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from pomegranate) (3.1)\n",
      "Collecting numba>=0.43.0 (from apricot-select>=0.6.1->pomegranate)\n",
      "  Obtaining dependency information for numba>=0.43.0 from https://files.pythonhosted.org/packages/1b/2e/1d80831b015606a6743ea4bf60ab1c91e7130ff1155381524a1dab0e8334/numba-0.58.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numba-0.58.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.24.0 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from apricot-select>=0.6.1->pomegranate) (4.66.1)\n",
      "Collecting nose (from apricot-select>=0.6.1->pomegranate)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=1.0.2->pomegranate) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=1.0.2->pomegranate) (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.9.0->pomegranate) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.9.0->pomegranate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=1.9.0->pomegranate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=1.9.0->pomegranate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from torch>=1.9.0->pomegranate) (2023.9.2)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.43.0->apricot-select>=0.6.1->pomegranate)\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/d4/3d/3f4612c80c1ccfb248df6ff70da33216374b24fc8a17fc84ee0aeab2c900/llvmlite-0.41.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading llvmlite-0.41.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.9.0->pomegranate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from sympy->torch>=1.9.0->pomegranate) (1.3.0)\n",
      "Downloading pomegranate-1.0.3-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.58.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.0-cp311-cp311-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: apricot-select\n",
      "  Building wheel for apricot-select (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apricot-select: filename=apricot_select-0.6.1-py3-none-any.whl size=48766 sha256=1c31a929f5d89c99bbfb78ee251a2b25399ab9d97f6b2ab3b764e42b4bdc20c2\n",
      "  Stored in directory: /Users/joseph/Library/Caches/pip/wheels/ab/bc/fe/cd12c36ddfd92d986d2e8fd49b94286c2dbce74c20da1c2588\n",
      "Successfully built apricot-select\n",
      "Installing collected packages: nose, llvmlite, numba, apricot-select, pomegranate\n",
      "Successfully installed apricot-select-0.6.1 llvmlite-0.41.0 nose-1.3.7 numba-0.58.0 pomegranate-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pomegranate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "PYserq0bzm_N",
   "metadata": {
    "id": "PYserq0bzm_N"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from operator import attrgetter\n",
    "import pandas as pd\n",
    "from sdv.metrics.tabular import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "other_metrics_dict = {\n",
    "    #'BNLikelihood': BNLikelihood, # pomegranate problem might success with python 3.9 and older\n",
    "    #'BNLogLikelihood': BNLogLikelihood, # pomegranate problem might success with python 3.9 and older\n",
    "    #'LogisticDetection': LogisticDetection,\n",
    "    #'SVCDetection': SVCDetection,\n",
    "    #'GMLogLikelihood': GMLogLikelihood,\n",
    "    'CSTest': CSTest, #work this metric first\n",
    "    #'KSTest': KSComplement, #work this metric first\n",
    "    #'ContinuousKLDivergence': ContinuousKLDivergence,\n",
    "    'DiscreteKLDivergence': DiscreteKLDivergence\n",
    "}\n",
    "\n",
    "other_metrics_dict_onlyn = {\n",
    "    #'BNLikelihood': BNLikelihood, # pomegranate problem might success with python 3.9 and older\n",
    "    #'BNLogLikelihood': BNLogLikelihood, # pomegranate problem might success with python 3.9 and older\n",
    "    'LogisticDetection': LogisticDetection,\n",
    "    'SVCDetection': SVCDetection,\n",
    "    'GMLogLikelihood': GMLogLikelihood,\n",
    "    #'CSTest': CSTest, #work this metric first\n",
    "    'KSTest': KSComplement, #work this metric first\n",
    "    'ContinuousKLDivergence': ContinuousKLDivergence,\n",
    "    #'DiscreteKLDivergence': DiscreteKLDivergence\n",
    "}\n",
    "\n",
    "privacy_categorical_metrics_dict = {\n",
    "    'CategoricalCAP': CategoricalCAP,\n",
    "    'CategoricalZeroCAP': CategoricalZeroCAP,\n",
    "    'CategoricalGeneralizedCAP': CategoricalGeneralizedCAP,\n",
    "    'CategoricalKNN': CategoricalKNN,\n",
    "    'CategoricalNB': CategoricalNB,\n",
    "    'CategoricalRF': CategoricalRF,\n",
    "    # 'CategoricalEnsemble': CategoricalEnsemble\n",
    "}\n",
    "\n",
    "privacy_numerical_metrics_dict = {\n",
    "    'NumericalMLP': NumericalMLP,\n",
    "    'NumericalLR': NumericalLR,\n",
    "    'NumericalSVR': NumericalSVR,\n",
    "    # 'NumericalRadiusNearestNeighbor': NumericalRadiusNearestNeighbor # This metrics is too slow, so we will not use.\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "-IHDt39UztMn",
   "metadata": {
    "id": "-IHDt39UztMn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_table(real_data, synthetic_data, numerical_columns, key_fields, sensitive_fields, target_block_size=30): #originally the block size was 100\n",
    "    \"\"\"\n",
    "    The function to create table\n",
    "    :param real_data: The original data\n",
    "    :param synthetic_data: The synthetic data generate by tools, should be a List of pandas.DataFrame\n",
    "    :param numerical_columns: A list of string, telling the function what columns are numerical columns\n",
    "    :param key_fields: The key field that we need to calculate privacy and utility\n",
    "    :param sensitive_fields: The sensitive field that we need to calculate privacy and utility. -> outcomes\n",
    "    :param target_block_size: How many rows in each block, the final result will be average of all blocks\n",
    "    :return: result_n(c)_avg: the numerical(categorical) result for each metrics,\n",
    "    numerical(categorical)_avg: the average of all metrics, total_score: the average of numerical and categorical\n",
    "    \"\"\"\n",
    "    #total_len = len(real_data)\n",
    "    #total_len = total_len // target_block_size * target_block_size # -> why should I divide it by target_block_size?\n",
    "\n",
    "    real_n, real_c = split_table(real_data, numerical_col=numerical_columns)\n",
    "\n",
    "    key_fields_n, key_fields_c, sensitive_fields_n, sensitive_fields_c = get_meta_data(real_n,\n",
    "                                                                                       real_c,\n",
    "                                                                                       key_fields,\n",
    "                                                                                       sensitive_fields)\n",
    "\n",
    "    data_dict_n = {\n",
    "        'real': real_n\n",
    "    }\n",
    "    data_dict_c = {\n",
    "        'real': real_c\n",
    "    }\n",
    "\n",
    "    for i, syn_data in enumerate(synthetic_data):\n",
    "        syn_n, syn_c = split_table(syn_data, numerical_columns)\n",
    "        data_dict_n[f\"level{i}\"] = syn_n\n",
    "        data_dict_c[f\"level{i}\"] = syn_c\n",
    "\n",
    "    data_dict_n = remove_nan_in_numerical(data_dict_n)\n",
    "\n",
    "    meta_data_n = {\n",
    "        'key_fields': key_fields_n,\n",
    "        'sensitive_fields': sensitive_fields_n,\n",
    "    }\n",
    "    meta_data_c = {\n",
    "        'key_fields': key_fields_c,\n",
    "        'sensitive_fields': sensitive_fields_c,\n",
    "    }\n",
    "    metric_list_c = privacy_categorical_metrics_dict.keys()\n",
    "    metric_list_n = privacy_numerical_metrics_dict.keys()\n",
    "\n",
    "    result_n = []\n",
    "    result_c = []\n",
    "    result_n_ot = []\n",
    "    result_c_ot = []\n",
    "\n",
    "    #for index in range(0, total_len, target_block_size):\n",
    "    partial_n = get_part_of_data(data_dict_n, target_block_size,index = 0) # 앞에서 data_dict와 같은 역할\n",
    "    partial_c = get_part_of_data(data_dict_c, target_block_size,index = 0)\n",
    "    partial_real_n = partial_n['real']\n",
    "    partial_real_c = partial_c['real']\n",
    "    partial_n.pop('real')\n",
    "    partial_c.pop('real')\n",
    "\n",
    "\n",
    "    numerical = _create_table(metric_list_n, partial_real_n, partial_n, meta_data_n, mode='n')\n",
    "    print('here')#-> just for debugging\n",
    "    categorical = _create_table(metric_list_c, partial_real_c, partial_c, meta_data_c, mode='c')\n",
    "    print('here')#-> just for debugging\n",
    "    result_n.append(numerical)\n",
    "    result_c.append(categorical)\n",
    "\n",
    "\n",
    "\n",
    "    # starting for privacy\n",
    "    # Assuming you have already defined other_metrics_dict, synthetic_data, and meta_data\n",
    "    # Compute other metrics\n",
    "    computed_metrics_otc = compute_other_metrics(other_metrics_dict, partial_real_c, partial_c)\n",
    "    computed_metrics_otn = compute_other_metrics_n(other_metrics_dict_onlyn, partial_real_n, partial_n)\n",
    "    result_n_ot.append(computed_metrics_otn)\n",
    "    result_c_ot.append(computed_metrics_otc)\n",
    "\n",
    "    # Print or use the computed metrics\n",
    "    for metric_name, metric_value in computed_metrics_otc.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "\n",
    "    for metric_name, metric_value in computed_metrics_otn.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "    #end for privacy\n",
    "\n",
    "\n",
    "\n",
    "    result_n_avg_ot = sum(result_n_ot) / len(result_n_ot)\n",
    "    result_c_avg_ot = sum(result_c_ot) / len(result_c_ot)\n",
    "    numerical_avg_ot = result_n_avg_ot.mean()\n",
    "    numerical_avg_ot['time'] *= len(synthetic_data)\n",
    "    categorical_avg_ot = result_c_avg_ot.mean()\n",
    "    categorical_avg_ot['time'] *= len(synthetic_data)\n",
    "\n",
    "    total_score_ot = (numerical_avg_ot + categorical_avg_ot) / 2\n",
    "\n",
    "\n",
    "\n",
    "    result_n_avg = sum(result_n) / len(result_n)\n",
    "    result_c_avg = sum(result_c) / len(result_c)\n",
    "    numerical_avg = result_n_avg.mean()\n",
    "    numerical_avg['time'] *= len(synthetic_data)\n",
    "    categorical_avg = result_c_avg.mean()\n",
    "    categorical_avg['time'] *= len(synthetic_data)\n",
    "\n",
    "    total_score = (numerical_avg + categorical_avg) / 2\n",
    "\n",
    "    return result_n_avg, result_c_avg, numerical_avg, categorical_avg, total_score, result_n_avg_ot, result_c_avg_ot, numerical_avg_ot, categorical_avg_ot, total_score_ot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "CpzO_CCe5c8v",
   "metadata": {
    "id": "CpzO_CCe5c8v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_other_metrics(metrics_dict, synthetic_data, meta_data):\\n    results = {}\\n    times = {}\\n    for metric_name, metric_class in metrics_dict.items():\\n        metric_instance = metric_class()\\n        metric_value = metric_instance.compute(synthetic_data=synthetic_data, **meta_data)\\n        results[metric_name] = metric_value\\n\\n    return results\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compute_other_metrics(metrics_dict, synthetic_data, meta_data):\n",
    "    results = {}\n",
    "    times = {}\n",
    "    for metric_name, metric_class in metrics_dict.items():\n",
    "        metric_instance = metric_class()\n",
    "        metric_value = metric_instance.compute(synthetic_data=synthetic_data, **meta_data)\n",
    "        results[metric_name] = metric_value\n",
    "\n",
    "    return results\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "UiB9zwWBM-9d",
   "metadata": {
    "id": "UiB9zwWBM-9d"
   },
   "outputs": [],
   "source": [
    "def compute_other_metrics(metrics_dict, _real_data, synthetic_data): # make another create_table just for privacy\n",
    "    global other_metrics_dict\n",
    "    # all_df = {}\n",
    "    # for meta_data in meta_data_list:\n",
    "    result = {}\n",
    "    times = {}\n",
    "    success_metrics = []\n",
    "    for level, data in synthetic_data.items(): # change the name for the level\n",
    "        scores = []\n",
    "        for metrics in metrics_dict:\n",
    "            print(metrics) # just for debugging\n",
    "            _start = time.time()\n",
    "            if metrics not in metrics_dict.keys():\n",
    "                continue\n",
    "            metric = metrics_dict[metrics]\n",
    "            score = metric.compute(real_data=_real_data, synthetic_data=data)\n",
    "            print('score :',score) # just for debugging\n",
    "            scores.append(score)\n",
    "            if metrics not in success_metrics:\n",
    "                success_metrics.append(metrics)\n",
    "                times[metrics] = 0\n",
    "            _end = time.time() - _start\n",
    "            times[metrics] += _end\n",
    "        result[level] = scores\n",
    "    result['time'] = [times[key] for key in success_metrics]\n",
    "    df = pd.DataFrame(result, index=success_metrics)\n",
    "    # df['time'] = times\n",
    "    # all_df[meta_data['sensitive_fields'][0]] = df\n",
    "\n",
    "    print('one table generated')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "J5BLo8D0eUnJ",
   "metadata": {
    "id": "J5BLo8D0eUnJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def compute_other_metrics(other_metrics_dict, real_data, synthetic_data_dict):\n",
    "    \"\"\"\n",
    "    Compute other metrics based on synthetic data and real data.\n",
    "\n",
    "    :param other_metrics_dict: A dictionary of other metrics functions.\n",
    "    :param real_data: The real data used as a reference for metric calculation.\n",
    "    :param synthetic_data_dict: A dictionary where keys represent synthetic data levels, and values are synthetic data.\n",
    "    :return: A DataFrame containing metric scores and execution times.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    times = {}\n",
    "    success_metrics = []\n",
    "\n",
    "    for level, data in synthetic_data_dict.items():\n",
    "        scores = {}\n",
    "        for metric_name, metric_function in other_metrics_dict.items():\n",
    "            print(metric_name)  # Just for debugging\n",
    "            _start = time.time()\n",
    "\n",
    "            # You can directly call the metric function without meta_data\n",
    "            score = metric_function.compute(real_data=real_data, synthetic_data=data)\n",
    "\n",
    "            print('score:', score)  # Just for debugging\n",
    "            scores[metric_name] = score\n",
    "\n",
    "            if metric_name not in success_metrics:\n",
    "                success_metrics.append(metric_name)\n",
    "                times[metric_name] = 0\n",
    "\n",
    "            _end = time.time() - _start\n",
    "            times[metric_name] += _end\n",
    "\n",
    "        result[level] = scores\n",
    "\n",
    "    result['time'] = [times[key] for key in success_metrics]\n",
    "    df = pd.DataFrame(result, index=success_metrics)\n",
    "\n",
    "    print('One table generated for other metrics')  # Just for debugging\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "Q0aWsE5VuEDp",
   "metadata": {
    "id": "Q0aWsE5VuEDp"
   },
   "outputs": [],
   "source": [
    "def compute_other_metrics_n(metrics_dict, _real_data, synthetic_data): #\n",
    "    global other_metrics_dict\n",
    "    # all_df = {}\n",
    "    # for meta_data in meta_data_list:\n",
    "    result = {}\n",
    "    times = {}\n",
    "    success_metrics = []\n",
    "    for level, data in synthetic_data.items(): # change the name for the level\n",
    "        scores = []\n",
    "        for metrics in metrics_dict:\n",
    "            print(metrics) # just for debugging\n",
    "            _start = time.time()\n",
    "            if metrics not in metrics_dict.keys():\n",
    "                continue\n",
    "            metric = metrics_dict[metrics]\n",
    "            score = metric.compute(real_data=_real_data, synthetic_data=data)\n",
    "            print('score :',score) # just for debugging\n",
    "            scores.append(score)\n",
    "            if metrics not in success_metrics:\n",
    "                success_metrics.append(metrics)\n",
    "                times[metrics] = 0\n",
    "            _end = time.time() - _start\n",
    "            times[metrics] += _end\n",
    "        result[level] = scores\n",
    "    result['time'] = [times[key] for key in success_metrics]\n",
    "    df = pd.DataFrame(result, index=success_metrics)\n",
    "    # df['time'] = times\n",
    "    # all_df[meta_data['sensitive_fields'][0]] = df\n",
    "\n",
    "    print('one table generated')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "taBB5amgzxLz",
   "metadata": {
    "id": "taBB5amgzxLz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_meta_data(real_data_n, real_data_c, key_fields, sensitive_fields):\n",
    "    key_fields_c = [key for key in key_fields if key in real_data_c.columns]\n",
    "    key_fields_n = [key for key in key_fields if key in real_data_n.columns]\n",
    "    sensitive_fields_c = [key for key in sensitive_fields if key in real_data_c.columns]\n",
    "    sensitive_fields_n = [key for key in sensitive_fields if key in real_data_n.columns]\n",
    "    return key_fields_n, key_fields_c, sensitive_fields_n, sensitive_fields_c\n",
    "\n",
    "def _create_table(metrics_list, _real_data, synthetic_data_dict: dict, meta_data, mode): #generate the privacy metrics (The colon in synthetic_data_dict: dict is a type hint in Python. It is used to specify the expected type of the synthetic_data_dict parameter.)\n",
    "    global privacy_numerical_metrics_dict, privacy_categorical_metrics_dict\n",
    "    # all_df = {}\n",
    "    # for meta_data in meta_data_list:\n",
    "    result = {}\n",
    "    times = {}\n",
    "    metrics_dict = privacy_numerical_metrics_dict if mode == 'n' else privacy_categorical_metrics_dict\n",
    "    success_metrics = []\n",
    "    for level, data in synthetic_data_dict.items(): # change the name for the level\n",
    "        scores = []\n",
    "        for metrics in metrics_list:\n",
    "            print(metrics) # just for debugging\n",
    "            _start = time.time()\n",
    "            if metrics not in metrics_dict.keys():\n",
    "                continue\n",
    "            metric = metrics_dict[metrics]\n",
    "            score = metric.compute(real_data=_real_data, synthetic_data=data, **meta_data)\n",
    "            print('score :',score) # just for debugging\n",
    "            scores.append(score)\n",
    "            if metrics not in success_metrics:\n",
    "                success_metrics.append(metrics)\n",
    "                times[metrics] = 0\n",
    "            _end = time.time() - _start\n",
    "            times[metrics] += _end\n",
    "        result[level] = scores\n",
    "    result['time'] = [times[key] for key in success_metrics]\n",
    "    df = pd.DataFrame(result, index=success_metrics)\n",
    "    # df['time'] = times\n",
    "    # all_df[meta_data['sensitive_fields'][0]] = df\n",
    "\n",
    "    print('one table generated')\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_table(data_table: pd.DataFrame, numerical_col=None): # for spliting the num and cat\n",
    "    if numerical_col:\n",
    "        numerical_data = data_table[numerical_col]\n",
    "        categorical_data = data_table.drop(numerical_col, axis=1).applymap(str)\n",
    "        return numerical_data, categorical_data\n",
    "\n",
    "    dtype_list = data_table.dtypes.apply(attrgetter('kind'))\n",
    "    numerical_index = []\n",
    "    categorical_index = []\n",
    "    for i, dtype in enumerate(dtype_list):\n",
    "        if dtype == 'f' or dtype == 'i':\n",
    "            numerical_index.append(i)\n",
    "        else:\n",
    "            categorical_index.append(i)\n",
    "    return data_table.iloc[:, numerical_index], data_table.iloc[:, categorical_index]\n",
    "\n",
    "\n",
    "def get_metadata(table: pd.DataFrame):\n",
    "    meta_data_list = []\n",
    "    clm = list(table.columns)\n",
    "    # for i, column in enumerate(clm):\n",
    "    #     m_d = {\n",
    "    #         'key_fields': clm[:i] + clm[i + 1:],\n",
    "    #         'sensitive_fields': [column]\n",
    "    #     }\n",
    "    #     meta_data_list.append(m_d)\n",
    "    index = random.randint(0, len(clm) - 1)\n",
    "    index = [1, 2]\n",
    "    meta_data_list.append({\n",
    "        'key_fields': [clm[i] for i in range(len(clm)) if i not in index],\n",
    "        'sensitive_fields': [clm[i] for i in index]\n",
    "    })\n",
    "    return meta_data_list\n",
    "\n",
    "\n",
    "def remove_nan_in_numerical(numerical_table_dict: dict):\n",
    "    for k, v in numerical_table_dict.items():\n",
    "        numerical_table_dict[k] = v.fillna(0)\n",
    "    return numerical_table_dict\n",
    "\n",
    "\n",
    "def get_part_of_data(table_dict, n, index): # as a result of regarding the for loop above, I fixed the index as 1. 인덱스는 시작점 역할을 하는 것 같음\n",
    "    new_dict = {}\n",
    "    # index = random.randint(0, 14691 - n)\n",
    "    # index = 1\n",
    "    for k, v in table_dict.items():\n",
    "        new_dict[k] = v.iloc[index:index + n, :] #index is the start of the row and index + n is the end of the row\n",
    "        new_dict[k].reset_index(drop=True, inplace=True)\n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JgGlRoPV3vb4",
   "metadata": {
    "id": "JgGlRoPV3vb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "nfAPG388I8Zq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "nfAPG388I8Zq",
    "outputId": "8c7ce17e-13df-4a9e-ed99-523678174f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "float64\n",
      "object\n",
      "object\n",
      "object\n",
      "float64\n",
      "object\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SUBJECT_ID',\n",
       " 'length_of_stay_sum',\n",
       " 'length_of_stay_avg',\n",
       " 'length_of_stay_min',\n",
       " 'length_of_stay_max',\n",
       " 'length_of_stay_rnd',\n",
       " 'Platelet.Count',\n",
       " 'Prothrombin.time',\n",
       " 'WBC',\n",
       " 'Hemoglobin',\n",
       " 'PTT',\n",
       " 'INR',\n",
       " 'Glucose..serum.',\n",
       " 'Hematocrit..serum.',\n",
       " 'Calcium.non.ionized',\n",
       " 'Phosphorous',\n",
       " 'BUN',\n",
       " 'O2.saturation.pulseoxymetry',\n",
       " 'Admission.Weight..Kg.',\n",
       " 'Heart.Rate',\n",
       " 'HCO3..serum.',\n",
       " 'Anion.gap',\n",
       " 'Potassium..serum.',\n",
       " 'Chloride..serum.',\n",
       " 'Sodium..serum.',\n",
       " 'Creatinine',\n",
       " 'Magnesium',\n",
       " 'Respiratory.Rate']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=[]\n",
    "org = pd.read_csv('data/mimi3.csv')\n",
    "(org.dtypes)\n",
    "columns = list(org.columns)\n",
    "for col in columns:\n",
    "  print(org[col].dtypes)\n",
    "  if org[col].dtypes != 'object':\n",
    "    col_list.append(col)\n",
    "del col_list[0]\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "pTomFYqF6djQ",
   "metadata": {
    "id": "pTomFYqF6djQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUBJECT_ID',\n",
       " 'length_of_stay_sum',\n",
       " 'length_of_stay_avg',\n",
       " 'length_of_stay_min',\n",
       " 'length_of_stay_max',\n",
       " 'length_of_stay_rnd',\n",
       " 'Platelet.Count',\n",
       " 'Prothrombin.time',\n",
       " 'WBC',\n",
       " 'Hemoglobin',\n",
       " 'PTT',\n",
       " 'INR',\n",
       " 'Glucose..serum.',\n",
       " 'Hematocrit..serum.',\n",
       " 'Calcium.non.ionized',\n",
       " 'Phosphorous',\n",
       " 'BUN',\n",
       " 'O2.saturation.pulseoxymetry',\n",
       " 'Admission.Weight..Kg.',\n",
       " 'Heart.Rate',\n",
       " 'HCO3..serum.',\n",
       " 'Anion.gap',\n",
       " 'Potassium..serum.',\n",
       " 'Chloride..serum.',\n",
       " 'Sodium..serum.',\n",
       " 'Creatinine',\n",
       " 'Magnesium',\n",
       " 'Respiratory.Rate']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "YXAaoaS9pfqv",
   "metadata": {
    "id": "YXAaoaS9pfqv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/homebrew/Cellar/ipython/8.16.1/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/joseph/Library/Python/3.11/lib/python/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/opt/six/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "Ok2gdo57xSWh",
   "metadata": {
    "id": "Ok2gdo57xSWh"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aCxsObCbsFsj",
   "metadata": {
    "id": "aCxsObCbsFsj"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(org)\n",
    "text_sequences = tokenizer.texts_to_sequences(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "Ts2uIHPtr8nU",
   "metadata": {
    "id": "Ts2uIHPtr8nU"
   },
   "outputs": [],
   "source": [
    "word_vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "i-6ekbFQxMMB",
   "metadata": {
    "id": "i-6ekbFQxMMB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serum': 1,\n",
       " 'length': 2,\n",
       " 'of': 3,\n",
       " 'stay': 4,\n",
       " 'gcs': 5,\n",
       " 'response': 6,\n",
       " 'rate': 7,\n",
       " 'unnamed': 8,\n",
       " '0': 9,\n",
       " 'subject': 10,\n",
       " 'id': 11,\n",
       " 'sum': 12,\n",
       " 'avg': 13,\n",
       " 'min': 14,\n",
       " 'max': 15,\n",
       " 'rnd': 16,\n",
       " 'platelet': 17,\n",
       " 'count': 18,\n",
       " 'prothrombin': 19,\n",
       " 'time': 20,\n",
       " 'wbc': 21,\n",
       " 'hemoglobin': 22,\n",
       " 'ptt': 23,\n",
       " 'verbal': 24,\n",
       " 'language': 25,\n",
       " 'motor': 26,\n",
       " 'eye': 27,\n",
       " 'opening': 28,\n",
       " 'inr': 29,\n",
       " 'religion': 30,\n",
       " 'patient': 31,\n",
       " 'location': 32,\n",
       " 'race': 33,\n",
       " 'glucose': 34,\n",
       " 'gender': 35,\n",
       " 'hematocrit': 36,\n",
       " 'calcium': 37,\n",
       " 'non': 38,\n",
       " 'ionized': 39,\n",
       " 'phosphorous': 40,\n",
       " 'bun': 41,\n",
       " 'o2': 42,\n",
       " 'saturation': 43,\n",
       " 'pulseoxymetry': 44,\n",
       " 'admission': 45,\n",
       " 'weight': 46,\n",
       " 'kg': 47,\n",
       " 'heart': 48,\n",
       " 'hco3': 49,\n",
       " 'anion': 50,\n",
       " 'gap': 51,\n",
       " 'potassium': 52,\n",
       " 'chloride': 53,\n",
       " 'sodium': 54,\n",
       " 'creatinine': 55,\n",
       " 'magnesium': 56,\n",
       " 'respiratory': 57,\n",
       " 'text': 58}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "F7f8a0r74Cxr",
   "metadata": {
    "id": "F7f8a0r74Cxr"
   },
   "outputs": [],
   "source": [
    "ob_col = []\n",
    "for col in columns:\n",
    "  if org[col].dtypes == 'object':\n",
    "    ob_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ST7M6_x4T0j",
   "metadata": {
    "id": "2ST7M6_x4T0j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCS...Verbal.Response',\n",
       " 'Language',\n",
       " 'GCS...Motor.Response',\n",
       " 'GCS...Eye.Opening',\n",
       " 'Religion',\n",
       " 'Patient.Location',\n",
       " 'Race',\n",
       " 'Gender',\n",
       " 'TEXT']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "DoYvZbXc5PVS",
   "metadata": {
    "id": "DoYvZbXc5PVS"
   },
   "outputs": [],
   "source": [
    "for col in ob_col:\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(col[0])\n",
    "  first_obj = tokenizer.texts_to_sequences(col[0])\n",
    "  if len(first_obj) > 5 :\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "QnkN9xRi8L1h",
   "metadata": {
    "id": "QnkN9xRi8L1h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 [    1     2     3 ... 18537 18538 18539]\n",
      "SUBJECT_ID [   23    36    85 ... 99923 99938 99982]\n",
      "length_of_stay_sum [12.26458333 31.09166667 12.82361111 ... 17.87291667 17.75\n",
      " 23.01875   ]\n",
      "length_of_stay_avg [ 6.13229167 10.36388889  6.41180556 ...  8.93645833 17.75\n",
      "  7.67291667]\n",
      "length_of_stay_min [ 5.49652778  8.28125     4.85763889 ... 35.65486111  7.80416667\n",
      " 17.75      ]\n",
      "length_of_stay_max [ 6.76805556 12.73680556  7.96597222 ... 35.65486111 17.75\n",
      " 10.07569444]\n",
      "length_of_stay_rnd [ 5.49652778 12.73680556  4.85763889 ... 35.65486111 17.75\n",
      "  6.81458333]\n",
      "Platelet.Count [ 179.    146.     16.    121.    101.    166.    157.15  102.    175.13\n",
      "  150.13  202.    112.    190.39  138.02   37.    152.    137.46  314.\n",
      "  100.    247.    183.98  129.    192.63  153.39  143.2   186.32  138.62\n",
      "  151.42  141.    153.83  155.    165.47  133.    150.79  302.    178.84\n",
      "  162.44  154.84  104.    224.    142.84  248.    144.43   41.    241.\n",
      "  195.68  191.09  161.7   154.08  175.    154.73  226.21  131.93  257.\n",
      "  167.02  140.82  162.46  177.    178.27  111.    437.    205.    151.02\n",
      "   19.    138.    153.    200.    175.4   164.12  163.67  268.    118.\n",
      "  128.    164.8   171.31  189.    168.15  156.77  106.    105.    192.78\n",
      "  194.74  308.    143.    158.33  179.47  138.53  131.42  292.    204.\n",
      "  287.    150.31  131.46  131.87  151.9   158.    129.06  203.76  171.29\n",
      "  168.22  146.01  206.    171.64  146.6   129.72  198.1   179.14  173.\n",
      "  123.    172.    132.     66.    198.    164.28  119.    263.    331.\n",
      "  159.76  113.    131.    180.34  160.43  231.    174.73  169.    151.05\n",
      "  201.    175.86  187.    154.96  134.72  141.86  134.03  162.16  148.95\n",
      "  155.01  445.    141.56  163.    181.44  168.33  127.     82.    290.\n",
      "   74.    161.4   142.    155.32  154.79  220.    160.57  135.    156.47\n",
      "  344.    561.    139.    153.98  151.36  201.08  348.    138.3   151.\n",
      "  139.43  141.3   191.    139.94  197.82  126.15  187.9   117.    130.\n",
      "  191.39  192.47  355.    177.8   176.    283.    154.17  246.    229.\n",
      "  157.    166.57  158.86  230.    159.    144.13  145.69  217.    144.\n",
      "  103.    134.7   204.84  160.07  181.    174.05  211.    195.63  449.\n",
      "  132.37  126.    188.    109.    146.3   306.    184.    215.    185.94\n",
      "  183.    327.    146.58  147.    232.    110.    227.    222.    197.76\n",
      "  137.45  167.24  255.    158.91  108.    144.23  168.53  422.    219.\n",
      "  168.05  143.02  132.16  116.    152.19  164.    186.    153.4   129.32\n",
      "  143.11  144.47   64.    144.6    77.    146.19  226.    145.57  170.01\n",
      "  176.86  170.08  125.77  171.25  163.74  228.     94.    136.    281.\n",
      "  410.    170.97  221.38  288.    264.    180.    338.    155.94  315.\n",
      "   46.    261.    158.14  143.14  175.36  149.6    68.    122.24  114.\n",
      "  198.57  172.01  143.21  133.92  136.49  163.54  209.    181.92  244.\n",
      "  186.3   134.39  125.6   353.    126.48  145.3   152.62  282.    163.97\n",
      "  160.69  151.75  137.    177.04  155.69  172.15  133.84  311.    124.49\n",
      "  193.    145.65  155.68  161.    107.    148.08  239.    144.28  148.5\n",
      "   10.    419.     73.    199.    115.    151.18  159.96  173.2   184.68\n",
      "  140.28  131.49  172.79  129.64  139.91  143.82   28.    212.1   225.\n",
      "  163.48  203.     91.    436.    126.06  237.    156.    254.    137.75\n",
      "  163.21  275.    187.92  277.    177.67  168.72  148.58  129.69  149.59\n",
      "  120.    140.33  252.    133.75  131.38  157.51  215.56  138.19  208.\n",
      "  141.02  131.3   133.54  270.    128.87  169.28  249.    134.95  165.65\n",
      "  152.48  155.85  295.    165.    212.    128.98  158.59  158.45  160.\n",
      "  150.    162.12  137.73  154.36  126.61  154.72  173.63  136.09  447.\n",
      "  140.06  125.05  142.81  149.4   136.2   223.    139.97  146.42  198.15\n",
      "  213.    143.15  152.46  271.    149.    196.99  161.32  169.18  130.43\n",
      "  189.43  260.    135.6   142.86  163.5   136.84  514.    148.    159.73\n",
      "  151.28  124.35  180.18  124.    142.07  148.39  171.    154.03  141.19\n",
      "  177.68  129.29  149.71  132.62  172.13  164.96  174.    144.7   134.38\n",
      "  178.66  141.98  127.62  154.64  152.3   140.61  119.36  125.    140.\n",
      "  193.25  130.61  163.63  173.58  161.67  203.99  140.88  243.    162.\n",
      "  175.27  177.08  154.53  122.    143.54  207.    131.85  152.74  126.22\n",
      "  180.12   47.    194.    135.74  145.12  183.72  177.9   154.    262.\n",
      "  196.    140.64  144.44  125.88  156.57  151.59  155.91  148.66  158.22\n",
      "  161.41  160.42   14.    187.34  148.76  174.78  157.36  135.15  150.5\n",
      "  297.    134.07  164.36  159.04  171.36  133.49  133.65  137.68  138.44\n",
      "  122.65  122.07  159.28  158.4   170.99  141.79  150.88  145.4   195.93\n",
      "  128.93  133.12  155.18  177.55  217.48  180.14  285.    138.5   174.15\n",
      "   25.    178.28  163.39  136.95  142.46  132.06  143.93  190.    134.\n",
      "  154.65  182.    140.65  167.96  127.94  139.53  131.34  170.87  138.84\n",
      "  130.23  178.35  266.    147.39  132.29  147.37  163.15  184.08  176.39\n",
      "  406.    171.17  411.    233.    189.22  144.3   131.82  189.15  149.24\n",
      "  122.22  152.16  483.    167.21  240.67  524.    166.97   20.    179.23\n",
      "  153.37  181.64  133.89  150.63  272.    298.    158.61  138.95  163.26\n",
      "  149.19  147.19  125.7   158.75  133.15  417.     58.    141.77  164.07\n",
      "  183.78  153.24  134.5   139.19  128.08  168.93  216.    159.45  182.71\n",
      "  145.    134.64  163.35  383.    346.    129.23  299.    193.63  163.66\n",
      "  143.67  158.95  136.57   13.    165.01  197.    171.16  139.09  147.62\n",
      "  557.    171.07  157.19  220.72  142.15  134.43  137.38  127.89  163.56\n",
      "  178.33  170.    161.03  144.41  138.13  149.7   142.65  153.89  149.86\n",
      "   52.    158.43  185.1   136.8   182.35  145.74  164.67  133.77  134.04\n",
      "  165.14  174.83  193.29  165.83  170.45  171.52  143.47  278.    250.\n",
      "  139.22  132.89  191.89  138.06  141.85  142.53  143.16  174.04  160.14\n",
      "  154.57  284.     22.    178.    142.08  138.03  195.    140.55  149.39\n",
      "  188.96  137.18  141.49  157.8   621.    156.76  167.    138.09  286.\n",
      "  158.37   11.    145.19  133.51  127.31  131.45  130.13  123.69  161.01\n",
      "  136.61 1000.    136.23  132.75  121.21  161.12  276.    169.59  149.03\n",
      "  188.87  185.    129.08  164.65  128.79  141.09  128.81  139.56  151.74\n",
      "  234.    136.92  494.    650.    144.61  153.97  181.97  124.51  171.8\n",
      "  162.14  170.29  128.76  133.41  196.24  168.31   48.    125.62  126.27\n",
      "  155.43  137.44  125.25  192.    140.22  132.79  310.    183.5   151.94\n",
      "  120.86  150.7   131.53  155.24  218.    119.91  186.35  157.38  151.76\n",
      "  161.51  214.    131.2   166.41  162.09  256.    111.75  139.36  119.76\n",
      "  178.47  141.54  265.    183.16  161.25  135.71  157.24  141.99  176.5\n",
      "  326.    141.58  146.27  178.3   133.29  142.59  141.87  145.2   157.4\n",
      "  238.    205.37  154.97  158.04  140.83  138.45  188.1   245.    139.75\n",
      "  155.55  171.75  412.    149.22  142.68  159.24  162.25  212.06  152.92\n",
      "  274.     63.    152.99  124.52  144.92  159.69  183.94  155.52  161.34\n",
      "  165.33  166.24  179.83  165.8   152.6   143.48  139.77  235.    155.09\n",
      "  175.89  157.6   130.62  133.19  135.7   368.    296.    153.05  128.57\n",
      "  476.    303.    124.78  159.79  148.44  242.    168.     15.    336.\n",
      "  139.41  141.18  253.    131.75   78.    126.46 1029.    138.91  152.35\n",
      "  127.34  210.    477.    135.24  589.    289.     42.    304.    330.\n",
      "  162.43  167.11  337.    151.1   131.33  371.    329.     32.    236.\n",
      "  139.03   34.    169.01  143.27  267.    251.    120.03   75.    128.75\n",
      "  418.   1070.     84.     18.    142.09  158.49  145.5   508.    453.\n",
      "  150.35  139.42  127.78  130.08  313.    423.    323.    367.    136.02\n",
      "  128.19  273.     55.     49.    127.73   69.   1074.    294.    127.86\n",
      "  142.3   240.    149.49  316.    325.    111.65  123.75  471.   1087.\n",
      " 1033.    333.    301.   1027.     35.   1034.     21.    350.   1001.\n",
      "   31.   1019.     26.    319.   1032.   1047.   1245.    429.    259.\n",
      " 1117.     39.    221.    491.    269.     72.    359.   1002.     51.\n",
      "   24.   1102.   1013.    339.    393.    280.    401.   1069.     33.\n",
      " 1037.     60.   1039.    340.   1049.     27.   1040.    395.    293.\n",
      " 1006.    357.     12.    364.     29.    342.   1129.    362.     54.\n",
      " 1053.      0.   1009.    627.    363.    415.     44.   1007.  ]\n",
      "Prothrombin.time [ 12.3    14.2    13.7    10.7    13.6    27.2    16.234  11.5    24.943\n",
      "  16.352  15.2    15.     12.2    13.     15.996  15.725  15.9    15.1\n",
      "  15.844  24.5    12.6    17.38   16.276  16.436  16.115  23.834  15.868\n",
      "  16.169  11.6    15.923  16.1    17.416  12.4    16.198  13.2    15.767\n",
      "  18.1    15.709  16.528  11.4    13.3    15.769  13.4    19.     18.675\n",
      "  14.8    32.786  24.562  16.709  16.36   15.388  22.9    15.431  16.934\n",
      "  15.556  16.73   15.52   15.614  16.7    21.9    15.548  16.6    12.9\n",
      "  11.8    17.42   15.427  22.6    15.396  15.402  15.464  15.344  16.181\n",
      "  17.634  13.8    13.5    15.476  29.5    16.13   30.97   17.4    16.867\n",
      "  15.584  15.625  15.81   12.1    15.603  15.469  15.65   15.425  16.004\n",
      "  16.792  15.508  15.422  16.642  16.573  14.5    15.78   15.3    15.4\n",
      "  12.5    15.284  16.     30.3    15.635  14.4    16.08   22.67   10.8\n",
      "  15.617  11.9    16.817  15.744  16.325  17.128  16.333  16.68   15.377\n",
      "  16.518  15.57   10.9    16.801  19.647  23.7    14.1    17.     13.9\n",
      "  17.387  20.82   15.758  15.778  16.597  16.505  24.715  14.6    24.922\n",
      "  11.3    15.714  24.105  15.598  15.571  16.839  18.524  12.7    18.263\n",
      "  15.437  15.872  16.556  19.7    11.1    10.6    18.754  16.066  16.815\n",
      "  20.7    13.1    15.858  26.8    16.332  14.9    16.575  16.566  15.295\n",
      "  15.71   14.     14.888  16.969  17.331  18.342  16.655  16.3    15.636\n",
      "  23.6    15.8    15.975  17.8    12.     18.6    15.401  17.7    19.925\n",
      "  10.3    12.8    38.377  15.367  16.644  15.266  18.523  15.559  16.715\n",
      "  15.7    23.3    14.7    16.5   129.     15.596  15.479  15.375  15.22\n",
      "  15.749  17.82   15.721  21.075  15.458 150.     15.847  42.8    15.626\n",
      "  15.988  21.796  16.908  29.6    16.2    14.553  18.2    15.228  25.532\n",
      "  27.4    13.69   15.6    17.906  24.9    22.985  17.383  15.535  19.9\n",
      "  16.561  15.58   16.372  15.523  25.6    18.026  16.4    15.815  28.072\n",
      "  17.081  15.403  15.335  16.768  19.666  14.96   16.775  23.5    15.47\n",
      "  15.262  15.534  16.711  15.433  22.215  15.604  15.699  24.439  16.674\n",
      "  17.524  15.415  18.717  15.88   17.768  15.727  15.694  15.399  14.867\n",
      "  10.1    15.414  17.2    15.585  20.2    22.867  15.45   15.438  15.674\n",
      "  15.797  14.627  15.735  15.543  15.563  23.2    15.579  18.     18.3\n",
      "  15.382  18.5    17.3    16.778  17.05   32.1    15.668  17.209  15.521\n",
      "  37.1    15.616  15.874  16.537  16.009  16.616  15.722  15.5    15.151\n",
      "  15.42   15.445  27.732  10.2    15.806  10.4    16.856  15.416  22.3\n",
      "  14.767  15.655  15.348  16.8    17.1    15.234  16.038  15.536  15.324\n",
      "  18.343  17.9    15.566  16.9    15.757  17.706  15.506  15.214  20.35\n",
      "  15.61   16.535  15.64   17.052  15.801  16.576  28.8    14.74   16.691\n",
      "  15.804  16.347  15.884  19.715  25.998  16.524  15.629  16.549  15.46\n",
      "  15.542  15.274  15.502  15.452  15.152  16.634  15.432  36.5    15.455\n",
      "  16.638  16.572  10.5    22.889  16.747  16.598  16.295  14.771  15.572\n",
      "  14.54   17.442  31.9    15.678  23.255  22.804  10.     15.349  15.467\n",
      "  16.901  26.281  15.895  15.97   15.876  15.827  15.306  24.7    14.94\n",
      "  16.175  15.509  16.434  17.266  26.993  15.66   15.736  15.487  15.697\n",
      "  17.294  16.851  15.643  16.485  19.6    16.985  11.     15.492  16.331\n",
      "  16.127  15.189  15.199  15.084  15.652  15.334  15.544  20.23   15.565\n",
      "  15.84   18.191  16.656  14.697  15.37   19.726  23.601  15.881  20.3\n",
      "  22.543  16.873  14.3    16.088  15.491  15.524  15.263  30.6    31.\n",
      "  14.75   14.621  15.628  15.875  22.     16.312  18.016  25.1    16.649\n",
      "  16.647  16.46   37.4    15.315  15.658  15.647  15.582  16.516  14.898\n",
      "  15.358  16.077  15.463  16.414  14.717  14.981  15.442 119.2    16.797\n",
      "  23.645  15.484  15.362  15.406  15.734  15.482  11.7    18.892  15.459\n",
      "  17.576  11.2    15.168  14.187  15.882  15.528  15.663  15.695  17.916\n",
      "  18.9    25.675  18.75   15.513  19.209  18.249  15.546  15.29   15.146\n",
      "  16.51   15.934  15.555  15.453  15.601  15.398  15.292  15.179  17.587\n",
      "  17.6    15.574  15.462  16.493  15.526  16.425  14.653  16.829  15.507\n",
      "  19.8    17.478  15.593  15.223  15.494  15.141  31.5    17.213  26.017\n",
      "  15.665  15.242  15.516  16.606  15.595  15.619  15.552  15.303  15.488\n",
      "  15.716  18.057  16.189  20.807  15.522  23.     26.416  18.171  24.4\n",
      "  15.296  15.683  15.162  15.486  26.015  15.473  15.267  15.419  26.2\n",
      "  14.661  24.722  15.737  21.814  15.531  16.793  15.412  15.654  27.1\n",
      "  16.156  15.393  17.856  16.391  15.549  16.494  15.518  15.188  16.503\n",
      "  15.498  31.064  17.999  17.436  16.526  18.32   24.1    15.356  15.337\n",
      "  18.132  17.345  24.504  22.1    15.418  16.705  18.4    16.931  15.755\n",
      "  16.144  15.715  17.698  28.7    15.294  15.133  14.544  15.503  16.678\n",
      "  25.8    15.373  15.606  14.664  15.483  15.576  16.483  15.281  15.465\n",
      "  19.817  18.311  14.669  16.311  17.654  17.444  17.184  15.608  15.538\n",
      "  14.722  17.629  15.702  14.82   16.762  15.448  14.609  16.665  14.964\n",
      "  15.657  16.77   14.818  15.717  15.569  25.158  26.5    15.43   16.899\n",
      "  18.143  17.961  18.044  14.811  19.2   106.3    15.322  15.69   16.094\n",
      "  37.9    16.661  15.384  16.928  15.41   15.443  15.618  15.611  16.092\n",
      "  59.1    15.441  15.361  16.796  15.238  15.649  17.672  16.557  16.916\n",
      "  19.619  23.523  15.577  15.515  24.     15.689  15.408  15.378  25.201\n",
      "  15.505  16.28   21.922  15.564  15.851  14.563  15.615  15.656  23.363\n",
      "  21.621  14.698  14.57   15.474  17.481  16.539  23.643  17.692  28.5\n",
      "  18.807  21.7    23.942  15.365  14.581  24.381  16.61   18.7    15.409\n",
      "  14.728  19.865  28.66   15.24   15.718  16.559  15.641  16.727  15.676\n",
      "  20.756  19.142  16.043  14.932  15.775  21.471  15.762  26.4    16.624\n",
      "  15.318  15.686  16.457  15.545  16.699  16.466  20.1    15.35   17.5\n",
      " 103.2    19.394  15.383  16.849  14.735  16.888  18.949  21.     15.793\n",
      "  15.475  22.696  15.439  15.812  15.457  17.908 114.2   110.4    21.4\n",
      "  21.5   108.1   131.3    19.5    26.9    14.25   13.581  19.3    13.767\n",
      "  21.6    20.5    13.557  18.8    26.7    25.2    13.567  21.3   103.1\n",
      "  19.1  ]\n",
      "WBC [1.48000e+01 1.03000e+01 8.30000e+00 1.02000e+01 1.04000e+01 6.30000e+00\n",
      " 1.09550e+01 1.01059e+01 1.23380e+01 1.01000e+01 1.06000e+01 3.80000e+00\n",
      " 1.23000e+01 1.18270e+01 1.19970e+01 4.20000e+01 1.00000e+01 1.23990e+01\n",
      " 1.15000e+01 2.20000e+00 1.30000e+01 1.70000e+00 1.25260e+01 1.08790e+01\n",
      " 1.16190e+01 1.11529e+01 9.33490e+00 1.13660e+01 1.08630e+01 1.85000e+01\n",
      " 1.10780e+01 1.58000e+01 1.15830e+01 1.06610e+01 6.00000e+00 1.10910e+01\n",
      " 1.03859e+01 1.00730e+01 1.08640e+01 8.10000e+00 1.09000e+01 1.10680e+01\n",
      " 1.19000e+01 1.08320e+01 1.05949e+01 1.10090e+01 1.17710e+01 5.80000e+00\n",
      " 1.10490e+01 1.08170e+01 1.08420e+01 6.60000e+00 9.92500e+00 1.11330e+01\n",
      " 1.18120e+01 1.00830e+01 1.18000e+01 1.21000e+01 1.09860e+01 3.69000e+01\n",
      " 1.05000e+01 1.10290e+01 1.05290e+01 1.10400e+01 4.40000e+00 2.97000e+01\n",
      " 4.10000e+00 1.10210e+01 1.14000e+01 1.08810e+01 1.03970e+01 1.16530e+01\n",
      " 1.10000e+01 9.32800e+00 9.91000e+00 1.08000e+01 7.60000e+00 1.03580e+01\n",
      " 1.04280e+01 1.03870e+01 1.08360e+01 1.74000e+01 1.13000e+01 1.06140e+01\n",
      " 1.08410e+01 9.91800e+00 1.18650e+01 1.12250e+01 1.00740e+01 1.06740e+01\n",
      " 1.08590e+01 1.12480e+01 9.69900e+00 1.12200e+01 9.61500e+00 9.11290e+00\n",
      " 1.11000e+01 2.10000e+01 1.90000e+01 8.70000e+00 7.00000e+00 1.01929e+01\n",
      " 1.83000e+01 1.41000e+01 6.20000e+00 9.80400e+00 1.30000e+00 1.29000e+01\n",
      " 9.10700e+00 9.62700e+00 1.07000e+01 1.02650e+01 4.60000e+00 1.05960e+01\n",
      " 1.10220e+01 1.01730e+01 9.31900e+00 1.00130e+01 1.04200e+01 1.99000e+01\n",
      " 1.02649e+01 1.05210e+01 1.10020e+01 8.40000e+00 1.03030e+01 7.40000e+00\n",
      " 1.06340e+01 9.81290e+00 1.16000e+01 1.90000e-01 1.28000e+01 8.90000e+00\n",
      " 1.01719e+01 9.61600e+00 1.08480e+01 1.03379e+01 1.45000e+01 1.05610e+01\n",
      " 9.72890e+00 1.43000e+01 1.36000e+01 4.30000e+00 1.06649e+01 7.59880e+00\n",
      " 9.89900e+00 1.15480e+01 5.70000e+00 1.06370e+01 9.57400e+00 9.28990e+00\n",
      " 9.79200e+00 9.85700e+00 1.20000e+01 5.30000e+00 8.77600e+00 8.62300e+00\n",
      " 9.53700e+00 6.50000e+00 1.04480e+01 1.33000e+01 1.50000e+01 5.20000e+00\n",
      " 1.00150e+01 1.05979e+01 1.05970e+01 1.17000e+01 1.10750e+01 1.03940e+01\n",
      " 1.11290e+01 9.48200e+00 1.06330e+01 8.97300e+00 1.61000e+01 1.04090e+01\n",
      " 1.12490e+01 1.37000e+01 1.89000e+01 1.04750e+01 1.40000e+01 1.47000e+01\n",
      " 1.07070e+01 3.38000e+01 9.70000e+00 7.70000e+00 2.49000e+01 1.05029e+01\n",
      " 4.50000e+00 5.90000e+00 1.12000e+01 3.00000e-01 1.01750e+01 1.02999e+01\n",
      " 1.13020e+01 9.35290e+00 1.07040e+01 1.05600e+01 1.50000e+00 3.14000e+01\n",
      " 4.90000e+00 1.16270e+01 1.12020e+01 1.05980e+01 3.40000e+00 1.02060e+01\n",
      " 1.51000e+01 9.61690e+00 1.05920e+01 1.02079e+01 9.69490e+00 8.20000e+00\n",
      " 1.80000e+00 1.12670e+01 9.20000e+00 1.06870e+01 1.90000e+00 1.01519e+01\n",
      " 1.00490e+01 1.00770e+01 6.40000e+00 9.13690e+00 1.01910e+01 1.00159e+01\n",
      " 1.02899e+01 6.70000e+00 1.80000e+01 4.80000e+00 1.00930e+01 2.04000e+01\n",
      " 9.48470e+00 7.30000e+00 5.40000e+00 1.00300e+01 1.04550e+01 1.03630e+01\n",
      " 9.25000e+00 1.09220e+01 2.50000e+00 1.03620e+01 9.36770e+00 9.49000e+00\n",
      " 1.11610e+01 1.13220e+01 9.86190e+00 1.17870e+01 8.52100e+00 2.02000e+01\n",
      " 9.58400e+00 1.06070e+01 1.03480e+01 1.40000e+00 1.08330e+01 1.10500e+01\n",
      " 9.99800e+00 1.02450e+01 1.08140e+01 2.60000e+00 8.20850e+00 1.00220e+01\n",
      " 8.59090e+00 1.08280e+01 1.69000e+01 1.19070e+01 1.06020e+01 1.04990e+01\n",
      " 9.72000e+00 9.80800e+00 9.82390e+00 1.49000e+01 1.59000e+01 6.90000e+00\n",
      " 7.20000e+00 2.00000e+00 5.50000e+00 1.03840e+01 1.75000e+01 8.60280e+00\n",
      " 5.60000e+00 1.15100e+01 1.05830e+01 1.07060e+01 1.06450e+01 1.06950e+01\n",
      " 1.11840e+01 9.81100e+00 1.09140e+01 1.53000e+01 1.03900e+01 1.73000e+01\n",
      " 4.00000e+00 1.07760e+01 1.60000e+01 1.01840e+01 1.22000e+01 8.80700e+00\n",
      " 1.44000e+01 1.32000e+01 1.01310e+01 8.73400e+00 9.80500e+00 1.01600e+01\n",
      " 1.11450e+01 1.07090e+01 3.70000e+00 9.96800e+00 1.06110e+01 1.05690e+01\n",
      " 9.42300e+00 7.98690e+00 1.02680e+01 1.04170e+01 2.10000e+00 1.07030e+01\n",
      " 1.08580e+01 1.10430e+01 9.86600e+00 1.16030e+01 8.90100e+00 9.96900e+00\n",
      " 9.79100e+00 1.06760e+01 1.64000e+01 1.09920e+01 9.97800e+00 1.04549e+01\n",
      " 3.30000e+00 1.14320e+01 1.34000e+01 1.03830e+01 1.07300e+01 1.08870e+01\n",
      " 1.14850e+01 9.47700e+00 1.04640e+01 1.87000e+01 1.01270e+01 3.00000e+00\n",
      " 1.11540e+01 1.07470e+01 1.17090e+01 1.13470e+01 1.05090e+01 9.38400e+00\n",
      " 1.01330e+01 3.90000e+00 1.01180e+01 1.04799e+01 1.00440e+01 1.06990e+01\n",
      " 1.10830e+01 1.10540e+01 7.80000e+00 1.00780e+01 1.56000e+01 9.86800e+00\n",
      " 9.91190e+00 1.05260e+01 1.05520e+01 1.07020e+01 1.06540e+01 9.00000e-01\n",
      " 1.00000e+00 9.81690e+00 1.16480e+01 1.08200e+01 5.10000e+00 1.02850e+01\n",
      " 0.00000e+00 1.05060e+01 1.05160e+01 1.12600e+01 1.25000e+01 1.05640e+01\n",
      " 1.01560e+01 8.21970e+00 1.17140e+01 1.08920e+01 9.19470e+00 1.03210e+01\n",
      " 1.04890e+01 9.54900e+00 1.06900e+01 4.70000e+00 1.27000e+01 1.10280e+01\n",
      " 7.50000e+00 9.88300e+00 1.07350e+01 1.02249e+01 1.10700e+01 1.63000e+01\n",
      " 1.04310e+01 8.83670e+00 1.12390e+01 1.31000e+01 9.23790e+00 9.98500e+00\n",
      " 1.03690e+01 1.10240e+01 1.10600e+01 1.07500e+01 1.04400e+01 9.80000e+00\n",
      " 9.20800e+00 1.11750e+01 1.05950e+01 1.09540e+01 9.94200e+00 8.50000e+00\n",
      " 1.05490e+01 1.08750e+01 1.05180e+01 1.05300e+01 3.60000e+00 1.02310e+01\n",
      " 9.05800e+00 1.07200e+01 1.05360e+01 1.18510e+01 7.00000e-01 1.07560e+01\n",
      " 8.95600e+00 7.45380e+00 8.12200e+00 1.07920e+01 1.95000e+01 1.38000e+01\n",
      " 1.19520e+01 8.49490e+00 1.14300e+01 2.90000e+00 1.19230e+01 1.04700e+01\n",
      " 8.60000e+00 1.08110e+01 1.11470e+01 1.07430e+01 1.02710e+01 8.95500e+00\n",
      " 2.53000e+01 1.21950e+01 9.47000e+00 1.08190e+01 1.09320e+01 1.04970e+01\n",
      " 1.07980e+01 1.12810e+01 1.01050e+01 1.06390e+01 1.37390e+01 9.83200e+00\n",
      " 9.65200e+00 9.16700e+00 1.07860e+01 1.09200e+01 1.02960e+01 1.00350e+01\n",
      " 1.02640e+01 8.74190e+00 1.16980e+01 1.08440e+01 1.02160e+01 1.13440e+01\n",
      " 9.93790e+00 1.16810e+01 9.73700e+00 1.08340e+01 1.06470e+01 1.02770e+01\n",
      " 1.10160e+01 1.04030e+01 9.55700e+00 9.90300e+00 1.52000e+01 1.82000e+01\n",
      " 2.69000e+01 7.65490e+00 1.00880e+01 1.05240e+01 9.53600e+00 1.01920e+01\n",
      " 1.07710e+01 1.16160e+01 1.00800e+01 1.11760e+01 1.09670e+01 9.53000e+00\n",
      " 1.04350e+01 1.03020e+01 1.08400e+01 1.00000e-01 1.05860e+01 1.15340e+01\n",
      " 1.77000e+01 1.04930e+01 1.08820e+01 1.06290e+01 1.08800e+01 1.08760e+01\n",
      " 1.10420e+01 1.09750e+01 2.20000e+01 1.06090e+01 9.93300e+00 1.11240e+01\n",
      " 1.01080e+01 1.04360e+01 9.25800e+00 9.07080e+00 1.04010e+01 1.24000e+01\n",
      " 1.07460e+01 9.77100e+00 1.00180e+01 1.15630e+01 1.04300e+01 9.82500e+00\n",
      " 1.14570e+01 1.09930e+01 9.36400e+00 1.57000e+01 4.20000e+00 1.09790e+01\n",
      " 1.42000e+01 7.40190e+00 1.88000e+01 9.18600e+00 1.54000e+01 1.39000e+01\n",
      " 1.03850e+01 1.07750e+01 1.05550e+01 1.02950e+01 1.05350e+01 1.02190e+01\n",
      " 1.15030e+01 1.00409e+01 1.10370e+01 6.80000e+00 1.01949e+01 7.10000e+00\n",
      " 9.75100e+00 9.60800e+00 1.26000e+01 1.07530e+01 1.08100e+01 1.06310e+01\n",
      " 9.93400e+00 1.08930e+01 1.08690e+01 9.02800e+00 9.42700e+00 1.02560e+01\n",
      " 1.06810e+01 1.08980e+01 1.17390e+01 1.05199e+01 1.01590e+01 1.10610e+01\n",
      " 1.11250e+01 9.12100e+00 1.04240e+01 1.05740e+01 1.07190e+01 9.52000e+00\n",
      " 1.05460e+01 1.05250e+01 1.18160e+01 1.11800e+01 9.00000e+00 9.23400e+00\n",
      " 1.01169e+01 1.20750e+01 1.07490e+01 1.12750e+01 1.02159e+01 1.16650e+01\n",
      " 1.07450e+01 1.10000e+00 1.10530e+01 9.94800e+00 1.03090e+01 1.05440e+01\n",
      " 1.08120e+01 3.20000e+00 1.09910e+01 2.30000e+00 1.08510e+01 1.02170e+01\n",
      " 2.57000e+01 1.10350e+01 1.06720e+01 1.10580e+01 1.14130e+01 1.01289e+01\n",
      " 3.10000e+00 9.87800e+00 1.07260e+01 1.04850e+01 1.10560e+01 1.04080e+01\n",
      " 1.15380e+01 1.12840e+01 1.15020e+01 6.10000e+00 1.15190e+01 1.98000e+01\n",
      " 1.09840e+01 1.72000e+01 9.90200e+00 1.10460e+01 8.97400e+00 9.93200e+00\n",
      " 9.94090e+00 1.02990e+01 1.04120e+01 1.08390e+01 1.03520e+01 1.20000e+00\n",
      " 5.00000e+00 1.07580e+01 9.55800e+00 1.15370e+01 1.05840e+01 1.04440e+01\n",
      " 1.05070e+01 1.07910e+01 1.05430e+01 1.14780e+01 1.07730e+01 1.05320e+01\n",
      " 1.07880e+01 1.10070e+01 2.00000e-01 1.11950e+01 9.50000e+00 1.17080e+01\n",
      " 1.06400e+01 1.09460e+01 1.00030e+01 1.09680e+01 2.80000e+00 1.04520e+01\n",
      " 1.60000e+00 1.03800e+01 1.13540e+01 1.07550e+01 9.31400e+00 1.07800e+01\n",
      " 1.07480e+01 1.01110e+01 1.23270e+01 1.01200e+01 9.71600e+00 1.08600e+01\n",
      " 1.01190e+01 1.00810e+01 8.48800e+00 6.00000e-01 1.22820e+01 2.30000e+01\n",
      " 9.02900e+00 1.06320e+01 1.10250e+01 9.81700e+00 3.50000e+00 1.04690e+01\n",
      " 1.01370e+01 1.25770e+01 1.12210e+01 9.99700e+00 9.90500e+00 1.07630e+01\n",
      " 1.10510e+01 1.04800e+01 1.05410e+01 1.07659e+01 9.99600e+00 1.06890e+01\n",
      " 9.89400e+00 1.02280e+01 8.78900e+00 7.56190e+00 1.03770e+01 1.04019e+01\n",
      " 1.01570e+01 1.05100e+01 1.08090e+01 9.10000e+00 9.67000e+00 1.08470e+01\n",
      " 1.55000e+01 1.08210e+01 7.90000e+00 1.07960e+01 1.05820e+01 1.65000e+01\n",
      " 1.08970e+01 1.01339e+01 1.62000e+01 1.86000e+01 1.06750e+01 2.36000e+01\n",
      " 4.00000e-01 1.03150e+01 1.05680e+01 1.08240e+01 1.35000e+01 2.00000e+01\n",
      " 9.30000e+00 1.08300e+01 1.66000e+01 9.67700e+00 1.04430e+01 8.00000e+00\n",
      " 6.24000e+01 2.40000e+01 7.76390e+00 1.01380e+01 1.03170e+01 1.08070e+01\n",
      " 9.70700e+00 9.79400e+00 1.10050e+01 1.46000e+01 1.12530e+01 8.78000e+00\n",
      " 1.10100e+01 1.11960e+01 1.07670e+01 1.08250e+01 9.82300e+00 1.07120e+01\n",
      " 1.07660e+01 1.05280e+01 5.00000e-01 1.13590e+01 8.00000e-01 9.68400e+00\n",
      " 1.92000e+01 2.27000e+01 3.40000e-01 1.93000e+01 2.45000e+01 2.11000e+01\n",
      " 2.40000e+00 1.79000e+01 2.32000e+01 3.09000e+01 2.16000e+01 1.32800e+02]\n",
      "Hemoglobin [13.1   10.9    8.3   11.3   10.7    9.949 10.     9.726  9.657 10.4\n",
      " 10.5    9.405  9.738  7.2    9.921 10.1   13.2    9.662  6.9    9.835\n",
      "  9.868  9.785  9.584  9.981  9.944  9.995  9.991  9.782 10.3   10.2\n",
      "  9.792 10.084  9.986 13.3    9.994  7.3   14.8   10.171  9.801  9.92\n",
      " 10.014  8.9   10.112  9.646  9.963 12.9    9.618 10.087 10.038  9.961\n",
      " 10.8   11.6   10.124  9.539 10.025 10.018 10.099  9.969 10.6    9.948\n",
      "  9.956  9.852  9.701 11.5   10.045  9.854  8.2   10.009 14.6   10.081\n",
      " 10.066  9.972  9.977  9.772  9.955  9.907  9.998 11.1    9.993  9.877\n",
      "  9.999  9.612  9.668  6.3   11.    11.4    9.863  9.841  9.545  7.\n",
      "  9.939  9.983 10.041  9.873  9.898  9.941  9.895 10.004 10.06   9.881\n",
      "  9.639  9.862 13.5    9.783  7.5   10.044  9.78  11.2    7.8   10.003\n",
      "  9.137  9.665  7.9   10.129  9.979  9.903  9.708  9.776 10.04   9.987\n",
      " 13.6    9.589  9.849  8.7   10.174  9.932  9.922  8.5    8.    10.067\n",
      " 11.7    9.823  9.803  9.992 12.1    9.914 10.192  6.6   10.114  9.942\n",
      " 15.9    9.632 11.8   15.7    9.765 10.048  9.73  10.022 10.063  7.4\n",
      "  8.1    9.887 10.056  9.9    9.613 10.023  9.79   9.984 15.1   10.083\n",
      "  9.6   10.042  9.891  9.787 10.197 12.8    9.794 10.001 11.9    9.878\n",
      "  9.2    9.     9.41   6.7   10.097 10.072  9.858 10.01   8.6   10.002\n",
      "  9.637  9.82  10.062  9.99   9.905  9.911  7.6   12.5    9.959 10.053\n",
      " 10.047 10.075 10.229 10.058  9.06   9.912  9.826  9.896  9.818 10.024\n",
      " 10.031  9.822  9.884 12.6   10.078  6.4    9.4   10.094  8.968  9.973\n",
      " 10.005 10.149  9.754  7.7    9.989 10.015 12.4    9.85   9.771  8.4\n",
      " 10.049  9.967  8.436 12.     9.958 14.    10.116 10.006 12.3   10.126\n",
      "  9.871 10.152 10.127  9.866 10.089 10.019  9.96   9.758  6.5    9.848\n",
      "  9.809 10.122  9.915 10.205 10.09   6.8    9.888 10.057 10.03   9.763\n",
      " 10.086  9.975  5.5    6.2   10.02  10.077  9.296 10.027  9.551  9.98\n",
      "  8.8   10.166 10.055  9.968  9.88  10.043  9.245 10.239  9.747  9.966\n",
      " 10.021 10.016 13.7    9.894 15.4    9.985  9.718  5.6   10.096 10.054\n",
      " 10.082 10.085  9.845  9.97  10.092 10.111  9.919  9.587  9.182  9.723\n",
      " 10.051  6.     9.828  9.836 10.102  9.69  10.387 10.029  9.931  9.87\n",
      "  9.729  9.804  9.929 10.007  9.882 10.032 10.017  9.724 10.061 10.035\n",
      "  9.95  10.079  9.935  9.924  9.918 13.9   10.12   9.859  9.982 16.7\n",
      "  9.147  9.893  9.902  9.3   10.334  9.89  10.144 10.026  9.997  9.373\n",
      "  9.889 10.103  9.938 10.093  9.761 10.139  9.923 14.2    8.786  9.581\n",
      "  9.833 10.036  9.892 13.4   12.7    9.957 10.073  9.917  9.1    9.762\n",
      " 10.069 11.529  9.775  9.865  9.913 10.331 13.    10.095  9.934  9.634\n",
      "  9.728  9.875 10.05   9.816 10.226 12.2   10.167  5.9    9.954  9.901\n",
      " 10.064 10.143  9.962  5.2   10.104  9.933 10.012  9.909 10.162 10.142\n",
      " 10.071 13.8   10.008  9.844  9.654  9.737 10.117  5.7   10.109 10.039\n",
      "  9.964  9.829  9.55   9.869  9.936  9.996  6.1   10.013  9.928 15.3\n",
      " 10.011  9.649  9.872  9.806  9.322  9.926  9.874  9.72   9.965 10.028\n",
      "  9.94   7.1    9.113  9.54   9.855  9.739  9.91   9.976 10.059 10.034\n",
      "  0.     9.851  9.62   9.108  5.8   10.113  9.908  9.764 10.037  5.3\n",
      "  4.3    3.6    4.9  ]\n",
      "PTT [ 24.5   113.6    27.4   ...  40.4   118.1    38.978]\n",
      "GCS...Verbal.Response ['Oriented' 'No Response-ETT' 'Confused' 'No Response'\n",
      " 'Incomprehensible sounds' 'Inappropriate Words']\n",
      "Language ['English' 'Spanish' 'Greek' 'Portuguese' 'Russian' 'Italian' 'Cantonese'\n",
      " 'Polish' 'Cambodian' 'Persian' 'Vietnamese' 'Mandarin' 'French' 'Arabic'\n",
      " 'Hindi']\n",
      "GCS...Motor.Response ['Obeys Commands' 'Localizes Pain' 'No response' 'Flex-withdraws'\n",
      " 'Abnormal extension' 'Abnormal Flexion']\n",
      "GCS...Eye.Opening ['Spontaneously' nan 'To Pain' 'To Speech']\n",
      "INR [ 1.      1.2     1.3     2.7     1.408   3.0704  1.442   1.1     1.582\n",
      "  1.38    1.4     1.383   2.3     1.671   1.448   1.416   1.3964  2.845\n",
      "  1.362   1.369   1.392   1.567   1.456   1.399   1.7     1.411   1.417\n",
      "  0.9     1.373   1.8     1.635   2.949   2.247   1.446   1.401   1.37\n",
      "  2.2     1.34    1.556   1.572   1.397   1.389   1.405   1.5     2.\n",
      "  1.361   1.609   1.356   2.1     1.352   1.354   1.382   1.35    1.375\n",
      "  1.628   1.386   2.8     1.398   2.997   1.6     1.421   1.3894  1.429\n",
      "  1.395   1.432   1.419   1.368   1.3474  1.464   1.453   1.437   1.363\n",
      "  3.      2.637   1.406   1.433   1.441   1.469   1.426   1.714   1.519\n",
      "  1.743   1.387   1.4684  1.443   2.518   2.554   1.381   2.741   1.489\n",
      "  1.402   1.422   1.765   1.693   1.407   1.385   1.458   1.76    1.491\n",
      "  1.9     2.6     1.333   1.371   1.293   1.557   1.616   1.462   1.391\n",
      "  1.7654  3.384   1.607   1.372   1.44    1.376   1.338   1.436   1.553\n",
      "  1.8894  1.358  21.8     4.2     1.4094  2.2988  1.596  10.7     1.301\n",
      "  1.32    2.5284  1.558   2.4     3.0874  1.7094  1.384   1.413   2.5\n",
      "  1.591   3.7354  1.359   1.719   1.439   1.332   1.377   1.355   2.189\n",
      "  2.6774  1.457   1.754   1.378   1.475   1.559   1.379   1.299   2.732\n",
      "  1.527   1.365   1.393   1.374   1.511   3.2     1.481   4.      1.415\n",
      "  1.302   1.334   3.299   1.4244  1.348   1.3334  1.343   1.618   1.325\n",
      "  1.855   1.459   1.447   1.466   1.617   4.751   1.388   1.428   1.412\n",
      "  1.36    1.394   0.8     1.341   3.9     2.7424  1.423   1.435   1.297\n",
      "  3.1     2.1444  2.837   1.351   1.366   3.2064  1.318   1.531   4.542\n",
      "  1.39    1.7214  1.337   1.438   1.418   1.512   1.317   1.298   1.396\n",
      "  1.345   1.353   1.699   1.579   1.288   1.7734  2.356   1.566   1.364\n",
      "  2.608   1.349   1.45    1.328   1.303   1.284   1.3974  1.43    1.534\n",
      "  1.473   1.409   1.347   1.3314  1.335   1.472   1.308   1.271   1.296\n",
      " 16.5     1.414   2.9144  1.3674  1.892   1.492   1.229   1.3734  1.367\n",
      "  1.5814  3.0584  1.8904  1.656   1.586   1.319   1.431   1.342   1.312\n",
      "  1.547   1.525   4.029   1.41    1.304   1.33    1.84    2.972   1.58\n",
      "  1.314   4.337   1.336   2.514   2.037   1.357   1.552   3.248   1.5868\n",
      "  1.8844  1.3494  1.709   1.544   2.5914  1.612   1.647  13.1     1.321\n",
      "  1.2924  1.344   1.4294  1.434   1.452   1.7234  1.549   1.305   1.479\n",
      "  1.505   1.563   1.455   1.5794  1.3804  1.307   2.9     1.445   1.51\n",
      "  2.419   1.75    1.776   1.3354  1.4004  4.1     1.545   1.47    6.7\n",
      "  1.404   1.292   1.8224  2.0864  1.3994  1.3574  2.46    2.063   1.346\n",
      "  1.917   1.9716  1.313   1.532   2.681   1.687   1.683   2.1084  2.133\n",
      "  2.631   1.3794  1.8874  1.6852  1.283   2.229   2.4494  1.633   1.4324\n",
      "  1.632   1.471   1.281   1.906   1.5844  0.      0.7     1.203   1.183\n",
      "  1.178   1.197   1.185 ]\n",
      "Religion ['Roman Catholic' 'Not specified' 'Protestant ' 'Jewish' 'Other' 'Unknown'\n",
      " 'Buddhist' 'Episcopalian' 'Seventh Day Adventist' 'Greek Orthodox'\n",
      " 'Jehovah Witness' 'Unitarian' 'Muslim' 'Eastern Orthodox '\n",
      " 'Christian Scientist' 'Hindu']\n",
      "Patient.Location ['CC6B' '4I' 'CC6D' 'CC6C' 'CC7C' 'FA6B' 'CC7B' 'CC5B' 'CC7D']\n",
      "Race ['White' 'Hispanic or Latino' 'Black / African American'\n",
      " 'Patient Declined to Answer' 'Black / African' 'Asian'\n",
      " 'Unknown / Not Specified' 'Hispanic / Latino - Puerto Rican' 'Other'\n",
      " 'Hispanic / Latino - Salvadoran' 'White - Russian' 'Asian - Korean'\n",
      " 'Unable to Obtain' 'Hispanic / Latino - Dominican' 'Asian - Chinese'\n",
      " 'Hispanic / Latino - Central American (other)' 'Black / Haitian'\n",
      " 'Black / Cape Verdean' 'White - Brazilian' 'Hispanic / Latino - Cuban'\n",
      " 'Asian - Vietnamese' 'Hispanic / Latino - Guatemalan' 'Portuguese'\n",
      " 'Asian - Asian Indian' 'Asian - Other' 'White - Other European'\n",
      " 'American Indian / Alaska Native' 'Asian - Cambodian'\n",
      " 'American Indian / Alaska Native - Federally Recognized Tribe'\n",
      " 'White - Eastern European' 'Hispanic / Latino - Mexican'\n",
      " 'Multiple Race/Ethnicity' 'Middle Eastern' 'Asian - Filipino']\n",
      "Glucose..serum. [114.   100.   112.   125.   171.   108.38 113.85 107.44 124.   102.\n",
      " 106.   115.02 103.56  77.   123.   113.56 229.   117.72 101.   115.61\n",
      " 104.9  107.76 113.76 106.4  106.72 108.   106.13 103.   110.42 104.41\n",
      " 104.   108.35 107.78 104.14 109.   105.94 109.13  55.   130.   114.36\n",
      " 104.54 102.5  105.48 141.   102.13 115.56 108.92 102.44 109.01 109.82\n",
      " 111.64 118.   143.   107.06 105.   100.49 107.91 108.54 107.   104.72\n",
      " 108.24 105.65 107.31 105.58 113.02 109.64 109.36 107.37  98.   106.66\n",
      " 107.33 105.39 113.87 106.42 107.21 104.91 106.74 114.37 110.   107.64\n",
      " 104.67 106.87  98.82 107.27 126.   162.   121.   105.92 129.   189.\n",
      " 174.   111.05 136.   103.88 115.22 115.74 133.   110.22 116.   105.41\n",
      " 105.5  104.43 106.3  115.   106.34 104.63 104.3  107.26 105.35 102.64\n",
      " 209.   110.21 103.94 105.98 106.51 105.67 132.   180.   134.   104.74\n",
      " 112.13 111.82 142.   105.66 105.96 104.34 114.42 106.38 111.     0.\n",
      " 114.78 113.19 154.   145.   103.65 105.01 109.57 101.8  146.   110.35\n",
      " 114.1  100.26 140.   104.6  216.   107.9  172.   110.94 119.   117.\n",
      " 109.18 109.51 116.99 122.   138.   109.65 102.38 108.7  135.   103.27\n",
      " 106.71 112.45 107.53 105.12 107.39 113.   113.53 127.   104.58 105.84\n",
      " 104.4  107.51  89.   105.63 113.74 117.41 104.46 104.52 104.39 129.55\n",
      " 274.   259.   105.29 106.69 106.29 105.91 103.62 112.52 105.56 104.24\n",
      " 124.71 101.09 107.3  102.47 101.49 150.   109.56  99.   105.49 105.09\n",
      " 106.1  104.99 105.79 116.29 107.62 104.09 101.26 106.83 102.75 110.79\n",
      "  95.   102.12 116.79 104.95 102.26 104.47 104.18 137.   106.81 102.36\n",
      " 113.16 106.86 102.51 105.83 111.9  106.44 107.38 131.   113.72 107.73\n",
      "  73.   103.35 106.05 100.1  109.5  102.14  99.52 105.14 103.8  104.36\n",
      " 103.41 105.81 139.42 103.71 103.38 105.17 110.3  158.   109.1  108.59\n",
      " 147.   108.49 106.35 105.16 168.   115.73  61.   112.22 106.78 139.\n",
      " 116.07 106.68 107.24 114.74 105.55 106.15 105.68 107.97 109.44 105.23\n",
      " 107.92 106.94 115.95 108.34 105.51 109.92 103.93 106.43 106.89 108.02\n",
      " 117.94 120.   106.7  103.76 101.7  105.86  85.   244.   101.77 105.9\n",
      " 107.98 110.26 104.33 108.4  104.69 112.59 149.   105.34 120.87 101.46\n",
      " 109.47 106.32 122.9  107.46 105.93 109.54 104.08 104.86  83.   113.61\n",
      " 105.3  104.17 104.51  68.   104.75 123.75 111.09 103.26 108.21 109.07\n",
      "  59.   103.67 106.01 103.45 159.   112.06 104.73 102.74  82.   105.71\n",
      " 104.78 106.07 106.65 106.11 103.13 106.97 105.43 107.8  110.58 111.23\n",
      " 102.84 105.4  105.05  99.84 106.33 128.   107.66 102.94 104.26 165.\n",
      " 112.74 109.41 105.27 111.93 104.76 106.99 112.71 109.2  110.89 148.\n",
      " 113.06 104.5  109.35 118.13 105.88 106.46 110.96 103.9  104.97 107.19\n",
      " 102.16 175.   181.   112.88 106.22 106.2  108.78 101.79 105.33 104.53\n",
      " 187.   105.21 107.67 103.44 112.21  92.   111.18 224.   152.   107.88\n",
      " 104.48 104.38 105.08 105.54 103.6  106.06 111.83 112.89  88.   106.64\n",
      " 102.87 109.08 104.82 104.55 103.14 104.85 105.11 104.89 109.14 105.37\n",
      " 104.8  106.21 105.77 110.44 105.25 108.48 102.79 108.6   99.97 367.\n",
      " 107.43 107.36 102.06 104.61 106.79 102.37 104.45  50.   107.96  54.\n",
      " 109.24 138.77 105.38 102.49 104.64 101.3  105.36 106.58 110.53 106.56\n",
      " 151.   164.   102.9  101.68  98.6  104.84 103.75 111.67  64.   106.76\n",
      " 114.22 103.98 105.2  104.2  102.32 108.69 106.47  86.   103.54 104.56\n",
      " 104.15 112.53 107.09 108.27 108.06 103.02 127.32 105.6  107.34 101.72\n",
      "  75.   115.91 126.7  102.88 109.45 107.29 383.   106.04 109.25 110.01\n",
      " 179.    57.   106.85 144.   104.12 103.73 102.89 103.99 104.42 102.11\n",
      " 106.49 104.25 103.64 116.82 104.23 103.09 109.58 202.   104.79 130.61\n",
      " 104.03 104.92 103.87 105.13 184.   109.49 104.05 112.05 103.63 106.26\n",
      " 104.19 103.11 109.76  74.   103.52 112.61 105.42 105.69  99.61 110.32\n",
      " 101.57 102.48 134.19 161.   200.   102.31 199.   101.45 107.32 104.94\n",
      "  90.   103.85 104.59 108.15 107.48 114.39 113.73 117.62  80.    78.\n",
      " 195.   103.31 103.83 106.02 104.83 104.93 119.12 104.77 103.46 104.37\n",
      " 121.28 104.13 160.   111.72 106.14 167.   110.25 103.42 112.24 103.68\n",
      " 106.82 104.29 173.   107.11  62.   125.08 213.   104.71  76.   122.75\n",
      " 153.   103.2   69.   106.84 103.03  91.   110.86 121.35 107.15 103.89\n",
      " 104.65 107.1  102.56 155.     1.   108.46 103.32 103.39  48.   226.\n",
      " 221.  ]\n",
      "Gender ['M' 'F']\n",
      "Hematocrit..serum. [3.690000e+01 3.090000e+01 2.640000e+01 2.390000e+01 1.700000e+01\n",
      " 4.040000e+01 2.612500e+01 2.140000e+01 2.328400e+01 2.413600e+01\n",
      " 2.330000e+01 1.950000e+01 2.860000e+01 2.040000e+01 2.287700e+01\n",
      " 2.456900e+01 2.180000e+01 2.660000e+01 2.438200e+01 3.630000e+01\n",
      " 2.130000e+01 4.000000e+01 2.295500e+01 2.200000e+01 2.414700e+01\n",
      " 2.512900e+01 2.447700e+01 2.211000e+01 2.540100e+01 2.382200e+01\n",
      " 2.436300e+01 3.080000e+01 2.522500e+01 2.070000e+01 2.403200e+01\n",
      " 2.500000e+01 2.385100e+01 2.210000e+01 2.471200e+01 2.403700e+01\n",
      " 3.010000e+01 4.030000e+01 2.557500e+01 1.460000e+01 2.980000e+01\n",
      " 2.440000e+01 2.472400e+01 4.250000e+01 2.603300e+01 2.387400e+01\n",
      " 2.380000e+01 2.438500e+01 2.840000e+01 2.452400e+01 2.538400e+01\n",
      " 2.504700e+01 3.880000e+01 2.250700e+01 2.542400e+01 2.507200e+01\n",
      " 2.770000e+01 2.438600e+01 1.680000e+01 3.160000e+01 3.470000e+01\n",
      " 2.456700e+01 2.460000e+01 2.310000e+01 2.690000e+01 2.790000e+01\n",
      " 2.249800e+01 2.353600e+01 2.397800e+01 3.220000e+01 3.200000e+01\n",
      " 2.620000e+01 2.494100e+01 2.447800e+01 2.340000e+01 2.358900e+01\n",
      " 2.452000e+01 2.060000e+01 1.910000e+01 2.367000e+01 2.316100e+01\n",
      " 2.360000e+01 3.400000e+01 2.590200e+01 2.410900e+01 2.524600e+01\n",
      " 2.526500e+01 4.060000e+01 2.600000e+01 2.474700e+01 2.558000e+01\n",
      " 2.534600e+01 2.499300e+01 0.000000e+00 2.400000e+01 2.487300e+01\n",
      " 2.336100e+01 2.429400e+01 2.373600e+01 2.487600e+01 2.429300e+01\n",
      " 2.451500e+01 2.399100e+01 2.354300e+01 2.354500e+01 2.730000e+01\n",
      " 2.990000e+01 2.630000e+01 2.090000e+01 2.830000e+01 2.350000e+01\n",
      " 2.230000e+01 2.350400e+01 2.960000e+01 3.450000e+01 3.420000e+01\n",
      " 2.577700e+01 2.950000e+01 2.332300e+01 2.239000e+01 2.570000e+01\n",
      " 2.470600e+01 2.711600e+01 1.590000e+02 2.410000e+01 2.457100e+01\n",
      " 2.446400e+01 2.527900e+01 2.407700e+01 2.458300e+01 2.497100e+01\n",
      " 2.457300e+01 2.270000e+01 2.575200e+01 3.270000e+01 2.437000e+01\n",
      " 2.245200e+01 2.420000e+01 3.210000e+01 2.160000e+01 3.230000e+01\n",
      " 2.370000e+01 2.528900e+01 2.401500e+01 2.458100e+01 2.455900e+01\n",
      " 2.432000e+01 2.469000e+01 2.940000e+01 3.330000e+01 2.810000e+01\n",
      " 3.110000e+01 2.300000e+01 2.452600e+01 2.369800e+01 2.452200e+01\n",
      " 2.480800e+01 3.130000e+01 3.180000e+01 2.415600e+01 2.490500e+01\n",
      " 2.120000e+01 2.258200e+01 2.490000e+01 2.519200e+01 2.377900e+01\n",
      " 2.580000e+01 1.710000e+01 1.900000e+01 2.470000e+01 2.260100e+01\n",
      " 2.290000e+01 2.357700e+01 2.820000e+01 2.740100e+01 3.000000e+01\n",
      " 2.432100e+01 2.970000e+01 2.260000e+01 2.390300e+01 2.700000e+01\n",
      " 2.430000e+01 2.391100e+01 2.432500e+01 2.680000e+01 2.010000e+01\n",
      " 2.474100e+01 2.405700e+01 2.540000e+01 2.650000e+01 2.427600e+01\n",
      " 2.755900e+01 2.270200e+01 2.800000e+01 2.296200e+01 3.660000e+01\n",
      " 2.345500e+01 2.411800e+01 2.920000e+01 2.543200e+01 3.140000e+01\n",
      " 2.411200e+01 4.540000e+01 2.298300e+01 2.480000e+01 1.880000e+01\n",
      " 2.910000e+01 4.560000e+01 2.422700e+01 2.446700e+01 3.560000e+01\n",
      " 2.300200e+01 2.441100e+01 2.414300e+01 1.890000e+01 3.360000e+01\n",
      " 2.280000e+01 2.450000e+01 2.590000e+01 2.240000e+01 2.599300e+01\n",
      " 2.476100e+01 2.498400e+01 2.610000e+01 2.451200e+01 3.070000e+01\n",
      " 2.406700e+01 2.550000e+01 2.553500e+01 2.478300e+01 2.441700e+01\n",
      " 4.380000e+01 2.445600e+01 2.455700e+01 2.410600e+01 2.620400e+01\n",
      " 2.547800e+01 3.870000e+01 2.410800e+01 3.310000e+01 2.508800e+01\n",
      " 3.640000e+01 2.349100e+01 2.492100e+01 3.610000e+01 2.325500e+01\n",
      " 2.320000e+01 3.050000e+01 3.350000e+01 2.850000e+01 3.100000e+01\n",
      " 2.333400e+01 1.180000e+01 1.870000e+01 3.040000e+01 2.597300e+01\n",
      " 2.517100e+01 2.395900e+01 2.760000e+01 2.560000e+01 2.170000e+01\n",
      " 2.581400e+01 2.428300e+01 2.447100e+01 2.487700e+01 2.368700e+01\n",
      " 2.315700e+01 2.870000e+01 2.327700e+01 2.424400e+01 2.080000e+01\n",
      " 2.388400e+01 2.443800e+01 2.411600e+01 2.443600e+01 2.510000e+01\n",
      " 2.610200e+01 2.574600e+01 2.403800e+01 2.329100e+01 2.501100e+01\n",
      " 2.420800e+01 3.500000e+01 2.439000e+01 2.439500e+01 2.488500e+01\n",
      " 2.437200e+01 2.370900e+01 2.740000e+01 2.454600e+01 2.420300e+01\n",
      " 2.190000e+01 3.860000e+01 2.495600e+01 1.760000e+01 3.490000e+01\n",
      " 2.670000e+01 2.478900e+01 2.367300e+01 2.448700e+01 2.403500e+01\n",
      " 2.505300e+01 2.100000e+01 2.510600e+01 2.411500e+01 2.494800e+01\n",
      " 2.502300e+01 2.549000e+01 2.401800e+01 2.377300e+01 2.000000e+01\n",
      " 2.030000e+01 2.391500e+01 3.740000e+01 2.355800e+01 3.120000e+01\n",
      " 2.503400e+01 3.240000e+01 2.150000e+01 2.335800e+01 2.277100e+01\n",
      " 2.442000e+01 2.432900e+01 2.470100e+01 2.551700e+01 2.400800e+01\n",
      " 2.466400e+01 2.336400e+01 2.302900e+01 2.505400e+01 2.520000e+01\n",
      " 4.340000e+01 2.493300e+01 2.446300e+01 2.424800e+01 2.452900e+01\n",
      " 2.305900e+01 2.250000e+01 2.487100e+01 2.338300e+01 2.880000e+01\n",
      " 3.780000e+01 2.339300e+01 2.443700e+01 3.430000e+01 2.758100e+01\n",
      " 4.010000e+01 1.850000e+01 2.900000e+01 2.338400e+01 2.423500e+01\n",
      " 2.745600e+01 2.406500e+01 2.456300e+01 1.450000e+01 2.465600e+01\n",
      " 2.544700e+01 2.269700e+01 2.530000e+01 2.437500e+01 1.960000e+01\n",
      " 2.507000e+01 2.405800e+01 2.443000e+01 2.501500e+01 2.494000e+01\n",
      " 2.450100e+01 2.413900e+01 2.585500e+01 2.379200e+01 3.410000e+01\n",
      " 2.439800e+01 2.365700e+01 2.423100e+01 1.980000e+01 2.450900e+01\n",
      " 2.456400e+01 2.496600e+01 2.890000e+01 2.508900e+01 3.830000e+01\n",
      " 2.409200e+01 2.348200e+01 2.433700e+01 2.562000e+01 2.379400e+01\n",
      " 2.478700e+01 2.506700e+01 2.572100e+01 2.553300e+01 3.760000e+01\n",
      " 2.430900e+01 1.690000e+01 2.445900e+01 2.410200e+01 2.499600e+01\n",
      " 2.499200e+01 1.580000e+01 2.710000e+01 3.580000e+01 2.436400e+01\n",
      " 2.593700e+01 2.020000e+01 2.263200e+01 1.670000e+01 2.485400e+01\n",
      " 2.613300e+01 2.466300e+01 2.630800e+01 2.264800e+01 2.499700e+01\n",
      " 2.394400e+01 2.793600e+01 2.441300e+01 2.386000e+01 2.576400e+01\n",
      " 2.567900e+01 2.547900e+01 2.750000e+01 2.418900e+01 2.361600e+01\n",
      " 2.526700e+01 3.030000e+01 2.519500e+01 2.506400e+01 2.439700e+01\n",
      " 3.550000e+01 2.489300e+01 3.250000e+01 2.317100e+01 1.340000e+02\n",
      " 2.433400e+01 3.290000e+01 2.448900e+01 2.423300e+01 2.206900e+01\n",
      " 3.300000e+01 2.450600e+01 2.490400e+01 2.428800e+01 2.423900e+01\n",
      " 2.578300e+01 2.050000e+01 2.332700e+01 2.394900e+01 2.477900e+01\n",
      " 2.455200e+01 2.474500e+01 2.435300e+01 2.780000e+01 2.502900e+01\n",
      " 2.245800e+01 1.750000e+01 2.415200e+01 2.363400e+01 2.244100e+01\n",
      " 3.020000e+01 2.413700e+01 1.860000e+01 2.477400e+01 2.381400e+01\n",
      " 2.434300e+01 2.495100e+01 2.444400e+01 2.384600e+01 2.484100e+01\n",
      " 2.461300e+01 2.406000e+01 2.839100e+01 2.424000e+01 2.615900e+01\n",
      " 2.489200e+01 2.524400e+01 2.429200e+01 2.541100e+01 2.483500e+01\n",
      " 2.466100e+01 2.538300e+01 2.759700e+01 2.471700e+01 2.429000e+01\n",
      " 2.497900e+01 2.454000e+01 2.433100e+01 2.205300e+01 2.440500e+01\n",
      " 3.480000e+01 2.456800e+01 2.491200e+01 2.492600e+01 2.487000e+01\n",
      " 2.328900e+01 2.416900e+01 2.447400e+01 2.445200e+01 2.482100e+01\n",
      " 4.100000e+01 2.485000e+01 2.413300e+01 2.346500e+01 2.678200e+01\n",
      " 3.320000e+01 5.210000e+01 2.272500e+01 3.670000e+01 3.390000e+01\n",
      " 2.367100e+01 2.451700e+01 2.110000e+01 2.400900e+01 2.358600e+01\n",
      " 2.490600e+01 2.400700e+01 2.396000e+01 2.486000e+01 2.637800e+01\n",
      " 2.808600e+01 3.530000e+01 2.384400e+01 2.426100e+01 2.426400e+01\n",
      " 2.487200e+01 2.440700e+01 2.425300e+01 2.386100e+01 1.780000e+01\n",
      " 2.405300e+01 2.470200e+01 2.384300e+01 2.443300e+01 2.472000e+01\n",
      " 2.384900e+01 2.394200e+01 2.411400e+01 2.443900e+01 2.416000e+01\n",
      " 2.449500e+01 2.462200e+01 2.459900e+01 2.465200e+01 2.330600e+01\n",
      " 2.371000e+01 2.533600e+01 2.436200e+01 2.409100e+01 2.220000e+01\n",
      " 2.337100e+01 2.357800e+01 2.389300e+01 2.349400e+01 2.398600e+01\n",
      " 2.720000e+01 2.495000e+01 2.420400e+01 2.329800e+01 2.291300e+01\n",
      " 4.300000e+01 2.335100e+01 2.437700e+01 2.382600e+01 2.363200e+01\n",
      " 2.323400e+01 1.930000e+01 3.260000e+01 2.471800e+01 2.400200e+01\n",
      " 2.526000e+01 2.301500e+01 2.271900e+01 2.394300e+01 2.443100e+01\n",
      " 2.437100e+01 3.440000e+01 2.508000e+01 2.371100e+01 1.970000e+01\n",
      " 2.349200e+01 2.365600e+01 2.456000e+01 2.407000e+01 2.381200e+01\n",
      " 2.427800e+01 2.416100e+01 2.352000e+01 2.833300e+01 2.213600e+01\n",
      " 2.343400e+01 2.464900e+01 2.391200e+01 2.313000e+01 2.375900e+01\n",
      " 2.406900e+01 2.396700e+01 3.515000e+01 2.448800e+01 2.347700e+01\n",
      " 1.830000e+01 2.408200e+01 2.765200e+01 2.404500e+01 2.339000e+01\n",
      " 2.388300e+01 2.397900e+01 3.590000e+01 2.335600e+01 2.571300e+01\n",
      " 3.700000e+01 2.350600e+01 2.430100e+01 2.475100e+01 2.432800e+01\n",
      " 1.820000e+01 2.882500e+01 2.321700e+01 2.408500e+01 2.458700e+01\n",
      " 2.344800e+01 2.427100e+01 2.500200e+01 2.356400e+01 2.304200e+01\n",
      " 3.720000e+01 4.230000e+01 3.340000e+01 2.409600e+01 1.600000e+01\n",
      " 2.387100e+01 2.377800e+01 2.262600e+01 2.341200e+01 2.348800e+01\n",
      " 3.190000e+01 2.455600e+01 2.292300e+01 2.461600e+01 2.462700e+01\n",
      " 2.388200e+01 4.110000e+01 2.411900e+01 2.351600e+01 2.318300e+01\n",
      " 2.457500e+01 2.367600e+01 2.393700e+01 2.203300e+01 2.352200e+01\n",
      " 2.917900e+01 2.427400e+01 4.240000e+01 2.287200e+01 2.477500e+01\n",
      " 3.730000e+01 2.288800e+01 1.920000e+01 2.445100e+01 4.170000e+01\n",
      " 2.473100e+01 2.438100e+01 2.265800e+01 1.720000e+01 2.248000e+01\n",
      " 2.431600e+01 2.410500e+01 2.396900e+01 2.395300e+01 2.489000e+01\n",
      " 2.484600e+01 2.386900e+01 2.238100e+01 4.470000e+01 1.510000e+01\n",
      " 2.372100e+01 2.300100e+01 2.420500e+01 2.397200e+01 2.408800e+01\n",
      " 2.371800e+01 2.462500e+01 2.430800e+01 2.416600e+01 3.510000e+01\n",
      " 1.660000e+01 2.512400e+01 2.584400e+01 2.285200e+01 2.433500e+01\n",
      " 2.408100e+01 2.366100e+01 2.313600e+01 2.328200e+01 3.840000e+01\n",
      " 2.652200e+01 3.060000e+01 2.276300e+01 2.011201e+06 2.366200e+01\n",
      " 2.415500e+01 3.150000e+01 2.298000e+01 1.650000e+01 2.308300e+01\n",
      " 2.360200e+01 2.279800e+01 2.333600e+01 2.414500e+01 2.682400e+01\n",
      " 3.990000e+01 2.424100e+01 3.520000e+01 2.420100e+01 2.374500e+01\n",
      " 2.365500e+01 2.458400e+01 3.380000e+01 2.333800e+01 2.442100e+01\n",
      " 2.321800e+01 2.343900e+01 2.250100e+01 2.248700e+01 2.352500e+01\n",
      " 2.534900e+01 1.790000e+01 2.274800e+01 2.394500e+01 3.810000e+01\n",
      " 2.460400e+01 2.420900e+01 4.280000e+01 2.439200e+01 2.930000e+01\n",
      " 2.493200e+01 2.460100e+01 1.420000e+01 2.389200e+01 2.405500e+01\n",
      " 3.370000e+01 1.940000e+01 3.460000e+01 3.850000e+01 2.339400e+01\n",
      " 3.790000e+01 2.345700e+01 2.459500e+01 3.710000e+01 2.379900e+01\n",
      " 1.090000e+01 2.362100e+01 2.356700e+01 2.395000e+01 1.770000e+01\n",
      " 2.199400e+01 2.284600e+01 2.347800e+01 3.770000e+01 1.800000e+01\n",
      " 1.520000e+01 2.280600e+01 2.276600e+01 2.399700e+01 2.319000e+01\n",
      " 1.810000e+01 2.419900e+01 2.247400e+01 2.365100e+01 2.236600e+01\n",
      " 1.630000e+01 2.473700e+01 2.474200e+01 2.226000e+01 2.324800e+01\n",
      " 2.273400e+01 1.560000e+01 2.334400e+01 2.312700e+01 3.900000e+01\n",
      " 1.990000e+01 1.300000e+01 2.385300e+01 2.372400e+01 3.280000e+01\n",
      " 2.354600e+01 1.190000e+01 1.730000e+01 2.222500e+01 2.353800e+01\n",
      " 1.550000e+01 1.270000e+01 1.840000e+01 3.650000e+01 1.610000e+02\n",
      " 1.540000e+01 1.490000e+01 1.390000e+01 1.740000e+01 1.470000e+01\n",
      " 1.370000e+01 1.570000e+01 1.110000e+02 3.570000e+01 1.120000e+02\n",
      " 1.350000e+01 1.150000e+01 1.410000e+01 1.400000e+01 1.590000e+01\n",
      " 1.640000e+01 1.530000e+01 1.540000e+02 1.120000e+01 1.110000e+01\n",
      " 1.070000e+02]\n",
      "Calcium.non.ionized [  7.8     7.7     7.      7.1    15.8     1.8    10.516  28.293  11.705\n",
      "  10.2     8.     10.5    12.673  12.129   8.5     9.474   8.9     7.6\n",
      "  10.1     6.4    14.16    6.2    12.213  10.504  12.204  22.808  13.121\n",
      "  14.739 146.     16.17   13.219   6.     15.391   7.5     6.6   164.\n",
      "  12.082   8.088   7.914   8.1     8.6     8.933   0.      8.8     7.869\n",
      "   9.589   7.903   7.556   8.638   8.3     6.9     7.802   7.906   7.715\n",
      "  16.091   9.358   7.935   8.113   9.2     7.885  10.      8.4    13.575\n",
      "   8.955   7.972   7.713   7.714   7.995   7.66   10.4     8.146   8.127\n",
      "   8.468   8.058   9.883   7.977   6.8    10.053   8.005   8.099   8.804\n",
      "   8.14    8.077  11.401   7.836  10.042   9.063   7.82    9.242  17.011\n",
      "  15.404   8.2     7.9     8.7     5.9     7.981  13.047   9.4     9.\n",
      "   7.98    7.2     6.5     8.071   8.163  14.592   8.18    7.832   9.157\n",
      "   7.799   7.889   7.921   8.845   9.767   7.77    8.024   7.679   9.048\n",
      "  25.119   9.1    10.004   9.88    9.168   8.229   9.274 171.     22.438\n",
      "   9.601  18.937   7.982   8.204   9.139  24.94    7.919   9.164   8.121\n",
      "   7.3    22.954  12.307   8.362   7.4   399.     11.75    5.2     9.218\n",
      "   7.91    8.066  10.339   8.219   8.174  10.777   8.33    8.029   8.22\n",
      "  11.7     8.015   8.027  12.999   7.997   7.937  16.078   7.811   7.812\n",
      "   8.186   7.966  10.555   7.866   9.226   9.114   8.145   7.909   7.853\n",
      "  10.539   8.087   8.215  13.254  12.226  13.921   7.996   8.552   7.825\n",
      "  15.071   5.8     8.111  16.928   8.026  10.467   8.048   7.847   9.248\n",
      "  28.399   9.679   8.156   9.115  10.81    8.228   8.126   8.079   9.216\n",
      "   9.228   6.7     9.578   7.684   7.991  28.455   9.824  15.386  10.117\n",
      "   7.963   9.232   9.231  13.679   7.859   9.019   6.1     9.336   7.975\n",
      "  15.608   7.864  10.362   9.201   7.617   8.039   7.854   7.943   8.014\n",
      "   7.913   9.335  10.508   8.041 130.      8.043  10.132   8.196  10.18\n",
      "   8.059  10.156  10.484   8.063  40.534 138.      9.033   7.902   8.213\n",
      "  10.424   8.047 102.      8.816   8.987   7.998   7.736   8.166   9.149\n",
      "   7.787   8.325  11.587   9.069   7.928 201.     12.488   9.691   9.447\n",
      "   7.855   9.198   8.671   7.808   7.801   8.141   7.676  33.814   8.936\n",
      "   8.057  12.459  11.258   9.046   6.3    10.7     8.189   8.008   7.849\n",
      "   5.4     7.886   7.843   7.657   7.634   9.623  11.496   9.076   7.831\n",
      "   7.922   7.933   8.139   9.126  10.928  24.292   9.172   9.146  10.859\n",
      "  23.412   8.287   7.893   9.884   8.77  131.      9.101  11.6     8.439\n",
      "   9.145   7.824   9.697   4.8     7.646  35.185   8.278  13.934   8.022\n",
      "   9.23    9.676   7.959   8.227   8.035  10.3     7.753  12.13   10.6\n",
      "   5.7     9.7     7.734   8.037  10.316   7.851   7.938   7.958   7.901\n",
      "   7.698   7.779   7.918  17.476   9.173  16.462  11.624   7.794  10.846\n",
      "   8.125  12.293   7.669   8.025   8.09    7.907   7.93    8.366   7.884\n",
      "   8.162   7.965   8.477   7.75    7.983   7.685   8.179   7.904   7.984\n",
      "   7.85    8.313   8.006   8.033  11.523   7.865   7.839   8.458  24.628\n",
      "   7.702   7.703   7.747   7.841   7.591   7.784   8.016   8.062   8.152\n",
      "  11.1    34.776   9.3     8.074   8.053   5.    178.      7.868   8.003\n",
      "   8.036   7.852   7.67    9.801   8.345   8.29    7.961   8.04    7.848\n",
      " 143.      7.658   8.13    7.615  10.895   7.962   8.142   7.608   8.329\n",
      "  24.687  10.219   7.745   7.923   7.979   7.834   8.031   7.805   7.718\n",
      "   8.758   7.973   7.772   8.116   8.011  36.521   7.681   9.945   7.807\n",
      "   7.623  17.448   8.105   7.974   7.655   9.511   8.07   12.194   7.626\n",
      "   9.992   7.89    8.054   8.143   8.299  25.315   7.648   7.622   7.668\n",
      "   7.835   8.02    7.857   4.9     7.895   7.822  14.591  11.866   7.78\n",
      "   7.748   8.333 170.     10.576  24.229   7.689   7.912   7.994   7.947\n",
      "   8.091   7.627   7.999   9.981   7.932   8.084   9.736   7.949  10.025\n",
      "   8.052   9.217   7.946   9.649   8.689   7.795   9.276   7.971   8.12\n",
      "   7.782   7.936   8.148   7.74   11.561   9.746   7.955  10.164   7.897\n",
      "   7.911   8.308   7.883   7.778   9.209   7.988   9.528   7.844  25.194\n",
      "   7.845 186.      8.726   9.137   7.776   7.708   7.976   7.863   7.509\n",
      "   8.209   8.097   7.704   9.022   7.706   7.96    7.525  25.154   8.078\n",
      "   7.894  10.546   9.432  25.613   9.73  157.      7.614 122.      7.94\n",
      "   8.096   7.828   7.861   7.717   7.823  12.789  11.951   7.631   7.952\n",
      "   7.874   7.761   8.069   7.754   8.06   12.      8.108  29.762  20.984\n",
      "  11.495   7.777  14.756  17.375   7.742   8.712   8.061   7.719   7.789\n",
      " 115.      7.826   7.678  11.233   8.822  11.3    11.444  14.047  16.218\n",
      "   7.664  14.351   7.746 124.     24.235  12.3    10.9     9.414 159.\n",
      "   5.6    12.6     9.915   9.597   5.3     7.95   28.612 108.      5.5\n",
      "  10.8   145.      7.964   8.042   7.762   8.138   8.828 234.      7.967\n",
      " 226.      8.367   8.16    8.17    9.535  12.935   9.293 123.    103.\n",
      " 249.     12.1   191.     11.062   8.355  11.8    11.5   168.      1.\n",
      " 224.    116.    106.    126.    273.     11.9   134.     11.    114.\n",
      " 162.      5.1     4.6    13.8   182.    175.    111.    383.    137.\n",
      " 154.     11.2    12.2   218.     16.2    15.5   105.    150.    139.\n",
      "  12.5     3.4   173.      2.8    13.7     1.6    11.4    12.7   110.\n",
      " 127.    153.   ]\n",
      "Phosphorous [  3.4     1.4     1.9     3.5     3.2     3.3     2.811   2.2     4.417\n",
      "   3.024   1.6     3.6     5.5     1.8     4.35    2.693   4.5     2.4\n",
      "   3.184   4.4     1.2     4.6     2.9     3.931   2.1     4.257   2.408\n",
      "   2.85    4.397   2.835   2.44    2.992  10.6     3.492   1.3     3.431\n",
      "   5.3     1.7     3.884   3.022   2.346   2.8     2.75    3.1     4.368\n",
      "   2.6     2.7     3.965   2.83    2.541   4.096   2.3     2.442   3.095\n",
      "   2.386   3.777   2.857   2.645   2.771   4.      3.      2.305   2.5\n",
      "   1.5     3.379   2.447   2.336   4.1    10.2     2.309   2.299   2.815\n",
      "   2.628   2.353   2.843   3.22    3.034   2.854   4.2     2.53    2.314\n",
      "   2.867   2.549   2.465   2.965   2.977   2.964   2.546   2.457   0.9\n",
      "   2.649   2.976   3.341   2.773   3.108   4.9     3.7     2.842   2.\n",
      "   3.115   2.497   4.318   2.687   2.27    2.784   2.32    2.272  11.5\n",
      "   2.431   2.767   2.813   2.205   2.398   2.364   1.      2.633   3.456\n",
      "   3.649   2.755   4.029   2.722   2.582   3.606  10.4     2.787   4.17\n",
      "   2.859   3.001   2.264   2.619   3.661   2.644   2.461   2.944   1.1\n",
      "   4.226   2.682   3.124   6.      2.235   4.3     2.433   2.974   2.345\n",
      "   2.871   3.248   2.316   2.751   3.051   3.9     2.832   2.818   3.973\n",
      "   4.031   2.701   2.938   3.33    2.502   2.412  10.9     3.473   2.654\n",
      "   2.663   3.927   3.056   2.906   2.622   2.366   3.076   2.607   3.189\n",
      "   3.91    4.222   3.638   2.427   3.011   2.371   4.276   7.7     2.416\n",
      "   4.149   2.349   2.154   2.327   2.852   2.277   2.256   4.617   2.951\n",
      "   3.111   2.275   3.333   3.007   2.428   2.679   2.377   2.298   2.337\n",
      "   2.381   3.449   2.192   2.527   4.56    3.096   3.165   2.912   2.367\n",
      "   2.598   2.776   2.149   3.817   2.121   2.55    8.      4.261   4.343\n",
      "   2.448   2.347   2.117   2.979   2.28    2.467   5.9     4.183   4.7\n",
      "   2.362   2.531   2.572   2.719   3.204   2.99    2.684   2.303   2.439\n",
      "   2.41    2.423   4.584   0.8     2.301   2.435   2.796   2.926   2.666\n",
      "   2.563   2.507   2.34    2.547   3.717   2.946   2.339   4.144   3.519\n",
      "   3.342   2.23    2.405   7.      2.865   2.772   2.905   2.342   2.355\n",
      "   4.262   2.388   3.089   2.328   4.396   2.601   2.338   2.535   4.066\n",
      "  10.5     2.323   2.376   2.941   2.949   2.426   2.161   2.822   2.268\n",
      "   3.769   3.408   4.167   2.508   2.669   2.524   5.661  20.      3.8\n",
      "   2.325   3.852   3.941   2.344   2.971   4.258   2.358   2.982   2.521\n",
      "   2.296   2.424   3.083   2.302   4.259   3.222   2.493   2.975   2.699\n",
      "   5.      2.372   2.889   2.528   0.5     2.382   2.324   3.952   2.466\n",
      "   2.208   2.396   2.385   4.123   2.532   2.315   2.246   2.626   3.365\n",
      "   2.19    4.336   3.42    3.291   2.789   4.375   0.7     2.986   2.199\n",
      "   5.6     2.928   2.441   4.369   2.762   2.389   3.388   2.515   2.361\n",
      "   2.895   2.472   2.665   3.24    3.136   4.299   2.729   2.293   2.36\n",
      "   2.499   3.317   4.239   2.258   2.141   2.295   2.373   2.359   2.173\n",
      "   2.957   4.693   5.1     2.658   2.866   2.234   2.392   3.253   3.084\n",
      "   2.749   2.401   3.145   4.078   2.551   2.227   2.455   2.523   2.603\n",
      "   2.175   2.525   2.933   2.434   2.202   2.879   3.005   2.308   2.63\n",
      "   2.673   3.667   2.543   2.476   3.181   2.635   2.294   2.58    2.38\n",
      "   2.273   3.929   2.617   2.375   2.464   4.446   2.284   3.92    2.267\n",
      "   2.47    4.408   2.667   3.078   2.611   2.352   2.317   2.26    0.6\n",
      "   8.4     3.046   3.044   2.229   2.111   3.018   2.943   2.724   2.907\n",
      "   3.607   2.16    2.333   2.743   2.397   2.289   3.195   3.132   2.25\n",
      "   2.479   2.471   2.517   2.966   3.795   4.269   2.698   2.534   2.374\n",
      "   2.486   4.223   2.927   3.382   3.117   2.478   2.37    2.519   2.739\n",
      "   4.8     2.463   2.969   2.945   2.837   2.383   2.624   2.182   2.343\n",
      "   2.967   2.313   2.686   2.357   2.319   2.613   2.307   2.341   3.255\n",
      "   2.878   2.35    2.418   3.02    2.285   2.306   2.332   5.8     2.446\n",
      "   2.648   2.844   2.86    3.658   2.274   2.116   2.794   2.174   2.691\n",
      "   2.828   2.863   2.354   2.221   2.204   2.378   2.158   2.716   3.415\n",
      "   3.18    2.393   2.591   2.952   3.131   5.524   2.217   2.247  10.1\n",
      "   2.164   2.402   2.529   2.595   4.457   3.657   2.128   2.432   2.584\n",
      "   2.64    2.356   2.189   4.238   2.399   2.45    4.672   3.507   2.902\n",
      "   2.368   4.61    3.642   2.254   3.019   2.614   2.12    5.2     6.2\n",
      "  11.8     2.706   2.213   0.3     3.092   0.      0.4     2.821   4.316\n",
      "   6.7     2.263   2.552   4.484  12.6     5.4     4.674   2.413   3.93\n",
      "   2.77    2.454   2.735   3.885  10.      2.861   2.631   2.159   2.255\n",
      "   2.609  11.4     2.947   6.1     3.372   2.918  10.3    10.8   143.\n",
      "  10.7    12.7    11.6    11.   ]\n",
      "BUN [ 14.    19.    15.    20.    34.17 101.    46.84  38.53  18.    64.\n",
      "  48.59  32.58  25.    16.    33.94 102.    10.    42.05  11.    38.88\n",
      "  30.29  35.27  51.11  34.28  40.21  38.08  34.    34.85  39.95  23.\n",
      "  27.    39.82  38.38  39.78  22.    30.44  29.    17.    31.29  54.\n",
      "   8.    47.85  45.04  37.92  37.73  53.    29.37  36.7   32.33  13.\n",
      "  51.21  31.98  24.    34.11  30.    57.    30.61  26.    71.    49.95\n",
      "  41.31  33.8   38.    24.71  51.    26.52  43.97  31.93 100.    41.81\n",
      "  43.71  27.63  37.97  48.    34.96  29.55  62.    31.11  25.77  25.2\n",
      "  38.06  33.95  42.92  37.69  38.01  35.02  26.76  31.62  57.11  49.8\n",
      "  44.    39.    51.05   7.    70.    29.23  45.57  50.04  35.72  25.02\n",
      "  33.81  43.28 110.    37.76  37.31  40.78  24.87  25.44  34.21  38.9\n",
      "  51.54   5.    37.93  44.8   32.1   31.23  26.59  43.88 116.    45.\n",
      "  44.12  52.84  30.42  26.91  31.91  26.45  50.88  28.    31.71  26.74\n",
      "  42.15  45.74  42.89  21.    30.64  31.    40.67   1.    44.68  40.02\n",
      "  28.73  12.    32.15  37.25  19.59  28.43  45.86  44.29  25.53  28.64\n",
      "  50.    33.61  46.98  32.09  36.53  29.31  50.59  28.52  25.09 108.\n",
      "  32.18  30.85  32.    29.9   47.    31.14 111.    31.49  39.34  28.13\n",
      "  43.    28.7   30.9   41.21  42.93  51.69  61.    23.45  47.36  44.59\n",
      "  48.07  21.56  27.04  32.13  50.91  54.79  24.68  32.02  51.9   48.27\n",
      "  44.34  34.04  31.44  31.81  24.7   27.11  24.26  33.38  21.9   34.58\n",
      "  51.37  41.79  55.35  24.92  30.65  39.76  25.64  33.55  47.76  22.92\n",
      "  39.13  76.    20.89  69.    29.13  40.    41.    44.13  45.21  41.19\n",
      "  30.39 106.    23.28 107.    21.62  21.42  27.34  29.11  31.67  39.65\n",
      "  30.55 130.    34.02  45.12  33.    49.    46.41  34.49  26.39  23.59\n",
      "  31.4   33.23  44.89  56.06  24.9   40.74  28.87  72.    19.05  18.2\n",
      "  44.08  31.38  28.11  40.88  24.47  43.45  41.41  33.54  35.68  38.71\n",
      "  55.    33.86  47.05  34.06  37.    27.59  24.61  32.22  29.51  29.62\n",
      "  28.47  23.01  48.23  29.26   4.    38.28  39.7   38.86 103.    41.05\n",
      "  26.31  37.89  27.05  31.39  52.3   33.92  19.7   50.17  23.14  37.33\n",
      "  33.62  28.83  37.64  37.22  25.86  33.01  63.    39.54  44.66  50.46\n",
      "  28.93  25.58   9.    59.    52.67  40.38  22.3   29.04  45.02  25.68\n",
      "  26.27  28.51  47.25  49.04  15.33  48.88  32.04  53.28  42.65  35.49\n",
      "  22.65  47.29  33.72  74.    45.06  23.47  34.75  25.16  56.55  58.\n",
      "  36.    38.7   36.12  25.69  19.83  39.06  49.57  28.09  23.97  29.22\n",
      "  28.54  56.    25.89  55.11  57.2   36.32  30.09  48.53  25.8   39.71\n",
      "  23.41  20.16  21.01  32.88  25.45  29.53  27.13  27.81  45.34  39.11\n",
      "  26.33  21.45  24.54  28.41  30.69  35.    33.66  46.5   42.59  37.58\n",
      "  43.61  24.59  29.8   34.27  52.78  25.65  16.98  32.68  55.76  27.29\n",
      "  31.25  25.33  33.79  22.42  30.43  36.68  47.56  28.99  60.    54.38\n",
      "  44.02  38.2   41.01  22.83  24.79  46.52  22.63  30.58  27.06  45.36\n",
      "  45.55  35.11  25.73  29.79 137.    33.26  33.57  38.26  23.48  36.57\n",
      "  27.3   26.06  19.61  37.87  23.88  39.14  37.19  28.23  31.2   26.1\n",
      "  35.15   2.    49.77  43.6   31.58  26.66  30.19  26.82  30.99  48.18\n",
      "  37.59 131.    30.79  59.43  37.21  56.93 112.    32.47  21.04  30.87\n",
      "  23.8   43.92  45.51  42.1   24.13  27.15  25.81  55.58 143.    43.53\n",
      "  30.7   20.3   31.59  34.09  23.66  36.54  43.19  28.49  57.73  44.45\n",
      "  22.82  28.28  44.5   26.99  29.39  37.48  44.52  21.82  28.61  26.65\n",
      "  37.14  36.39  31.37  59.99  48.54  35.45  30.12  25.56  40.18  36.02\n",
      "  52.    31.47  31.15  48.08  35.53  30.98  31.84  23.79  46.51  31.51\n",
      "  40.01  28.62  28.1   43.39  49.4   25.05  21.86  38.72  26.37  22.61\n",
      "  28.96  24.66  40.44  42.    23.81  44.49  28.06  42.27  36.67  52.24\n",
      "  32.29  42.73  45.62  27.16  29.32  15.34  44.95  52.91  28.57  39.97\n",
      "  32.12  21.36  22.49  47.89  16.9   65.    35.31  23.61 109.    45.96\n",
      "  40.29  32.24  34.33  22.01  31.31  36.92   6.    48.77  46.49  22.81\n",
      "  25.38  46.79  15.08  40.41  44.76  49.35  43.11  95.    53.23  29.49\n",
      "  40.08  25.49  45.49  21.38  42.79  38.57  31.99  47.59  51.26  42.95\n",
      "  28.17  23.57  32.01  49.5   45.98  43.09  46.67  60.14  54.08  52.97\n",
      "  32.66  56.38  27.09  42.51  26.6   33.15 104.    29.15  24.35  31.32\n",
      "  25.63  25.72  46.77 113.    73.    22.7   28.84  39.66  29.16  24.17\n",
      "  29.83  30.01  46.57  27.58  49.74  41.58  46.    58.94  22.2   51.02\n",
      " 105.    49.15  31.83  19.24  66.    42.9   80.    44.35  24.67  35.71\n",
      "  62.14  23.39  42.82  43.52  20.51  35.81 114.    45.41  25.04   3.\n",
      "  14.87  26.85  28.94  33.34 121.    47.27  32.05 122.   128.   115.\n",
      " 118.   117.   120.     0.   175.  ]\n",
      "O2.saturation.pulseoxymetry [100.    83.    68.04  92.96   0.    81.79  93.35  85.43  98.92  99.57\n",
      "  95.41  90.08  97.62  97.52  75.42  99.96  98.49  97.86  99.43  91.17\n",
      "  96.45  96.56  89.86  93.55  96.48  94.27  88.56  95.66  97.84  97.96\n",
      "  97.11  99.86  81.56  99.87  97.39  97.75  96.96  87.99  97.37  99.67\n",
      "  98.96  97.66  97.72  97.63  97.58  98.53  99.58  98.75  99.79  95.\n",
      "  99.88  99.63  99.82  99.72  97.57  93.82  98.58  99.42  99.37  99.89\n",
      "  99.33  80.96  87.64  97.27  98.89  95.68  93.    98.62  79.7   99.69\n",
      "  98.76  97.81  99.46  91.96  99.55  98.3   81.67  91.    94.66  98.13\n",
      "  91.89  97.67  88.24  96.69  86.88  99.38  85.    99.6   97.01  85.81\n",
      "  97.47  98.48  83.35  95.94  99.36  81.    93.63  96.71  94.85  99.71\n",
      "  90.    98.2   99.34  88.63  98.45  98.56  99.04  98.46  86.    98.47\n",
      "  81.64  92.    99.    99.85  96.6   99.78  83.61  99.74  99.62  99.83\n",
      "  95.29  99.52  98.51  95.06  96.26  85.01  94.8   86.65  85.28  89.\n",
      "  99.28  97.15  84.41  92.94  89.84  90.73  99.66  99.73  99.65  99.56\n",
      "  99.75  99.9   99.45  99.92  85.79  90.68  85.88  82.75  96.11  93.65\n",
      "  93.74  83.39  99.3   98.29  87.    88.    91.21  94.    92.72  92.47\n",
      "  98.    99.77  81.03  99.54  89.73  99.8   98.82  98.17  98.67  98.36\n",
      "  97.82  98.87  98.73  80.94  95.73  99.5   93.59  96.61  93.79  98.28\n",
      "  98.71  94.12  99.93  99.84  97.21  84.45  84.57  98.86  99.53  99.21\n",
      "  94.82  92.45  90.78  86.4   99.81  96.17  87.63  92.88  10.    97.99\n",
      "  84.38  96.52  95.4   95.88  97.88  97.7   99.91  97.95  80.38  99.39\n",
      "  87.9   81.68  84.94  96.89  97.92  96.16  85.46  98.99  93.98  99.7\n",
      "  98.1   96.59  82.5   98.78  93.09  97.91  93.69  93.53  96.06  95.91\n",
      "  98.72  99.59  99.68  95.04  99.01  98.66  88.27  96.94  95.72  99.95\n",
      "  98.34  95.56  81.93  86.59  95.64  98.7   85.93  98.83  96.82  95.6\n",
      "  91.67  97.1   97.65  99.25  82.35  93.91  58.    97.09  94.23  97.55\n",
      "  87.48  85.39  99.44  98.68  98.93  96.24  97.69  98.24  98.91  96.95\n",
      "  98.79  84.    92.62  96.32  98.77  93.14  94.03  97.41  99.15  99.47\n",
      "  96.81  98.55  94.48  97.61  78.    96.78  96.08  98.38  96.87  95.97\n",
      "  97.29  92.05  99.48  98.21  84.3   97.3   83.81  85.53  95.09  80.25\n",
      "  91.47  94.78  95.59  97.73  97.85  99.76  88.94  93.13  99.99  90.53\n",
      "  98.65  98.04  98.9   84.69  98.4   99.61  93.15  96.84  96.    98.8\n",
      "  84.02  79.25  97.    85.67  96.76  97.04  97.34  94.94  96.5   80.\n",
      "  95.67  95.15  98.63  60.    97.54  88.6   98.25  19.    99.1   73.\n",
      "  95.81  96.8   38.    97.71  93.87  88.76  82.    61.    94.09   1.\n",
      "  79.  ]\n",
      "Admission.Weight..Kg. [ 66.8 106.2  98.  ...  42.7  45.1 124.8]\n",
      "Heart.Rate [115.   100.    54.    81.18   0.    52.96  87.36  60.    55.    65.57\n",
      "  85.38  83.9  102.    67.    70.3   65.64  88.48  75.69  59.7   88.91\n",
      "  81.77  84.69 103.    83.75  75.98 -88.    75.79  88.47  80.3   89.45\n",
      "  31.    93.08 139.    86.67  77.    72.03  78.88  89.37  89.49  66.\n",
      "  91.6   81.4   90.68  38.    68.95  90.78  90.41  82.69 101.    61.\n",
      "  93.03  70.    51.    69.95  88.13  90.33  47.    94.95  93.07  63.\n",
      "  88.77  87.95  82.09  82.32  86.6   27.    81.24  84.38  88.94  95.41\n",
      "  93.36  95.79  89.35  88.45  83.47  79.89  86.76  87.46  88.82  91.81\n",
      "  94.91  63.36  73.94  90.09  83.4   79.51  58.    56.    78.36  57.\n",
      "  83.27  63.24  83.05  62.    95.15  88.16  93.01  90.64  90.94  84.07\n",
      "  83.25  96.39  94.84  87.52 153.    91.91  77.41 104.    77.45  84.67\n",
      "  77.69  93.38  83.48  92.21  68.31 110.    53.    64.    78.66  66.04\n",
      "  85.81  88.01  69.    96.95  82.42  81.92  66.07  85.45  95.61  81.94\n",
      " 167.    68.97  81.65  72.45  52.    86.82  81.15  89.94 105.    91.89\n",
      "  93.19  89.29  89.59  73.76  77.92  86.01  89.53  76.    85.43  87.62\n",
      "  83.21  63.98  89.78  86.2   88.42  94.06  78.55  92.35  95.54  80.\n",
      "  90.55  96.91  95.24  93.31  81.73  80.21  97.51  77.98  88.23  72.\n",
      "  96.13  94.23  81.88  72.91  78.78  98.56  86.17  68.08  82.34  68.48\n",
      "  59.    89.68  96.07  94.58  88.53  89.43  80.88  97.93  67.94  77.21\n",
      "  92.62  90.19  85.49  75.72  83.6   87.78  43.    89.25  98.81  95.58\n",
      "  91.24  92.71  77.15  93.77  94.93  61.16  76.83  74.    89.87  97.63\n",
      "  83.89  93.24  96.88  77.79  92.9  107.    92.02  96.57  83.91  73.\n",
      "  79.    84.41  73.15 106.    62.9   89.97  85.73  94.2   97.28  97.72\n",
      "  90.24  91.7   95.38 108.    89.89  95.84  68.    96.38  82.57  89.55\n",
      "  73.84  75.45  90.75  96.33  95.28  48.    92.98  97.99  96.42  88.37\n",
      "  57.66 109.    79.57  44.    95.51  92.49  39.    84.54  86.13  86.37\n",
      "  94.99  79.48  89.48  90.34  92.31  71.    88.97  87.61  49.    77.64\n",
      "  94.61  87.64  83.62  83.78  94.16  96.2   95.7   91.79  95.98  91.06\n",
      "  89.46  59.21  87.17  91.28  77.39  91.15  87.87  90.54  93.22  87.75\n",
      "  85.    93.63  85.68  82.82  96.79  78.43  99.1   80.98  97.03  69.87\n",
      "  92.26  91.09  88.28  97.65  98.42  87.13  92.89  72.99  70.05  65.\n",
      "  92.13  96.51  62.82  83.63 150.    50.    97.34  88.76  86.19  95.03\n",
      "  97.23  92.92 114.    72.04  97.88  90.29  76.67  30.    98.55  77.06\n",
      "  82.11  81.98  87.69  85.42  82.59  95.43  86.57 112.    91.32  92.19\n",
      "  95.26  86.94  79.92  93.98  92.72  46.    93.75  94.79  98.18  91.04\n",
      "  88.41  85.61  93.14  98.06  90.67  94.87  69.42  94.82  66.24  82.77\n",
      "  91.9   91.48 116.    78.94  95.71  89.83  91.65  95.88  84.    91.98\n",
      "  91.67  98.48  89.15  70.54  86.21  91.73  77.07  95.29  75.96  95.3\n",
      "  89.19  97.35  82.41  93.86  87.09  72.16  91.96  84.47  89.81  98.64\n",
      "  85.82  95.82  94.33  89.01  61.02  93.48  89.23  97.89  87.12  92.24\n",
      "  86.07  93.54  94.02  96.31  97.71  91.54  90.11  74.36  77.75  59.81\n",
      "  87.94  80.16  93.35  94.45  94.01  72.82  91.69  84.42  90.66  85.91\n",
      "  95.14  94.97  93.25  90.51  90.71  99.13  91.77  90.12  92.79  95.08\n",
      "  86.55  74.01  91.46  85.18  89.16  82.5   61.92  92.15  95.75  75.6\n",
      "  89.1   92.82  90.86  93.93  80.86  97.04  84.45  91.82  90.3   82.73\n",
      "  83.11  76.34  91.74  94.75  61.74  74.21 111.    93.42  96.45  92.76\n",
      "  72.32  92.03  86.83  92.44  86.52  95.68  98.45  85.5   76.97  76.24\n",
      "  97.47  96.72  79.43  88.22  91.12  80.95  75.13  70.82  90.1   97.09\n",
      "  93.29  90.89  91.37  94.88  96.09  76.64  81.45  96.41  92.74  74.73\n",
      "  89.92  91.02  73.75  87.54  94.66  95.16  88.07  22.    88.92  79.82\n",
      "  72.47  85.02  96.64  92.37  86.75  92.27  85.52  93.82  89.27  92.53\n",
      "  98.14  91.61  88.78  98.51  87.11  97.24  93.91  93.94  92.09  80.6\n",
      "  93.45  88.33  88.87  72.9   86.22  98.33  92.6   91.26  82.    91.\n",
      "  98.17  92.55  91.01  74.22  94.8   86.46  73.27  79.35  97.22  96.26\n",
      "  96.69  81.    84.94  75.    98.1   91.68  96.46  87.82  95.62  98.87\n",
      "  93.73  97.76  93.83  95.39  81.83  97.12  93.8   90.77  83.58  94.3\n",
      "  93.62  80.2   94.1   85.19  84.8   78.35  75.01  92.84  41.    83.23\n",
      "  94.39  94.54  90.36  80.8   97.05  90.08  89.95  90.58  68.3   23.\n",
      "  94.19  90.49  91.16  91.33  97.21  95.63  85.65  89.24  86.79  67.28\n",
      "  68.38  81.07  92.07  70.89  95.94  45.    71.61  96.53  92.63  87.81\n",
      "  87.39  98.23  95.57  92.67  88.02  75.16  81.09  97.61  92.58  90.69\n",
      "  90.26  92.43  98.99  88.35  97.68  94.98  97.53  74.33  95.02  97.58\n",
      " 101.02  85.47  79.45  81.33  93.57  92.83  88.61  96.87  90.27  98.73\n",
      "  84.97  94.41  86.09  68.78  87.22  95.59  79.53  90.    79.44  92.28\n",
      " 161.    75.48  88.36  85.77  90.57  97.14  93.85  92.05  93.84  26.\n",
      "  62.05  84.09  87.85  97.83  91.47  92.34  99.25  95.77  86.9   71.34\n",
      "  95.11  93.17  93.39  64.59  88.55  92.16  84.03  96.74  95.66  96.21\n",
      "  83.    93.33  79.56  93.37  79.65  87.79  96.93  88.29  88.31 135.\n",
      "  93.44  87.51  81.86  94.89  70.38  92.17  82.06  85.14  93.64  85.58\n",
      "  93.55  40.    89.63  85.21  94.7   92.56  91.58  96.3   77.58  85.96\n",
      "  81.89  95.47  95.95  87.08 102.11  89.    92.    72.64  96.35  86.23\n",
      "  93.3   84.95 190.    98.46  99.35  83.57  75.09  94.07  42.    96.89\n",
      "  87.91  98.34  95.65  77.46  97.91 120.    95.07  32.   118.    -1.\n",
      "   1.   113.    34.   134.    28.   130.    36.   119.  ]\n",
      "HCO3..serum. [ 25.    24.    17.    21.    12.    20.41  15.    16.85  18.71  20.\n",
      "  18.01  18.85  27.    22.    20.37  18.34  18.64  19.86  18.43  17.3\n",
      "  19.5   18.1   18.9   19.    18.18  23.    14.    18.26  18.67  18.42\n",
      "  18.    19.83  19.14  17.89  17.97  18.12  31.    18.52  22.85  20.46\n",
      "  16.84  20.38  19.52  26.    19.15  19.31  28.    17.22  18.41  18.99\n",
      "  10.    19.21  29.    19.58  18.35  18.91  17.94  17.92  21.84  18.68\n",
      "  16.    20.36  20.29  19.66  20.92  20.28  20.51  20.45  18.36  19.61\n",
      "  20.83  19.16  20.08  20.71  17.96  18.59  13.    17.59  22.11  17.93\n",
      "  17.25  19.26  18.79  19.91  18.55  18.51  19.72  19.1   30.    18.58\n",
      "  16.9   36.    17.99  18.21  18.89  17.57  19.39  18.22  18.74  17.72\n",
      "  22.76  21.81  18.93  19.02  16.55  22.59  19.95  17.26  17.85  24.11\n",
      "  19.03  18.39  18.45  18.88  20.56  18.78  22.16  23.52  17.37  17.79\n",
      "  17.51  21.68  11.    20.54  19.41  16.08  18.8   32.    19.05  22.23\n",
      "  19.79  19.06  18.87  20.44  17.75  19.18  19.68  19.53  21.58  18.48\n",
      "  17.86  20.63  18.05  17.36  17.15  20.78  19.6   22.57  19.01  21.37\n",
      "  18.09  16.95  18.62  19.57  17.32  18.61  17.63  21.35  33.    19.45\n",
      "  19.42  20.4   19.7   17.45  19.8   19.09  21.12  20.76  19.38  22.63\n",
      "  19.89  18.24  34.    21.76  17.64  16.83  20.48  19.48  20.87  18.38\n",
      "  17.65  16.8   21.6   21.82  17.54  20.2   35.    18.08  21.1   18.17\n",
      "  22.35  19.64  19.08  17.23  20.16  20.11  20.05  20.04  16.98  20.89\n",
      "  18.4   18.69  21.83  21.08  17.69  19.35  17.87  20.3   18.31  20.68\n",
      "  20.98  19.11  17.46  19.81  16.77  20.31  20.24  20.14  23.59  18.97\n",
      "  18.25  20.39  21.73  18.2   19.2   19.22  19.94  18.56  21.46  19.47\n",
      "  18.96  21.05  18.23  18.54  18.75  20.21  20.42  21.87  16.05  17.29\n",
      "  21.51  18.07  19.63  20.86  20.07  22.1   18.6   23.43  19.88  22.93\n",
      "  19.4   18.5   19.69  21.77  21.74  20.02  23.45  19.55  19.73  19.17\n",
      "  16.58  19.29  19.51  18.7   17.44  20.12  19.07  19.12  18.49  20.01\n",
      "  22.47  16.2   17.98  18.04  18.15  19.84  23.07  19.67  18.53  19.44\n",
      "  21.93  20.18  19.25  21.79  18.06  17.9   18.72  19.04  21.33  20.93\n",
      "  18.29  19.59  16.72  19.32  20.47  17.83  18.14  21.42  19.49  17.5\n",
      "  18.46  18.02  18.83  19.13  18.47  16.48  20.84  19.37  20.9   18.03\n",
      "  17.39  19.74  23.56  18.16  21.25  17.01  16.39  19.43  18.63  21.64\n",
      "  20.57  23.02  19.75  21.45  17.73  18.28  21.28  21.27  18.77  19.46\n",
      "  18.57  21.78  20.65  20.27  18.27  20.26  17.6   16.64  19.82  19.23\n",
      "  22.77  18.94  20.17  22.33  17.33  17.17  19.3   20.81  40.    18.33\n",
      "  17.71  19.62  20.85  17.56  22.21  18.65  19.93  19.65  19.27  19.96\n",
      "  17.95  16.11  19.77  20.75  19.85  48.    17.81  18.76  16.24  15.65\n",
      "  19.71  20.8    0.    16.23  21.3   16.04  16.89  21.65  15.94  21.19\n",
      "  19.54  21.85  37.   107.   197.  ]\n",
      "Anion.gap [ 12.    10.    14.    18.    11.    20.    11.61  14.56  11.75  12.75\n",
      "  11.56  11.57  17.    16.    12.51  12.83  10.79  12.34  14.73  11.44\n",
      "  11.46  19.    12.57  11.82  15.    12.55  11.88  10.83  10.91  13.\n",
      "  11.07  15.19  12.13  10.72  11.09  10.9   11.99  10.65  12.93  11.41\n",
      "  10.89  11.9   10.56  12.31  11.22  10.7   45.    11.3   10.96  11.53\n",
      "  11.63  12.07  10.82  10.76  11.36  10.99  10.73  11.54  11.66  10.57\n",
      "  10.8   11.6   11.91  11.17  11.35  14.01  11.67  10.75  10.52  10.86\n",
      "  10.66  10.61  11.12  11.03  12.37  13.36  11.38  10.54  23.    11.45\n",
      "  13.67  11.08  11.8   12.52  11.47  13.6   11.19  21.    10.69  10.85\n",
      "  10.63  10.67  11.55  10.81  11.89  12.08  11.4   10.74  11.01  13.25\n",
      "  11.27  11.04   8.    11.79  10.44  12.19  10.6   12.17  12.44  10.46\n",
      "  12.03  12.2   15.29  10.84  10.32  14.04  12.77  10.37  11.52  14.85\n",
      "  11.72  11.39   9.    10.64  10.58  13.39  10.43  10.59  14.17  10.95\n",
      "  10.55  11.28  10.5   10.48  10.38  25.    13.49  11.32  10.51  11.5\n",
      "  10.68  10.35  10.93  11.24  12.29  11.92  11.73  11.31  10.49  11.14\n",
      "  10.45  13.93  10.77  11.96  12.43  11.34  14.71  12.1   11.06  11.29\n",
      "  10.97  10.47  12.7   11.93  14.92  12.22  14.28  11.13  11.87  10.23\n",
      "  11.21  12.85  10.53  10.62  11.83  11.37  11.43  12.65   7.    13.04\n",
      "  11.11  10.98  10.24  11.86  11.49  11.94  11.58  11.1   13.65  10.4\n",
      "  10.87  10.29   1.    11.85  14.86  11.68  11.16  11.51  12.74  11.25\n",
      "  14.94  12.66  14.3   26.    11.2   -3.    10.27  12.48  12.38  10.34\n",
      "  13.12  10.42  10.39  12.72  12.96  10.94  11.33  12.09  11.23  10.71\n",
      "  11.59  12.11  14.4   10.25  12.12  19.92   0.    11.26  11.15  13.84\n",
      "  12.78  14.36  14.02  13.53  10.41  13.33  10.78   6.   -21.  ]\n",
      "Potassium..serum. [ 3.4000e+00  3.2000e+00  3.9000e+00  3.3000e+00  3.5000e+00  1.9000e+00\n",
      "  3.5740e+00  3.1000e+00 -7.0120e+00  3.6090e+00  3.7000e+00  3.8000e+00\n",
      "  4.9540e+00  3.5460e+00  4.6000e+00  3.7950e+00  4.0000e+00  4.9410e+00\n",
      "  2.9000e+00  3.6740e+00  3.4360e+00  3.4670e+00 -1.2698e+01  3.4960e+00\n",
      "  3.4590e+00  3.5260e+00  3.7080e+00  3.5760e+00  3.0000e+00  3.6890e+00\n",
      "  3.5670e+00  3.4490e+00  4.1000e+00  3.6230e+00  3.5540e+00  3.7050e+00\n",
      "  3.5600e+00  3.4160e+00  3.4930e+00  3.4050e+00  3.8210e+00  3.5160e+00\n",
      "  3.6000e+00 -3.5890e+00  3.5680e+00  3.6180e+00  3.3650e+00  4.9150e+00\n",
      "  3.4410e+00  3.4380e+00  3.4250e+00  3.4740e+00  3.4460e+00  3.5210e+00\n",
      "  3.4850e+00  4.7000e+00  3.8580e+00  3.6350e+00  3.4910e+00  3.4940e+00\n",
      "  5.0000e+00  3.6080e+00  3.5490e+00  3.5220e+00  3.5080e+00  3.5890e+00\n",
      "  3.4790e+00  3.4810e+00  3.4990e+00  3.5710e+00  3.4830e+00  3.5240e+00\n",
      " -4.9000e-02  6.7000e-02  4.4000e+00  3.4610e+00  3.7680e+00  3.4500e+00\n",
      " -9.1420e+00  4.2000e+00  3.5110e+00  3.3840e+00  3.5880e+00  3.3870e+00\n",
      "  3.3970e+00  3.5410e+00 -3.6570e+00  2.6000e+00  3.6460e+00  3.4730e+00\n",
      "  3.3990e+00  3.4470e+00  3.4720e+00  1.6900e-01  4.3000e+00  3.5230e+00\n",
      "  1.4040e+00  3.7170e+00  3.7850e+00 -3.7500e+00  3.7230e+00  3.3340e+00\n",
      "  3.4880e+00  2.8000e+00 -1.9790e+00  3.4760e+00  3.8360e+00  4.5000e+00\n",
      "  5.2000e+00  3.4240e+00  3.4040e+00  3.4330e+00  2.5000e+00  3.5930e+00\n",
      "  3.8380e+00  3.8180e+00  4.7980e+00  3.4290e+00  3.4480e+00  3.7330e+00\n",
      "  3.5560e+00  3.5840e+00  2.1000e+00 -3.1923e+01  2.4000e+00  2.3000e+00\n",
      "  3.5990e+00  3.5610e+00 -3.8000e-02  3.4170e+00  3.4200e+00  3.7710e+00\n",
      "  3.4400e+00  3.4450e+00  4.8000e+00  3.6790e+00  3.4860e+00  3.5180e+00\n",
      "  3.4680e+00  3.3920e+00  3.7530e+00  3.7740e+00 -1.0500e-01  3.4100e+00\n",
      " -3.3300e+00  3.4750e+00  1.8000e-02  4.9000e+00  3.3780e+00  3.3750e+00\n",
      "  3.4220e+00  3.7300e+00  3.3910e+00  3.3710e+00 -6.8210e+00  3.5750e+00\n",
      "  3.6450e+00  4.8570e+00  3.5730e+00  3.3860e+00  3.3880e+00  3.4060e+00\n",
      "  3.5900e+00  3.3560e+00 -9.2470e+00 -7.9000e-02  3.8320e+00  3.3590e+00\n",
      "  6.2900e+00  3.4770e+00  3.3760e+00 -1.1100e-01  2.7000e+00  3.3600e+00\n",
      "  3.2910e+00  3.4540e+00  3.8000e-02  4.8910e+00  3.4120e+00  3.3540e+00\n",
      "  3.3490e+00  3.3740e+00  3.3810e+00  3.7700e+00  3.5310e+00  3.4280e+00\n",
      "  3.3950e+00  3.6040e+00  3.5050e+00  3.3610e+00  3.5170e+00 -9.1680e+00\n",
      "  3.4080e+00  3.6140e+00  3.6620e+00  3.4010e+00  3.5190e+00  3.4140e+00\n",
      "  3.4920e+00  3.7900e+00  3.7090e+00  3.3800e+00  3.8710e+00  3.4430e+00\n",
      "  3.6020e+00  3.4260e+00  3.3820e+00  4.8650e+00  3.6710e+00 -1.0621e+01\n",
      "  3.4650e+00  3.6950e+00  3.4270e+00  3.4340e+00  3.7650e+00  3.4190e+00\n",
      "  3.3690e+00  3.7930e+00  3.5970e+00  3.4520e+00  3.5850e+00  3.6300e+00\n",
      "  3.6980e+00 -3.5550e+00  1.0000e+01 -6.8930e+00  3.4980e+00  3.3640e+00\n",
      "  3.6500e+00  3.8730e+00  3.4640e+00  3.5600e-01  3.8810e+00 -9.8000e-02\n",
      "  3.5020e+00  3.5370e+00  3.8010e+00  3.4030e+00 -1.2745e+01  3.4320e+00\n",
      "  3.3940e+00  3.3770e+00  3.3930e+00  3.5120e+00  3.5590e+00 -1.6344e+01\n",
      "  1.3570e+00  1.3050e+00  3.6720e+00 -3.6250e+00  3.3900e+00  4.9840e+00\n",
      "  3.6630e+00  3.3390e+00  3.4800e+00  3.3060e+00  3.4130e+00  3.7350e+00\n",
      "  4.8750e+00  3.8060e+00  6.3260e+00  3.4840e+00  3.4570e+00  3.6520e+00\n",
      "  3.6670e+00  3.6990e+00  3.8910e+00  3.4230e+00  4.9690e+00  3.4550e+00\n",
      "  3.4560e+00 -2.2550e+00  5.0150e+00  3.3400e+00  3.5130e+00  3.6570e+00\n",
      "  3.3850e+00  3.4210e+00  3.3470e+00  3.3830e+00  3.3660e+00  3.4390e+00\n",
      "  3.8410e+00  5.7000e+00 -9.2450e+00  3.4180e+00  3.8340e+00  3.8850e+00\n",
      "  3.5350e+00  3.4020e+00  3.3700e+00  3.7790e+00  3.5150e+00  3.8480e+00\n",
      "  3.3730e+00 -3.6040e+00  3.3890e+00  3.4530e+00  3.3270e+00  3.6370e+00\n",
      "  3.3510e+00  3.3960e+00 -9.1560e+00  1.3280e+00  3.3420e+00  3.3330e+00\n",
      "  3.7380e+00  3.7310e+00  3.4090e+00  3.5660e+00  3.3230e+00  3.4630e+00\n",
      "  3.8160e+00  3.4700e+00  3.8050e+00 -3.7320e+00  3.3980e+00  3.4110e+00\n",
      "  3.5060e+00  2.0000e+00  3.5300e+00  3.3500e+00  3.3790e+00  3.8590e+00\n",
      "  3.4070e+00  3.3530e+00  1.3400e+00 -1.0432e+01  4.9310e+00  3.9020e+00\n",
      "  3.3630e+00  3.6970e+00  3.8300e+00  3.6650e+00  3.2930e+00  3.5040e+00\n",
      "  3.4310e+00  3.4440e+00  3.3300e+00  3.7800e+00  3.6840e+00  3.2540e+00\n",
      "  2.2000e+00  3.3290e+00  5.3000e+00  3.7270e+00  3.3410e+00  3.4620e+00\n",
      "  3.7560e+00  3.6480e+00  3.4780e+00  6.4010e+00  3.7810e+00  3.5530e+00\n",
      "  3.9460e+00  1.4400e+01  1.2900e+02  3.4150e+00  1.8000e+00  3.3180e+00\n",
      "  3.4710e+00 -3.5383e+01  4.9230e+00  3.3580e+00  5.1000e+00  3.3550e+00\n",
      " -1.0615e+01 -2.1150e+00  3.7150e+00  3.3250e+00  3.4350e+00  3.6660e+00\n",
      "  3.3240e+00  3.3210e+00  3.2640e+00  3.6580e+00 -1.7731e+01  3.6960e+00\n",
      "  1.1100e+01  3.3260e+00 -1.2856e+01  3.3220e+00  1.3200e+00  3.3040e+00\n",
      "  3.5720e+00  3.3120e+00 -1.3064e+01  3.5860e+00  3.2650e+00  3.2720e+00\n",
      "  4.7280e+00  3.3070e+00  3.3100e+00  1.4300e+02  0.0000e+00  1.0200e+01\n",
      " -3.5000e+02  1.5400e+02  1.0000e+00]\n",
      "Chloride..serum. [106.   102.    92.   100.   116.   101.52  96.74 100.96 101.   105.\n",
      " 100.7  100.94 101.74 110.   100.74 101.37 101.31 101.27  95.91 100.65\n",
      " 100.67 100.51  89.   101.28 101.42 107.   100.95 100.43 104.   101.41\n",
      " 101.7  100.61 101.59 102.01 101.17 102.04 101.68  98.23 101.88 101.9\n",
      " 101.09  96.   101.91 114.    86.   100.79 100.98 103.    93.   101.54\n",
      " 100.73 101.08 100.52 100.57 102.17 101.81 101.48 102.52 103.06 100.58\n",
      " 100.78 103.1  101.55 102.1  101.33 100.08 101.01 102.58 100.56  97.13\n",
      " 101.06 101.93 102.57 101.38 101.16 101.1  101.25 111.    82.   101.32\n",
      " 101.12 100.17 102.03  99.2  102.39 100.92  97.75 101.21 101.49 100.76\n",
      "  97.67 100.4  103.16 100.9  100.77 101.07 101.43 101.13 102.25 102.76\n",
      " 101.2  101.69  84.   102.81 101.14  94.    97.26 108.   101.36 101.3\n",
      " 101.61 101.44 100.87  98.4  100.72 101.89 101.47  99.   109.   101.71\n",
      "  99.34 113.   100.85 100.83  96.67 100.48 102.14 100.91 101.11  96.15\n",
      " 100.71 100.64 101.22 102.07 100.44 100.54 101.73 102.46 100.81 101.63\n",
      "  90.   100.41 102.16 100.88 102.59 101.57 101.39 100.5  101.05 100.63\n",
      " 100.62 100.84  96.17 100.89  87.   101.45 101.82 101.5   88.   101.76\n",
      " 101.04 103.3  101.19 112.   102.45 101.4  101.35 101.78 102.06 101.34\n",
      "  96.61 100.99 101.46 101.24 102.27 102.31 101.6  101.65 101.66 102.36\n",
      " 100.09 102.87 101.53  96.41 102.56  99.45 104.57 100.59 101.83  95.\n",
      " 101.29  97.81  99.54 100.86 100.97 100.82 102.15 102.21 100.38 101.92\n",
      " 102.82 103.71 101.62 102.83 102.37 100.19 101.02 102.23 101.56 101.23\n",
      " 101.18  79.   100.68  96.1  102.02 101.8  101.67 101.72 100.45  99.36\n",
      " 101.95 100.75 101.87 100.8   95.94 100.35 101.84 115.   102.09 101.03\n",
      " 100.55 101.15 101.75 102.26 100.33  96.81 101.58 104.18 101.97 101.99\n",
      " 100.06   0.   100.39  91.    97.37 100.46 101.64  95.66 103.43 100.36\n",
      "  96.46  97.6   96.69 102.05 100.66  99.99  97.36 100.6   98.65  99.59\n",
      " 101.86 100.22  98.   100.47 100.28  75.    80.  ]\n",
      "Sodium..serum. [144.   139.   137.   136.   130.   145.   134.78 131.   125.52 133.09\n",
      " 133.   142.   130.62 133.5  134.   134.43 132.   131.96 123.   130.74\n",
      " 132.91 133.33 125.19 133.23 133.03 133.28 128.   133.04 133.39 132.63\n",
      " 135.   133.37 131.71 133.81 141.   133.7  138.   131.63 132.81 133.94\n",
      " 133.96 133.38 135.1  135.03 125.81 135.26 134.14 133.36 134.3  126.\n",
      " 129.32 132.78 133.14 143.   134.09 134.88 132.7  133.6  121.   132.94\n",
      " 132.44 140.   134.95 132.43 133.8  134.49 133.45 134.17 134.93 135.33\n",
      " 133.85 131.9  135.2  133.41 135.12 134.84 133.69 129.49 122.   127.\n",
      " 124.   132.93 135.93 132.19 125.6  132.92 133.73 125.   132.97 129.\n",
      " 135.17 135.62 133.4  132.38 133.2  133.55 132.34 133.99 122.43 131.92\n",
      " 133.27 132.74 133.05 132.42 129.09 133.68 130.04 135.02 134.46 132.89\n",
      " 123.11 134.79 132.45 146.   125.06 136.2  132.59 132.96 132.58 133.93\n",
      " 132.76 134.67 136.35 130.98 131.69 132.04 134.24 119.   135.77 124.73\n",
      " 134.77 134.15 128.79 132.52   0.   135.41 133.26 128.7  133.19 133.72\n",
      " 133.18 134.59 130.89 133.66 129.61 133.56 134.89 133.3  133.07 123.69\n",
      " 133.58 134.12 134.18 130.12 105.   132.11 132.84 133.67 134.23 133.34\n",
      " 133.61 132.14 122.41 133.29 130.86 134.08 132.99 134.91 132.5  133.11\n",
      " 133.53 133.47 134.65 128.88 134.87 135.25 135.14 133.1  135.05 133.17\n",
      " 133.08 134.26 130.42 128.95 131.68 134.37 133.13 134.2  133.12 132.56\n",
      " 119.17 133.15 133.46 133.44 133.89 134.54 133.92 134.61 135.65 134.62\n",
      " 147.   117.   133.59 135.68 130.33 134.48 124.74 132.72 120.   132.83\n",
      " 132.87 133.06 132.69 134.85 135.31 116.   132.9  132.95 133.82 112.\n",
      " 135.78 134.03 132.73 133.16 135.7  133.31 131.74 123.97 135.37 134.16\n",
      " 122.92 134.34 134.28 135.44 131.45 133.54 135.84 133.49 126.8  136.65\n",
      " 133.52 132.35 134.75 131.64 134.74 125.21 118.   134.38 134.33 124.27\n",
      " 134.05 129.95 129.94 134.19 134.96 134.8  134.66 135.47 132.68 136.77\n",
      " 133.01 132.54 134.73 134.42 135.71 132.23 131.95 133.76 122.73 134.25\n",
      " 133.21 130.6  132.61 132.65 130.77 135.01 118.1  132.49 132.66 132.06\n",
      " 133.75 133.79 134.57 135.21 133.25 132.36 132.17 132.6  132.98 134.41\n",
      " 133.97 134.01 132.48 134.68 133.48 131.8  123.63 132.33 132.77 135.28\n",
      " 134.11 119.01 129.89 129.12 131.48 134.45 133.84 133.63 132.02 130.24\n",
      " 134.32 132.28 135.66 122.3  134.9  134.47 149.   132.71 131.6  135.56\n",
      " 132.85 129.16 124.32 132.55 132.53 134.86 134.44 135.54 137.08 131.26\n",
      " 133.71 134.64 134.53 133.88 134.7  133.42 132.4  132.88 128.43 135.45\n",
      " 132.13 133.35 131.34 130.75 131.12 132.57 134.22 135.42 131.39 132.16\n",
      " 134.27 132.67 132.22 132.86 127.95 135.16 133.87 131.54 124.67 134.36\n",
      " 135.59 131.97 119.61 124.9  132.41 125.91 130.66 134.56 132.3  132.37\n",
      " 110.   124.45 134.35 130.25 124.65 102.   125.67 130.15 133.74 132.2\n",
      " 132.27 133.64 115.   122.22 114.   131.3  131.85 131.2  104.   111.\n",
      " 107.    -4.   113.   101.   108.  ]\n",
      "Creatinine [ 0.6    0.8    1.1    5.3   10.4    0.5    1.58   1.7    3.773  1.697\n",
      "  1.     3.7    2.187  1.706  1.4    0.9    1.533  1.8    0.7    5.1\n",
      "  2.081  1.99   1.234  2.377  3.591  1.502  1.511  1.564 11.1    1.926\n",
      "  2.051 10.2    1.796  1.827  1.24   2.2    1.287  1.6    1.346  2.5\n",
      "  2.749  1.918  1.249  1.275  1.9    1.338  1.579  1.384  2.602  1.614\n",
      "  1.115  0.3    1.717  3.     1.176  1.5    1.819  1.207  1.156  5.2\n",
      "  1.111  1.121  1.257  1.206  1.2    1.237  1.537  1.3    1.544  1.668\n",
      "  2.8    1.374  1.195 10.1    1.562  1.052  1.244  1.59   0.2    1.595\n",
      "  1.301  2.072  1.181  1.559  1.182  1.153  1.267  2.129  1.548  2.1\n",
      "  1.721  1.409  1.246  3.278  1.575  1.105  1.185  1.205 11.3    1.221\n",
      "  1.353  1.826  1.098  1.079  2.7    1.525  1.397  2.183  2.799  1.582\n",
      "  1.263  2.15   1.155  2.771  6.1    1.662  1.673  1.178  1.191  1.619\n",
      "  2.46   1.36   1.117  1.286  4.     0.4    3.504  1.513  5.5   10.6\n",
      "  1.129  1.18   2.6    1.172  1.134  1.572  1.163  1.034  1.493  1.442\n",
      "  1.159  3.4   10.     1.437  1.383  3.447  1.314  1.183  2.128  1.162\n",
      "  1.092  2.     6.5    1.556  1.218  1.169  1.271  2.375  3.3    1.05\n",
      "  2.193  1.174  2.125  1.808  2.662  1.268  3.1    1.004  1.19   3.425\n",
      "  1.194  3.014  0.939  1.107  1.184  1.135  1.192  4.233  1.889  1.312\n",
      "  1.481  1.23   1.751  1.222  1.15   1.202  1.109  1.133  2.4    2.226\n",
      "  1.009  3.159  2.126  2.064  1.131  1.196  1.344  1.108  1.167  1.391\n",
      "  1.01   1.279  2.3    0.94  16.2    2.9    1.224  3.162  1.138  1.215\n",
      "  1.059  0.959  0.991  1.106  1.306  1.143  4.6    3.6    5.6    1.443\n",
      "  1.214  1.737  1.42   1.704  1.08   3.2    1.017  1.208  1.21   3.787\n",
      "  1.256  1.623  1.142  0.985  1.316  1.313  1.137  1.291  2.838  1.082\n",
      "  1.278  1.467  1.173  1.16   5.9    1.204  1.678  1.716  2.478  1.088\n",
      "  1.179  1.342  4.234  1.358  4.2    2.046  1.189 12.2    1.141  3.9\n",
      "  1.152  1.604  0.907  1.635  0.995  2.895  1.709  1.288  1.327  1.186\n",
      "  1.209  1.069  1.733  1.177  2.593  2.661  1.345  1.049  3.549  1.676\n",
      "  0.925  1.534  1.265  1.065  1.136  1.453  1.188  4.1    0.779  2.782\n",
      "  1.612  1.201  1.377 10.5    1.058  1.809  1.469  1.04   1.005  2.829\n",
      "  1.193  1.168  1.114  0.923  1.113  1.767  1.067  1.355  2.045  0.961\n",
      "  2.653  1.388  1.161  1.477  1.259  1.036  1.295 10.3    1.361  1.045\n",
      "  8.3    1.041  1.048  1.885  1.402  1.334  1.49   1.102  1.476  1.126\n",
      "  1.044  1.039  1.603  1.508  1.862  1.199  1.31   1.555  1.057  1.262\n",
      "  1.231  3.313  0.983  1.266  0.815  1.243  1.211  0.945  1.12   1.512\n",
      "  1.468  3.973  1.261  1.011  1.084  1.068  1.337  1.104  1.252  1.028\n",
      "  0.944  1.122  1.154  1.051 12.7    1.688  1.128  2.742  1.229  1.253\n",
      "  0.997  1.299  1.372  3.587  1.166  2.232  1.368  0.992  1.197  0.972\n",
      "  4.532  1.086  1.09   6.7    1.694  1.563  0.89   2.913  1.464  1.545\n",
      "  2.279  0.964  1.164  1.093  1.158  0.975  2.565  1.915  0.927  1.245\n",
      "  3.5    1.35   1.225  2.305  3.836  1.127  1.438  1.85   1.72   1.648\n",
      "  1.212  1.026  2.066  1.296  1.232  1.436  0.99   1.255  1.061  1.123\n",
      "  1.097  1.027  1.054  1.147  1.638  4.8    1.336  1.615  1.029  1.553\n",
      "  1.003  1.223  1.488  0.824  1.657  2.635  0.934  0.912  0.979  1.274\n",
      "  0.817  1.587  1.019  1.007 11.     0.952  1.14   2.105  1.148  1.386\n",
      "  0.967  1.304  0.797  1.473  1.634  1.531  5.01   4.4    0.1    1.096\n",
      "  1.315  0.908  1.373  3.066  1.527  1.228  6.     0.958  1.103  1.151\n",
      "  3.205  2.513  1.578  1.631  2.975  2.745  1.024  1.415  1.68   1.387\n",
      " 12.4    0.994  1.077  1.145  0.96   1.269  1.078  3.641  0.     8.\n",
      "  1.13   1.099  2.806  0.996  3.018  1.289  3.8    0.957  1.116  2.357\n",
      "  1.022  1.213  1.013  1.149 12.9    1.025  5.4    0.85   4.9    1.072\n",
      "  1.401 11.8   12.1   10.8   11.5   11.4   12.3  ]\n",
      "Magnesium [1.8   1.9   1.7   1.2   0.7   1.789 1.676 1.784 1.5   2.    1.807 1.81\n",
      " 1.6   1.4   1.978 2.6   2.1   1.87  1.3   1.799 1.704 1.794 1.714 1.746\n",
      " 1.695 1.73  2.3   1.879 1.737 1.796 1.773 1.673 1.734 1.718 1.707 1.691\n",
      " 2.2   1.693 1.918 1.754 1.606 1.965 1.744 1.705 1.732 1.753 1.68  2.4\n",
      " 1.679 1.726 1.722 1.1   1.692 1.689 1.938 1.736 1.775 1.76  1.927 1.738\n",
      " 1.78  1.923 1.669 1.721 1.75  1.769 1.907 1.653 1.699 1.802 1.976 1.687\n",
      " 1.708 1.756 1.739 1.688 1.755 1.684 1.697 1.685 1.728 1.719 1.585 1.785\n",
      " 1.675 1.672 1.765 1.67  1.712 1.662 1.801 1.698 1.715 1.665 1.837 1.723\n",
      " 1.678 0.8   1.637 1.648 1.74  1.    1.647 1.706 2.5   1.96  1.941 1.827\n",
      " 1.795 1.98  1.819 1.748 1.72  1.85  1.702 1.94  1.618 1.658 1.997 1.664\n",
      " 1.818 1.743 1.71  1.701 1.867 1.783 1.654 1.945 1.928 1.731 1.686 1.671\n",
      " 1.834 1.674 1.709 1.901 1.954 1.643 1.752 1.844 1.651 1.711 1.659 1.992\n",
      " 1.871 1.66  1.59  1.724 1.841 1.694 1.729 1.975 1.763 1.873 1.749 1.641\n",
      " 1.874 1.69  1.645 1.703 1.733 1.622 1.716 1.889 1.958 2.9   2.814 1.682\n",
      " 1.817 1.896 1.661 1.937 1.713 1.681 1.99  1.806 1.747 1.813 2.035 1.717\n",
      " 1.764 1.876 1.989 1.638 1.886 1.772 1.777 1.86  0.3   1.811 1.956 2.7\n",
      " 1.64  1.667 1.677 1.65  1.843 1.657 1.797 1.579 1.562 1.611 1.836 1.909\n",
      " 1.925 0.    1.882 1.668 2.068 1.866 1.829 1.953 1.979 1.803 1.757 1.649\n",
      " 1.636 1.911 1.634 1.652 1.741 1.696 1.891 1.663 1.855 1.952 1.917 1.666\n",
      " 1.922 1.767 1.981 1.908 1.683 1.833 1.758 1.899 1.751 1.987 1.629 1.727\n",
      " 1.966 1.54  1.916 1.851 1.962 1.633 1.642 1.865 2.165 0.9   1.863 1.914\n",
      " 2.005 1.656 1.91  1.893 1.842 1.61  1.968 1.781 1.864 1.878 2.8   1.742\n",
      " 1.778 1.725 1.89  1.848 1.852 1.601 1.974 1.814 1.595 1.582 1.948 1.933\n",
      " 1.93  1.635 1.615 1.924 1.845 1.548 1.626 1.825 1.644 1.861 0.6   3.2  ]\n",
      "Respiratory.Rate [ 11.    10.    20.     0.     8.74   6.8    7.7   12.     8.69   7.66\n",
      "   9.34   8.19   8.38   6.96   6.29   6.4    7.73   7.98   8.82   6.9\n",
      "  14.     8.35   7.21   8.09   7.52   8.33  13.     7.9   18.     7.45\n",
      "   6.93   8.59   7.12  11.68   7.46   6.84   9.12   8.08   7.78  19.\n",
      "   7.04  21.     7.74   7.     7.62   7.48   6.71   7.05   7.68   7.71\n",
      "   7.32   9.22   7.17   8.75  15.     7.69   9.63   8.44   8.57   7.61\n",
      "   6.18   6.98   8.14   7.93   7.85   7.91   6.62  17.     8.99   8.97\n",
      "   6.97  11.45   6.83   6.38   8.25   9.14   7.33   7.27   8.32   5.77\n",
      "   7.55   6.69   7.19   6.56   7.26   7.41   8.96   6.82   5.89   5.72\n",
      "   6.88  11.32   9.48   6.67   7.06  11.56   8.05   7.39   6.76   7.2\n",
      "  11.89   6.94   8.66   6.15   7.08  16.     1.     9.11   6.2    9.77\n",
      "  11.96   6.31   9.39   7.83   6.49  10.84   8.95   6.47   9.21   6.91\n",
      "  10.99   7.75   6.74   5.91   6.57   6.5    6.78   7.5    6.55   8.01\n",
      "   5.78   5.58   5.38   6.66   8.92  10.98   7.16   8.78   6.01   5.71\n",
      "   9.85   9.76   6.21   7.63   6.13   6.39   7.22   7.81   8.2    7.4\n",
      "   9.7    6.27   8.16   7.13   6.85   5.18   6.7    6.36   7.54   6.46\n",
      "   9.74   8.84  11.65   6.51  11.08   7.89   5.57   5.93   6.45   6.58\n",
      "   6.63   8.28   7.47   8.5    6.99   6.73   7.57   8.54   9.9    6.35\n",
      "   6.92   9.52   6.89   8.62   8.71   6.61   7.29   6.68   9.43   9.06\n",
      "   7.43   6.53   7.3    9.87   5.86   5.98  10.39   8.47   7.18  10.56\n",
      "   8.41   9.81   6.72   7.36   8.52   5.9    7.65   7.44   7.84  11.8\n",
      "   7.72   6.44   5.96   8.03   8.6    5.56   6.23   6.25   6.33   9.49\n",
      "   6.79  12.98   6.3    8.13   3.86   7.09   7.99  10.82   8.02   7.37\n",
      "   8.24   9.57   6.02   9.46   7.88   7.95  12.01   8.67  11.37   7.79\n",
      "   6.05   7.24  10.88   8.27  11.72   6.59   4.88   7.87   8.23   7.03\n",
      "   7.1    7.59   8.07  11.76   7.02   6.65   8.04   7.49   7.34   7.51\n",
      "   5.1    7.14   9.67   5.99   9.31   6.09   7.07   7.31   6.     8.51\n",
      "  11.39   9.1    6.34   6.07  10.94   6.54   5.83   5.95   6.17   9.53\n",
      "   7.35   9.07   7.38  12.06   7.01   7.28   9.62   6.6    6.48   6.77\n",
      "   9.54   6.04   7.77   6.75   8.9    5.74  10.19   9.16   7.56   6.06\n",
      "   5.79   8.29   8.56   6.11   7.15   6.64  10.24   7.42   9.35  22.\n",
      "   7.97   6.37   8.72   5.48   8.1    7.11  10.1    8.98   6.87   5.17\n",
      "   8.8    6.81   5.85   6.41   6.28   7.58   5.88   3.8    9.44  13.24\n",
      "   6.52   8.     6.95   5.5    5.04   5.01   8.21   8.37   5.16   5.23\n",
      "   8.53   4.3    4.98   4.78   3.77   9.33   4.43   5.13   8.26   7.92\n",
      "   8.79   8.65   9.99   5.63   8.48   8.91   7.6    9.17   9.02   6.08\n",
      "   8.89   8.76   3.06   4.86   4.72   5.41   7.23   9.15   5.62   6.14\n",
      "   5.28   9.01   9.19   6.26   8.55   5.45  28.     4.32   3.91   4.59\n",
      "   7.82   8.11   6.24   4.22   5.46   4.17   4.85 118.  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT ['[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest tubes removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest tubes removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the right IJ\\n sheath remains in place.  Both left chest tubes have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n'\n",
      " '[**2157-10-21**] 3:31 PM\\n CT HEAD W/O CONTRAST                                            Clip # [**Clip Number (Radiology) 58866**]\\n Reason: 75 year old man with L brain mass s/p resection, evaluate fo\\n Admitting Diagnosis: BRAIN MASS\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours.\\n REASON FOR THIS EXAMINATION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours\\n No contraindications for IV contrast\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n EXAM:  CT of the head.\\n\\n CLINICAL INFORMATION:  Patient with brain mass, status post resection.\\n\\n TECHNIQUE:  Axial images of the head were obtained without contrast.\\n Correlation was made with the MRI of [**2157-10-20**].\\n\\n FINDINGS:  The patient is status post resection of extra-axial mass seen on\\n the previous MRI in the left parietal parafalcine region.  Postoperative\\n changes with craniotomy are seen.  Pneumocephalus identified.  Expected\\n post-surgical change is seen.  No hemorrhage identified.\\n\\n IMPRESSION:  Expected post-surgical changes with pneumocephalus seen in the\\n left parietal region.\\n\\n\\n'\n",
      " \"4:30p-7a\\nneuro: pt remained sedated on fent/versed and paralyzed with cisatracurium gtts. cisatr. gtt titrated to 2 eyebrow twitches, fent/versed titrated for sedation to vitals. +PERRL.\\n\\ncv: remained st through the shift, see flowsheet for hourly vs and detailed assessments. received 500cc bolus, hr down to 100-110's from 110-120. off ntg/neo, keeping sbp<120. chest remains open with ioban dressing. palpable pulses to all extremities. ci>2. lytes repleated prn.\\n\\nresp: ls clear bilat. see flowsheet for abg/vent setings. not overbreathing vent, remains paralyzed. chest tubes to 20cm h2o seal suctions, draining sm amts serosanguinous. o2sats >98%.\\n\\ngi/gu: abd soft, absent bowel sounds. [**Hospital1 207**] sump draining light brown to low cont suction. indwelling cath draining clear yellow urine, sufficient amts >30cc/hr.\\n\\nendo: RISS\\n\\nplan: continue to monitor hemodynamics. scheduled for the 10:30 OR, family aware, continue to keep pt paralyzed and sedated until the OR. continue to keep sbp<120. do not turn until after chest closure.\\n\"\n",
      " ...\n",
      " 'CVICU\\n   HPI:\\n   HD5\\n   [**10-28**] POD 1\\n   80M s/p MVR(33mm SJ tissue valve)/CABGx4(LIMA-.LAD, SVG->OM, Diag, PDA)\\n   [**10-27**]\\n   EF: 25% Wt.: 82.6 kg Cr.: 1.3\\n   PMHx: CHF, CAD-s/p MI [**2190**], HTN, ^lipids, PVD, NIDDM, osteoporosis,\\n   GERD, NIDDM, anemia, spinal stenosis, LBP, asbestos exposure, glaucoma,\\n   renal calculi-s/p lithotripsy, colonic polyps, diverticulosis,\\n   hemorrhoids, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 1284**]\\n   [**Last Name (un) **]: Prilosec 20\\', Altace 10\\', Metformin 500 TID, Crestor 10\\', ASA 81\\',\\n   MVI, Actonel 35 mg weekly, Lasix, Timolol 0.5% to L eye\"\\n   Current medications:\\n     Aspirin EC . Aspirin . Atorvastatin . . Docusate Sodium . Docusate\\n   Sodium (Liquid) . Epinephrine HCl . Insulin . Influenza Virus Vaccine .\\n   . Meperidine .\\n   . Milrinone . Morphine Sulfate . Neostigmine . Nitroglycerin,\\n   Oxycodone-Acetaminophen . Pantoprazole . Phenylephrine . Potassium\\n   Chloride . Propofol\\n   . Sucralfate . Vancomycin\\n   24 Hour Events:\\n INTUBATION - At [**2200-10-27**] 04:15 PM\\n OR RECEIVED - At [**2200-10-27**] 04:15 PM\\n CCO PAC - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n CORDIS/INTRODUCER - START [**2200-10-27**] 04:15 PM\\n INVASIVE VENTILATION - START [**2200-10-27**] 04:15 PM\\n EKG - At [**2200-10-27**] 05:00 PM\\n   Post operative day:\\n   POD#1 - S/P CABG X4, MVR\\n   Requiring multiple pressors after surgery. Improved from mmediate\\n   postop period.\\n   maintain support as necessary,wean vent as tolerated if stable\\n   Allergies:\\n   Percocet (Oral) (Oxycodone Hcl/Acetaminophen)\\n   Unknown;\\n   Vicodin (Oral) (Hydrocodone Bit/Acetaminophen)\\n   Unknown;\\n   Last dose of Antibiotics:\\n   Vancomycin - [**2200-10-28**] 08:00 AM\\n   Infusions:\\n   Epinephrine - 0.02 mcg/Kg/min\\n   Milrinone - 0.375 mcg/Kg/min\\n   Phenylephrine - 0.8 mcg/Kg/min\\n   Propofol - 25 mcg/Kg/min\\n   Other ICU medications:\\n   Carafate (Sucralfate) - [**2200-10-27**] 11:48 PM\\n   Morphine Sulfate - [**2200-10-28**] 08:00 AM\\n   Other medications:\\n   Flowsheet Data as of  [**2200-10-28**] 09:26 AM\\n   Vital signs\\n   Hemodynamic monitoring\\n   Fluid balance\\n                                                                  24 hours\\n                                                             Since [**04**] a.m.\\n   HR: 96 (82 - 96) bpm\\n   BP: 108/51(66) {83/46(56) - 115/61(76)} mmHg\\n   RR: 18 (12 - 32) insp/min\\n   SPO2: 96%\\n   Heart rhythm: A Paced\\n   Wgt (current): 92.6 kg (admission): 80.7 kg\\n   Height: 68 Inch\\n   CVP: 15 (14 - 21) mmHg\\n   PAP: (47 mmHg) / (23 mmHg)\\n   CO/CI (Fick): (7.3 L/min) / (3.8 L/min/m2)\\n   CO/CI (CCO): (4.4 L/min) / (2 L/min/m2)\\n   SvO2: 66%\\n   Mixed Venous O2% sat: 52 - 72\\n   Total In:\\n                                                                 10,697 mL\\n                                                                  1,859 mL\\n   PO:\\n   Tube feeding:\\n   IV Fluid:\\n                                                                  9,672 mL\\n                                                                  1,468 mL\\n   Blood products:\\n                                                                    975 mL\\n                                                                    361 mL\\n   Total out:\\n                                                                  1,868 mL\\n                                                                    585 mL\\n   Urine:\\n                                                                    698 mL\\n                                                                    305 mL\\n   NG:\\n                                                                     50 mL\\n   Stool:\\n   Drains:\\n   Balance:\\n                                                                  8,829 mL\\n                                                                  1,274 mL\\n   Respiratory support\\n   O2 Delivery Device: Endotracheal tube\\n   Ventilator mode: CPAP/PSV\\n   Vt (Set): 550 (550 - 550) mL\\n   Vt (Spontaneous): 560 (362 - 610) mL\\n   PS : 16 cmH2O\\n   RR (Set): 14\\n   RR (Spontaneous): 10\\n   PEEP: 5 cmH2O\\n   FiO2: 50%\\n   RSBI: 90\\n   PIP: 18 cmH2O\\n   Plateau: 17 cmH2O\\n   Compliance: 45.8 cmH2O/mL\\n   SPO2: 96%\\n   ABG: 7.44/26/109/20/-4\\n   Ve: 14 L/min\\n   PaO2 / FiO2: 218\\n   Physical Examination\\n   General Appearance: No acute distress\\n   HEENT: PERRL\\n   Cardiovascular: (Rhythm: Regular)\\n   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: CTA\\n   bilateral : ), (Sternum: Stable )\\n   Abdominal: Soft, Non-distended, Non-tender, Bowel sounds present\\n   Left Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Right Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Skin: (Incision: Clean / Dry / Intact)\\n   Neurologic: (Awake / Alert / Oriented: x 1), Follows simple commands,\\n   (Responds to: Verbal stimuli), Moves all extremities\\n   Labs / Radiology\\n   187 K/uL\\n   10.3 g/dL\\n   128 mg/dL\\n   0.8 mg/dL\\n   20 mEq/L\\n   4.6 mEq/L\\n   26 mg/dL\\n   105 mEq/L\\n   129 mEq/L\\n   35\\n   10.6 K/uL\\n        [image002.jpg]\\n                             [**2200-10-28**]  01:55 AM\\n                             [**2200-10-28**]  02:00 AM\\n                             [**2200-10-28**]  03:00 AM\\n                             [**2200-10-28**]  04:00 AM\\n                             [**2200-10-28**]  05:00 AM\\n                             [**2200-10-28**]  06:00 AM\\n                             [**2200-10-28**]  07:00 AM\\n                             [**2200-10-28**]  08:00 AM\\n                             [**2200-10-28**]  09:03 AM\\n                             [**2200-10-28**]  09:06 AM\\n   Hct\\n   35\\n   TCO2\\n   21\\n   18\\n   Glucose\\n   126\\n   104\\n   103\\n   92\\n   72\\n   78\\n   99\\n   128\\n   Other labs: PT / PTT / INR:16.9/50.6/1.5, Fibrinogen:324 mg/dL, Lactic\\n   Acid:1.2 mmol/L\\n   Imaging: CXR- clear.\\n   Microbiology: Blodd cx x2- pending ([**10-26**])\\n   Assessment and Plan\\n   Assessment and Plan: Milrinone/epi/neo, off propafol. CV stable on\\n   support.\\n   Wean pressors as tolerated if CV stable\\n   gentle diuresis\\n   Neurologic: Neuro checks Q: 1 hr\\n   Cardiovascular: Aspirin, Statins\\n   Pulmonary: Spontaneous breathing trial\\n   Gastrointestinal / Abdomen:\\n   Nutrition: NPO\\n   Renal: Foley, Adequate UO\\n   Endocrine: RISS\\n   Lines / Tubes / Drains: Foley, OGT, ETT, Chest tube - pleural , Chest\\n   tube - mediastinal, Pacing wires\\n   Wounds: Dry dressings\\n   Imaging: CXR today\\n   Fluids: KVO\\n   Consults: P.T.\\n   ICU Care\\n   Glycemic Control:  Regular insulin sliding scale\\n   CCO PAC - [**2200-10-27**] 04:15 PM\\n   Arterial Line - [**2200-10-27**] 04:15 PM\\n   Cordis/Introducer - [**2200-10-27**] 04:15 PM\\n   16 Gauge - [**2200-10-27**] 04:15 PM\\n   Prophylaxis:\\n   DVT: Boots\\n   Stress ulcer: PPI\\n   VAP bundle: HOB elevation, Mouth care, Daily wake up, RSBI\\n   Communication: Patient discussed on interdisciplinary rounds , ICU\\n   Code status: Full code\\n   Disposition: ICU\\n'\n",
      " '[**2156-11-30**] 4:36 PM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 85322**]\\n Reason: r/o ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p TVR and ct removal\\n REASON FOR THIS EXAMINATION:\\n  r/o ptx\\n ______________________________________________________________________________\\n PROVISIONAL FINDINGS IMPRESSION (PFI): TXPb TUE [**2156-11-30**] 7:50 PM\\n  1.  Small right apical pneumothorax without evidence of tension\\n  2.  Small left pleural effusion and atelectasis.\\n  3.  Interval removal of endotracheal and orogastric tubes.\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATION:  Evaluate for pneumothorax status post chest tube removal in\\n patient recently undergone TVR.\\n\\n COMPARISONS:  Chest radiograph from [**2156-11-29**].\\n\\n PORTABLE UPRIGHT RADIOGRAPH OF THE CHEST:  There is a small right apical\\n pneumothorax with no evidence of tension.  Compared to the prior radiograph,\\n the endotracheal and orogastric tubes have been removed.  The lung volumes are\\n low.  There is left basilar volume loss due to a small pleural effusion and\\n probable associated atelectasis which may have been present on the prior\\n study, but is now layering due to upright patient position.  The sternal\\n cerclage wires are intact.  The Swan-Ganz catheter is unchanged.\\n Post-surgical cardiac and mediastinal widening is unchanged.\\n\\n IMPRESSION:\\n 1.  Small right apical pneumothorax without evidence of tension\\n 2.  Small left pleural effusion and atelectasis.\\n 3.  Interval removal of endotracheal and orogastric tubes.\\n\\n\\n'\n",
      " '[**2156-11-30**] 10:02 PM\\n CHEST (PORTABLE AP); -77 BY DIFFERENT PHYSICIAN                 [**Name Initial (PRE) 7**] # [**Clip Number (Radiology) 86199**]\\n Reason: assess left apical ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p chest tube removal\\n REASON FOR THIS EXAMINATION:\\n  assess left apical ptx\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n AP CHEST, 10:08 P.M. ON [**11-30**]\\n\\n HISTORY:  Chest tube removed.\\n\\n IMPRESSION:  AP chest compared to [**11-15**] through 22:\\n\\n No appreciable residual pneumothorax.  Small bilateral pleural effusions\\n persist.  Heart size is normal.  Infrahilar atelectasis is mild and unchanged.\\n\\n Swan-Ganz catheter traverses the right jugular introducer ending in the right\\n pulmonary artery.  Heart size top normal unchanged.\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "  print(col,org[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "Tn1CWOHbyKB_",
   "metadata": {
    "id": "Tn1CWOHbyKB_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>length_of_stay_sum</th>\n",
       "      <th>length_of_stay_avg</th>\n",
       "      <th>length_of_stay_min</th>\n",
       "      <th>length_of_stay_max</th>\n",
       "      <th>length_of_stay_rnd</th>\n",
       "      <th>Platelet.Count</th>\n",
       "      <th>Prothrombin.time</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>PTT</th>\n",
       "      <th>GCS...Verbal.Response</th>\n",
       "      <th>Language</th>\n",
       "      <th>GCS...Motor.Response</th>\n",
       "      <th>GCS...Eye.Opening</th>\n",
       "      <th>INR</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Patient.Location</th>\n",
       "      <th>Race</th>\n",
       "      <th>Glucose..serum.</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hematocrit..serum.</th>\n",
       "      <th>Calcium.non.ionized</th>\n",
       "      <th>Phosphorous</th>\n",
       "      <th>BUN</th>\n",
       "      <th>O2.saturation.pulseoxymetry</th>\n",
       "      <th>Admission.Weight..Kg.</th>\n",
       "      <th>Heart.Rate</th>\n",
       "      <th>HCO3..serum.</th>\n",
       "      <th>Anion.gap</th>\n",
       "      <th>Potassium..serum.</th>\n",
       "      <th>Chloride..serum.</th>\n",
       "      <th>Sodium..serum.</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Respiratory.Rate</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>12.264583</td>\n",
       "      <td>6.132292</td>\n",
       "      <td>5.496528</td>\n",
       "      <td>6.768056</td>\n",
       "      <td>5.496528</td>\n",
       "      <td>179.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>Oriented</td>\n",
       "      <td>English</td>\n",
       "      <td>Obeys Commands</td>\n",
       "      <td>Spontaneously</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>CC6B</td>\n",
       "      <td>White</td>\n",
       "      <td>114.0</td>\n",
       "      <td>M</td>\n",
       "      <td>36.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>115.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>106.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest tubes removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest tubes removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the right IJ\\n sheath remains in place.  Both left chest tubes have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>12.264583</td>\n",
       "      <td>6.132292</td>\n",
       "      <td>5.496528</td>\n",
       "      <td>6.768056</td>\n",
       "      <td>5.496528</td>\n",
       "      <td>179.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>Oriented</td>\n",
       "      <td>English</td>\n",
       "      <td>Obeys Commands</td>\n",
       "      <td>Spontaneously</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>CC6B</td>\n",
       "      <td>White</td>\n",
       "      <td>114.0</td>\n",
       "      <td>M</td>\n",
       "      <td>36.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>115.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>106.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[**2157-10-21**] 3:31 PM\\n CT HEAD W/O CONTRAST                                            Clip # [**Clip Number (Radiology) 58866**]\\n Reason: 75 year old man with L brain mass s/p resection, evaluate fo\\n Admitting Diagnosis: BRAIN MASS\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours.\\n REASON FOR THIS EXAMINATION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours\\n No contraindications for IV contrast\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n EXAM:  CT of the head.\\n\\n CLINICAL INFORMATION:  Patient with brain mass, status post resection.\\n\\n TECHNIQUE:  Axial images of the head were obtained without contrast.\\n Correlation was made with the MRI of [**2157-10-20**].\\n\\n FINDINGS:  The patient is status post resection of extra-axial mass seen on\\n the previous MRI in the left parietal parafalcine region.  Postoperative\\n changes with craniotomy are seen.  Pneumocephalus identified.  Expected\\n post-surgical change is seen.  No hemorrhage identified.\\n\\n IMPRESSION:  Expected post-surgical changes with pneumocephalus seen in the\\n left parietal region.\\n\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>31.091667</td>\n",
       "      <td>10.363889</td>\n",
       "      <td>8.281250</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>113.6</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Localizes Pain</td>\n",
       "      <td>Spontaneously</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>4I</td>\n",
       "      <td>White</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4:30p-7a\\nneuro: pt remained sedated on fent/versed and paralyzed with cisatracurium gtts. cisatr. gtt titrated to 2 eyebrow twitches, fent/versed titrated for sedation to vitals. +PERRL.\\n\\ncv: remained st through the shift, see flowsheet for hourly vs and detailed assessments. received 500cc bolus, hr down to 100-110's from 110-120. off ntg/neo, keeping sbp&lt;120. chest remains open with ioban dressing. palpable pulses to all extremities. ci&gt;2. lytes repleated prn.\\n\\nresp: ls clear bilat. see flowsheet for abg/vent setings. not overbreathing vent, remains paralyzed. chest tubes to 20cm h2o seal suctions, draining sm amts serosanguinous. o2sats &gt;98%.\\n\\ngi/gu: abd soft, absent bowel sounds. [**Hospital1 207**] sump draining light brown to low cont suction. indwelling cath draining clear yellow urine, sufficient amts &gt;30cc/hr.\\n\\nendo: RISS\\n\\nplan: continue to monitor hemodynamics. scheduled for the 10:30 OR, family aware, continue to keep pt paralyzed and sedated until the OR. continue to keep sbp&lt;120. do not turn until after chest closure.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>31.091667</td>\n",
       "      <td>10.363889</td>\n",
       "      <td>8.281250</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>113.6</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Localizes Pain</td>\n",
       "      <td>Spontaneously</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>4I</td>\n",
       "      <td>White</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[**2131-5-24**] 9:45 AM\\n PICC LINE PLACMENT SCH                                          Clip # [**Clip Number (Radiology) 17943**]\\n Reason: PICC for IV antibiotics\\n Admitting Diagnosis: CHEST PAIN/SHORTNESS OF BREATH\\n ********************************* CPT Codes ********************************\\n * [**Numeric Identifier 413**] PICC W/O [**Numeric Identifier 932**] FLUORO GUID PLCT/REPLCT/REMOVE   *\\n * [**Numeric Identifier 375**] US GUID FOR VAS. ACCESS                                                *\\n ****************************************************************************\\n ______________________________________________________________________________\\n [**Hospital 3**] MEDICAL CONDITION:\\n   69 year old man s/p sternal rewire\\n\\n REASON FOR THIS EXAMINATION:\\n  PICC for IV antibiotics\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATION:  69-year-old status post sternal rewiring requiring IV\\n antibiotics.\\n\\n RADIOLOGISTS:  The procedure was performed by Dr. [**Last Name (STitle) 5344**], with Dr. [**Last Name (STitle) 169**],\\n the attending physician [**Name Initial (PRE) **].\\n\\n PROCEDURE AND FINDINGS:  Patient was placed supine on the angiographic table.\\n Due to prior ultrasounds demonstrating extensive thrombus within the left\\n upper extremity, the right upper extremity was chosen for the PICC line.\\n Ultrasound demonstrated an appropriate right basilic vein which was punctured\\n with a 21-gauge micropuncture needle, through which a 0.018 guide wire was\\n advanced into the SVC.  A single lumen PICC trimmed to 35 cm and was advanced\\n under fluoroscopic guidance with its tip placed in the distal SVC.  Final\\n fluoroscopic image was taken to confirm tip placement.  Hard copy ultrasound\\n images were printed before and after venous puncture to confirm patency. There\\n are no immediate post-procedure complications.\\n\\n IMPRESSION:  Successful placement of 35 cm single lumen PICC via the right\\n basilic vein with its tip in the distal SVC; line ready for use.\\n\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>31.091667</td>\n",
       "      <td>10.363889</td>\n",
       "      <td>8.281250</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>12.736806</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>113.6</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Localizes Pain</td>\n",
       "      <td>Spontaneously</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>4I</td>\n",
       "      <td>White</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Respiratory Care\\nPt intubated on ventilatory support. Able to tol gradual decrease in FiO2 over duration of shift with support of Nitric Oxide Ventilation. ABG reveals continued mixed respiratory and metabolic acidosis. BS clear. Plan is to continue and wean vent support as tol. AM RSBI not performed due to hemodynamic instability and ventilatory requirements of INO vent.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18512</th>\n",
       "      <td>18535</td>\n",
       "      <td>99923</td>\n",
       "      <td>17.872917</td>\n",
       "      <td>8.936458</td>\n",
       "      <td>7.804167</td>\n",
       "      <td>10.068750</td>\n",
       "      <td>10.068750</td>\n",
       "      <td>117.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Flex-withdraws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>CC6C</td>\n",
       "      <td>White</td>\n",
       "      <td>104.0</td>\n",
       "      <td>M</td>\n",
       "      <td>28.7</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[**2201-3-3**] 1:58 PM\\n CHEST (PA &amp; LAT)                                                Clip # [**Clip Number (Radiology) 6762**]\\n Reason: Please assess interval change of R pleural effusion\\n Admitting Diagnosis: HYPONATREMIA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  54-year-old male with alcohol cirrhosis, MELD score 19, and decompensation with\\n  ascites, low-grade hepatic encephalopathy, and portal hypertension with grade\\n  [**12-14**] esophageal varices, presents with hypotension, stable observation in MICU\\n  now called out to floor and with chronic kidney disease.\\n REASON FOR THIS EXAMINATION:\\n  Please assess interval change of R pleural effusion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n HISTORY:  54-year-old male, with alcohol cirrhosis, MELD score 19.  Assess for\\n intrathoracic process.\\n\\n COMPARISON:  Multiple prior studies with the latest on [**2201-2-23**].\\n\\n PA AND LATERAL CHEST RADIOGRAPH:  The lung volumes are slightly low.\\n Bibasilar atelectasis is mild with small bilateral pleural effusions.  There\\n is no pneumothorax or definite focal airspace consolidation.  The\\n cardiomediastinal silhouette, hilar contour and pulmonary vasculature are\\n normal.  The underlying osseous structures are grossly unremarkable.\\n\\n IMPRESSION:  Mild bibasilar atelectasis with small pleural effusions.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18513</th>\n",
       "      <td>18536</td>\n",
       "      <td>99938</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Flex-withdraws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>CC7B</td>\n",
       "      <td>White</td>\n",
       "      <td>115.0</td>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CVICU\\n   HPI: [**11-3**] POD 7\\n   80M s/p MVR(33mm SJ tissue valve)/CABGx4(LIMA-.LAD, SVG-&gt;OM, Diag, PDA)\\n   [**10-27**]\\n   EF: 25% Wt.: 82.6 kg Cr.: 1.3\\n   PMHx: CHF, CAD-s/p MI [**2190**], HTN, ^lipids, PVD, NIDDM, osteoporosis,\\n   GERD, NIDDM, anemia, spinal stenosis, LBP, asbestos exposure, glaucoma,\\n   renal calculi-s/p lithotripsy, colonic polyps, diverticulosis,\\n   hemorrhoids, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 1284**]\\n   [**Last Name (un) **]: Prilosec 20', Altace 10', Metformin 500 TID, Crestor 10', ASA 81',\\n   MVI, Actonel 35 mg weekly, Lasix, Timolol 0.5% to L eye\"\\n   Current medications:\\n   Amiodarone, Aspirin, Atorvastatin, Captopril, Colace, Lasix, Dilaudid\\n   prn, heparin, Toprol XL, protonix, timolol 0.5%\\n   24 Hour Events:\\n EKG - At [**2200-11-2**] 02:15 PM\\n EKG - At [**2200-11-2**] 03:45 PM\\n   awire trace=1st degree av block\\n   Post operative day:\\n   POD#7 - S/P CABG X4, MVR\\n   [**16**] hour events: started lasix gtt for diuresis, remained in ICU due to\\n   no available floor bed\\n   Allergies:\\n   Percocet (Oral) (Oxycodone Hcl/Acetaminophen)\\n   Unknown;\\n   Vicodin (Oral) (Hydrocodone Bit/Acetaminophen)\\n   Unknown;\\n   Last dose of Antibiotics:\\n   Infusions:\\n   Furosemide (Lasix) - 5 mg/hour\\n   Other ICU medications:\\n   Other medications:\\n   Flowsheet Data as of  [**2200-11-3**] 08:57 AM\\n   Vital signs\\n   Hemodynamic monitoring\\n   Fluid balance\\n                                                                  24 hours\\n                                                             Since [**04**] a.m.\\n   Tmax: 37.1\\nC (98.7\\n   T current: 36.2\\nC (97.1\\n   HR: 76 (71 - 88) bpm\\n   BP: 95/52(62) {81/42(51) - 115/75(80)} mmHg\\n   RR: 19 (17 - 28) insp/min\\n   SPO2: 98%\\n   Heart rhythm: 1st AV (First degree AV Block)\\n   Wgt (current): 91.6 kg (admission): 80.7 kg\\n   Height: 68 Inch\\n             Total In:\\n                                                                  1,017 mL\\n                                                                    315 mL\\n   PO:\\n                                                                    640 mL\\n                                                                    120 mL\\n   Tube feeding:\\n   IV Fluid:\\n                                                                    377 mL\\n                                                                    195 mL\\n   Blood products:\\n   Total out:\\n                                                                  1,517 mL\\n                                                                    760 mL\\n   Urine:\\n                                                                  1,517 mL\\n                                                                    760 mL\\n   NG:\\n   Stool:\\n   Drains:\\n   Balance:\\n                                                                   -500 mL\\n                                                                   -445 mL\\n   Respiratory support\\n   O2 Delivery Device: None\\n   SPO2: 98%\\n   ABG: ///24/\\n   Physical Examination\\n   General Appearance: No acute distress\\n   HEENT: PERRL\\n   Cardiovascular: (Rhythm: Regular)\\n   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: CTA\\n   bilateral : , Diminished: left base), (Sternum: Stable )\\n   Abdominal: Soft, Non-distended, Non-tender, Bowel sounds present, bowel\\n   movement [**11-2**]\\n   Left Extremities: (Edema: 2+), (Temperature: Warm), (Pulse - Dorsalis\\n   pedis: Diminished), (Pulse - Posterior tibial: Diminished)\\n   Right Extremities: (Edema: 2+), (Temperature: Warm), (Pulse - Dorsalis\\n   pedis: Diminished), (Pulse - Posterior tibial: Diminished)\\n   Skin: (Incision: Clean / Dry / Intact)\\n   Neurologic: (Awake / Alert / Oriented: x 3), Follows simple commands,\\n   Moves all extremities\\n   Labs / Radiology\\n   185 K/uL\\n   10.7 g/dL\\n   130 mg/dL\\n   1.0 mg/dL\\n   24 mEq/L\\n   4.1 mEq/L\\n   26 mg/dL\\n   92 mEq/L\\n   128 mEq/L\\n   30.7 %\\n   9.1 K/uL\\n        [image002.jpg]\\n                             [**2200-10-30**]  08:35 PM\\n                             [**2200-10-31**]  02:29 AM\\n                             [**2200-10-31**]  02:59 AM\\n                             [**2200-10-31**]  11:49 AM\\n                             [**2200-11-1**]  04:24 AM\\n                             [**2200-11-1**]  03:37 PM\\n                             [**2200-11-2**]  02:37 AM\\n                             [**2200-11-3**]  02:37 AM\\n                             [**2200-11-3**]  04:00 AM\\n                             [**2200-11-3**]  07:57 AM\\n   WBC\\n   10.2\\n   9.5\\n   12.1\\n   9.1\\n   Hct\\n   28.1\\n   41\\n   31.3\\n   33.2\\n   30.6\\n   30.7\\n   Plt\\n   129\\n   124\\n   153\\n   185\\n   Creatinine\\n   0.9\\n   1.0\\n   0.9\\n   1.0\\n   TCO2\\n   21\\n   Glucose\\n   146\\n   193\\n   115\\n   105\\n   59\\n   [**Telephone/Fax (3) 1515**]\\n   Other labs: PT / PTT / INR:15.1/33.8/1.3, Fibrinogen:622 mg/dL, Lactic\\n   Acid:1.5 mmol/L, Ca:8.2 mg/dL, Mg:2.2 mg/dL, PO4:3.7 mg/dL\\n   Imaging: CXR [**11-1**] left effusion\\n   Microbiology: urine culture pending\\n   Assessment and Plan\\n   Acute systolic heart failure\\n   Assessment and Plan:\\n   Neurologic: Neuro checks Q: 2 hr, Pain controlled, dilaudid prn\\n   Cardiovascular: Aspirin, Beta-blocker, Statins, Discontinue epicardial\\n   wires, captopril for acute systolic heart failure\\n   Pulmonary: IS, cough and deep breath\\n   Gastrointestinal / Abdomen:  tolerating diet\\n   Nutrition: Diabetic diet no sodium restriction, 1000 ml fluid\\n   restriction due to hyponatremia\\n   Renal: Foley, Adequate UO, continue lasix gtt for goal [**Telephone/Fax (1) 264**] ml\\n   negative in 24 hours\\n   Hematology:  stable\\n   Endocrine: RISS, Lantus (R)\\n   Infectious Disease: Check cultures, follow up on urine\\n   Lines / Tubes / Drains: Foley, Pacing wires, maintain foley to monitor\\n   urine output\\n   Wounds: Dry dressings\\n   Consults: P.T.\\n   ICU Care\\n   Glycemic Control:  Regular insulin sliding scale, Lantus (R) protocol\\n   Lines:\\n   Cordis/Introducer - [**2200-10-27**] 04:15 PM\\n   20 Gauge - [**2200-11-3**] 06:46 AM\\n   Prophylaxis:\\n   DVT: Boots, SQ UF Heparin\\n   Stress ulcer: PPI\\n   VAP bundle:\\n   Comments:\\n   Communication: Patient discussed on interdisciplinary rounds , ICU\\n   Code status: Full code\\n   Disposition: Transfer to floor\\n   ------ Protected Section ------\\n   Agree with above.   Heart failure consult with [**First Name8 (NamePattern2) 509**] [**Last Name (NamePattern1) **].\\n   ------ Protected Section Addendum Entered By:[**Name (NI) 768**] [**Last Name (NamePattern1) **], MD\\n   on:[**2200-11-3**] 14:40 ------\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18514</th>\n",
       "      <td>18537</td>\n",
       "      <td>99938</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Flex-withdraws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>CC7B</td>\n",
       "      <td>White</td>\n",
       "      <td>115.0</td>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CVICU\\n   HPI:\\n   HD5\\n   [**10-28**] POD 1\\n   80M s/p MVR(33mm SJ tissue valve)/CABGx4(LIMA-.LAD, SVG-&gt;OM, Diag, PDA)\\n   [**10-27**]\\n   EF: 25% Wt.: 82.6 kg Cr.: 1.3\\n   PMHx: CHF, CAD-s/p MI [**2190**], HTN, ^lipids, PVD, NIDDM, osteoporosis,\\n   GERD, NIDDM, anemia, spinal stenosis, LBP, asbestos exposure, glaucoma,\\n   renal calculi-s/p lithotripsy, colonic polyps, diverticulosis,\\n   hemorrhoids, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 1284**]\\n   [**Last Name (un) **]: Prilosec 20', Altace 10', Metformin 500 TID, Crestor 10', ASA 81',\\n   MVI, Actonel 35 mg weekly, Lasix, Timolol 0.5% to L eye\"\\n   Current medications:\\n     Aspirin EC . Aspirin . Atorvastatin . . Docusate Sodium . Docusate\\n   Sodium (Liquid) . Epinephrine HCl . Insulin . Influenza Virus Vaccine .\\n   . Meperidine .\\n   . Milrinone . Morphine Sulfate . Neostigmine . Nitroglycerin,\\n   Oxycodone-Acetaminophen . Pantoprazole . Phenylephrine . Potassium\\n   Chloride . Propofol\\n   . Sucralfate . Vancomycin\\n   24 Hour Events:\\n INTUBATION - At [**2200-10-27**] 04:15 PM\\n OR RECEIVED - At [**2200-10-27**] 04:15 PM\\n CCO PAC - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n CORDIS/INTRODUCER - START [**2200-10-27**] 04:15 PM\\n INVASIVE VENTILATION - START [**2200-10-27**] 04:15 PM\\n EKG - At [**2200-10-27**] 05:00 PM\\n   Post operative day:\\n   POD#1 - S/P CABG X4, MVR\\n   Requiring multiple pressors after surgery. Improved from mmediate\\n   postop period.\\n   maintain support as necessary,wean vent as tolerated if stable\\n   Allergies:\\n   Percocet (Oral) (Oxycodone Hcl/Acetaminophen)\\n   Unknown;\\n   Vicodin (Oral) (Hydrocodone Bit/Acetaminophen)\\n   Unknown;\\n   Last dose of Antibiotics:\\n   Vancomycin - [**2200-10-28**] 08:00 AM\\n   Infusions:\\n   Epinephrine - 0.02 mcg/Kg/min\\n   Milrinone - 0.375 mcg/Kg/min\\n   Phenylephrine - 0.8 mcg/Kg/min\\n   Propofol - 25 mcg/Kg/min\\n   Other ICU medications:\\n   Carafate (Sucralfate) - [**2200-10-27**] 11:48 PM\\n   Morphine Sulfate - [**2200-10-28**] 08:00 AM\\n   Other medications:\\n   Flowsheet Data as of  [**2200-10-28**] 09:26 AM\\n   Vital signs\\n   Hemodynamic monitoring\\n   Fluid balance\\n                                                                  24 hours\\n                                                             Since [**04**] a.m.\\n   HR: 96 (82 - 96) bpm\\n   BP: 108/51(66) {83/46(56) - 115/61(76)} mmHg\\n   RR: 18 (12 - 32) insp/min\\n   SPO2: 96%\\n   Heart rhythm: A Paced\\n   Wgt (current): 92.6 kg (admission): 80.7 kg\\n   Height: 68 Inch\\n   CVP: 15 (14 - 21) mmHg\\n   PAP: (47 mmHg) / (23 mmHg)\\n   CO/CI (Fick): (7.3 L/min) / (3.8 L/min/m2)\\n   CO/CI (CCO): (4.4 L/min) / (2 L/min/m2)\\n   SvO2: 66%\\n   Mixed Venous O2% sat: 52 - 72\\n   Total In:\\n                                                                 10,697 mL\\n                                                                  1,859 mL\\n   PO:\\n   Tube feeding:\\n   IV Fluid:\\n                                                                  9,672 mL\\n                                                                  1,468 mL\\n   Blood products:\\n                                                                    975 mL\\n                                                                    361 mL\\n   Total out:\\n                                                                  1,868 mL\\n                                                                    585 mL\\n   Urine:\\n                                                                    698 mL\\n                                                                    305 mL\\n   NG:\\n                                                                     50 mL\\n   Stool:\\n   Drains:\\n   Balance:\\n                                                                  8,829 mL\\n                                                                  1,274 mL\\n   Respiratory support\\n   O2 Delivery Device: Endotracheal tube\\n   Ventilator mode: CPAP/PSV\\n   Vt (Set): 550 (550 - 550) mL\\n   Vt (Spontaneous): 560 (362 - 610) mL\\n   PS : 16 cmH2O\\n   RR (Set): 14\\n   RR (Spontaneous): 10\\n   PEEP: 5 cmH2O\\n   FiO2: 50%\\n   RSBI: 90\\n   PIP: 18 cmH2O\\n   Plateau: 17 cmH2O\\n   Compliance: 45.8 cmH2O/mL\\n   SPO2: 96%\\n   ABG: 7.44/26/109/20/-4\\n   Ve: 14 L/min\\n   PaO2 / FiO2: 218\\n   Physical Examination\\n   General Appearance: No acute distress\\n   HEENT: PERRL\\n   Cardiovascular: (Rhythm: Regular)\\n   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: CTA\\n   bilateral : ), (Sternum: Stable )\\n   Abdominal: Soft, Non-distended, Non-tender, Bowel sounds present\\n   Left Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Right Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Skin: (Incision: Clean / Dry / Intact)\\n   Neurologic: (Awake / Alert / Oriented: x 1), Follows simple commands,\\n   (Responds to: Verbal stimuli), Moves all extremities\\n   Labs / Radiology\\n   187 K/uL\\n   10.3 g/dL\\n   128 mg/dL\\n   0.8 mg/dL\\n   20 mEq/L\\n   4.6 mEq/L\\n   26 mg/dL\\n   105 mEq/L\\n   129 mEq/L\\n   35\\n   10.6 K/uL\\n        [image002.jpg]\\n                             [**2200-10-28**]  01:55 AM\\n                             [**2200-10-28**]  02:00 AM\\n                             [**2200-10-28**]  03:00 AM\\n                             [**2200-10-28**]  04:00 AM\\n                             [**2200-10-28**]  05:00 AM\\n                             [**2200-10-28**]  06:00 AM\\n                             [**2200-10-28**]  07:00 AM\\n                             [**2200-10-28**]  08:00 AM\\n                             [**2200-10-28**]  09:03 AM\\n                             [**2200-10-28**]  09:06 AM\\n   Hct\\n   35\\n   TCO2\\n   21\\n   18\\n   Glucose\\n   126\\n   104\\n   103\\n   92\\n   72\\n   78\\n   99\\n   128\\n   Other labs: PT / PTT / INR:16.9/50.6/1.5, Fibrinogen:324 mg/dL, Lactic\\n   Acid:1.2 mmol/L\\n   Imaging: CXR- clear.\\n   Microbiology: Blodd cx x2- pending ([**10-26**])\\n   Assessment and Plan\\n   Assessment and Plan: Milrinone/epi/neo, off propafol. CV stable on\\n   support.\\n   Wean pressors as tolerated if CV stable\\n   gentle diuresis\\n   Neurologic: Neuro checks Q: 1 hr\\n   Cardiovascular: Aspirin, Statins\\n   Pulmonary: Spontaneous breathing trial\\n   Gastrointestinal / Abdomen:\\n   Nutrition: NPO\\n   Renal: Foley, Adequate UO\\n   Endocrine: RISS\\n   Lines / Tubes / Drains: Foley, OGT, ETT, Chest tube - pleural , Chest\\n   tube - mediastinal, Pacing wires\\n   Wounds: Dry dressings\\n   Imaging: CXR today\\n   Fluids: KVO\\n   Consults: P.T.\\n   ICU Care\\n   Glycemic Control:  Regular insulin sliding scale\\n   CCO PAC - [**2200-10-27**] 04:15 PM\\n   Arterial Line - [**2200-10-27**] 04:15 PM\\n   Cordis/Introducer - [**2200-10-27**] 04:15 PM\\n   16 Gauge - [**2200-10-27**] 04:15 PM\\n   Prophylaxis:\\n   DVT: Boots\\n   Stress ulcer: PPI\\n   VAP bundle: HOB elevation, Mouth care, Daily wake up, RSBI\\n   Communication: Patient discussed on interdisciplinary rounds , ICU\\n   Code status: Full code\\n   Disposition: ICU\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18515</th>\n",
       "      <td>18538</td>\n",
       "      <td>99982</td>\n",
       "      <td>23.018750</td>\n",
       "      <td>7.672917</td>\n",
       "      <td>6.128472</td>\n",
       "      <td>10.075694</td>\n",
       "      <td>6.814583</td>\n",
       "      <td>101.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Localizes Pain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>CC7B</td>\n",
       "      <td>White</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[**2156-11-30**] 4:36 PM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 85322**]\\n Reason: r/o ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p TVR and ct removal\\n REASON FOR THIS EXAMINATION:\\n  r/o ptx\\n ______________________________________________________________________________\\n PROVISIONAL FINDINGS IMPRESSION (PFI): TXPb TUE [**2156-11-30**] 7:50 PM\\n  1.  Small right apical pneumothorax without evidence of tension\\n  2.  Small left pleural effusion and atelectasis.\\n  3.  Interval removal of endotracheal and orogastric tubes.\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATION:  Evaluate for pneumothorax status post chest tube removal in\\n patient recently undergone TVR.\\n\\n COMPARISONS:  Chest radiograph from [**2156-11-29**].\\n\\n PORTABLE UPRIGHT RADIOGRAPH OF THE CHEST:  There is a small right apical\\n pneumothorax with no evidence of tension.  Compared to the prior radiograph,\\n the endotracheal and orogastric tubes have been removed.  The lung volumes are\\n low.  There is left basilar volume loss due to a small pleural effusion and\\n probable associated atelectasis which may have been present on the prior\\n study, but is now layering due to upright patient position.  The sternal\\n cerclage wires are intact.  The Swan-Ganz catheter is unchanged.\\n Post-surgical cardiac and mediastinal widening is unchanged.\\n\\n IMPRESSION:\\n 1.  Small right apical pneumothorax without evidence of tension\\n 2.  Small left pleural effusion and atelectasis.\\n 3.  Interval removal of endotracheal and orogastric tubes.\\n\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18516</th>\n",
       "      <td>18539</td>\n",
       "      <td>99982</td>\n",
       "      <td>23.018750</td>\n",
       "      <td>7.672917</td>\n",
       "      <td>6.128472</td>\n",
       "      <td>10.075694</td>\n",
       "      <td>6.814583</td>\n",
       "      <td>101.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>No Response-ETT</td>\n",
       "      <td>English</td>\n",
       "      <td>Localizes Pain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>CC7B</td>\n",
       "      <td>White</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[**2156-11-30**] 10:02 PM\\n CHEST (PORTABLE AP); -77 BY DIFFERENT PHYSICIAN                 [**Name Initial (PRE) 7**] # [**Clip Number (Radiology) 86199**]\\n Reason: assess left apical ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p chest tube removal\\n REASON FOR THIS EXAMINATION:\\n  assess left apical ptx\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n AP CHEST, 10:08 P.M. ON [**11-30**]\\n\\n HISTORY:  Chest tube removed.\\n\\n IMPRESSION:  AP chest compared to [**11-15**] through 22:\\n\\n No appreciable residual pneumothorax.  Small bilateral pleural effusions\\n persist.  Heart size is normal.  Infrahilar atelectasis is mild and unchanged.\\n\\n Swan-Ganz catheter traverses the right jugular introducer ending in the right\\n pulmonary artery.  Heart size top normal unchanged.\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18517 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  SUBJECT_ID  length_of_stay_sum  length_of_stay_avg  \\\n",
       "0               1          23           12.264583            6.132292   \n",
       "1               2          23           12.264583            6.132292   \n",
       "2               3          36           31.091667           10.363889   \n",
       "3               4          36           31.091667           10.363889   \n",
       "4               5          36           31.091667           10.363889   \n",
       "...           ...         ...                 ...                 ...   \n",
       "18512       18535       99923           17.872917            8.936458   \n",
       "18513       18536       99938           17.750000           17.750000   \n",
       "18514       18537       99938           17.750000           17.750000   \n",
       "18515       18538       99982           23.018750            7.672917   \n",
       "18516       18539       99982           23.018750            7.672917   \n",
       "\n",
       "       length_of_stay_min  length_of_stay_max  length_of_stay_rnd  \\\n",
       "0                5.496528            6.768056            5.496528   \n",
       "1                5.496528            6.768056            5.496528   \n",
       "2                8.281250           12.736806           12.736806   \n",
       "3                8.281250           12.736806           12.736806   \n",
       "4                8.281250           12.736806           12.736806   \n",
       "...                   ...                 ...                 ...   \n",
       "18512            7.804167           10.068750           10.068750   \n",
       "18513           17.750000           17.750000           17.750000   \n",
       "18514           17.750000           17.750000           17.750000   \n",
       "18515            6.128472           10.075694            6.814583   \n",
       "18516            6.128472           10.075694            6.814583   \n",
       "\n",
       "       Platelet.Count  Prothrombin.time   WBC  Hemoglobin    PTT  \\\n",
       "0               179.0              12.3  14.8        13.1   24.5   \n",
       "1               179.0              12.3  14.8        13.1   24.5   \n",
       "2               146.0              14.2  10.3        10.9  113.6   \n",
       "3               146.0              14.2  10.3        10.9  113.6   \n",
       "4               146.0              14.2  10.3        10.9  113.6   \n",
       "...               ...               ...   ...         ...    ...   \n",
       "18512           117.0              12.8  12.7        10.4   29.3   \n",
       "18513           115.0              15.1  10.2        10.1   33.8   \n",
       "18514           115.0              15.1  10.2        10.1   33.8   \n",
       "18515           101.0              12.6   3.8        10.0   31.4   \n",
       "18516           101.0              12.6   3.8        10.0   31.4   \n",
       "\n",
       "      GCS...Verbal.Response Language GCS...Motor.Response GCS...Eye.Opening  \\\n",
       "0                  Oriented  English       Obeys Commands     Spontaneously   \n",
       "1                  Oriented  English       Obeys Commands     Spontaneously   \n",
       "2           No Response-ETT  English       Localizes Pain     Spontaneously   \n",
       "3           No Response-ETT  English       Localizes Pain     Spontaneously   \n",
       "4           No Response-ETT  English       Localizes Pain     Spontaneously   \n",
       "...                     ...      ...                  ...               ...   \n",
       "18512       No Response-ETT  English       Flex-withdraws               NaN   \n",
       "18513       No Response-ETT  English       Flex-withdraws               NaN   \n",
       "18514       No Response-ETT  English       Flex-withdraws               NaN   \n",
       "18515       No Response-ETT  English       Localizes Pain               NaN   \n",
       "18516       No Response-ETT  English       Localizes Pain               NaN   \n",
       "\n",
       "       INR        Religion Patient.Location   Race  Glucose..serum. Gender  \\\n",
       "0      1.0  Roman Catholic             CC6B  White            114.0      M   \n",
       "1      1.0  Roman Catholic             CC6B  White            114.0      M   \n",
       "2      1.2   Not specified               4I  White            100.0      M   \n",
       "3      1.2   Not specified               4I  White            100.0      M   \n",
       "4      1.2   Not specified               4I  White            100.0      M   \n",
       "...    ...             ...              ...    ...              ...    ...   \n",
       "18512  1.1  Roman Catholic             CC6C  White            104.0      M   \n",
       "18513  1.3   Not specified             CC7B  White            115.0      M   \n",
       "18514  1.3   Not specified             CC7B  White            115.0      M   \n",
       "18515  1.2  Roman Catholic             CC7B  White            100.0      M   \n",
       "18516  1.2  Roman Catholic             CC7B  White            100.0      M   \n",
       "\n",
       "       Hematocrit..serum.  Calcium.non.ionized  Phosphorous   BUN  \\\n",
       "0                    36.9                  7.8          3.4  14.0   \n",
       "1                    36.9                  7.8          3.4  14.0   \n",
       "2                    30.9                  7.7          1.4  19.0   \n",
       "3                    30.9                  7.7          1.4  19.0   \n",
       "4                    30.9                  7.7          1.4  19.0   \n",
       "...                   ...                  ...          ...   ...   \n",
       "18512                28.7                 10.7          2.4  26.0   \n",
       "18513                21.0                  7.9          2.6  24.0   \n",
       "18514                21.0                  7.9          2.6  24.0   \n",
       "18515                23.0                  8.5          2.3  19.0   \n",
       "18516                23.0                  8.5          2.3  19.0   \n",
       "\n",
       "       O2.saturation.pulseoxymetry  Admission.Weight..Kg.  Heart.Rate  \\\n",
       "0                            100.0                   66.8       115.0   \n",
       "1                            100.0                   66.8       115.0   \n",
       "2                             83.0                  106.2       100.0   \n",
       "3                             83.0                  106.2       100.0   \n",
       "4                             83.0                  106.2       100.0   \n",
       "...                            ...                    ...         ...   \n",
       "18512                        100.0                  106.6       100.0   \n",
       "18513                        100.0                   80.7       100.0   \n",
       "18514                        100.0                   80.7       100.0   \n",
       "18515                        100.0                   64.6       100.0   \n",
       "18516                        100.0                   64.6       100.0   \n",
       "\n",
       "       HCO3..serum.  Anion.gap  Potassium..serum.  Chloride..serum.  \\\n",
       "0              25.0       12.0                3.4             106.0   \n",
       "1              25.0       12.0                3.4             106.0   \n",
       "2              24.0       10.0                3.2             102.0   \n",
       "3              24.0       10.0                3.2             102.0   \n",
       "4              24.0       10.0                3.2             102.0   \n",
       "...             ...        ...                ...               ...   \n",
       "18512          18.0       12.0                3.3             102.0   \n",
       "18513          20.0       11.0                3.6             101.0   \n",
       "18514          20.0       11.0                3.6             101.0   \n",
       "18515          25.0       10.0                3.0             100.0   \n",
       "18516          25.0       10.0                3.0             100.0   \n",
       "\n",
       "       Sodium..serum.  Creatinine  Magnesium  Respiratory.Rate  \\\n",
       "0               144.0         0.6        1.8              11.0   \n",
       "1               144.0         0.6        1.8              11.0   \n",
       "2               139.0         0.8        1.9              10.0   \n",
       "3               139.0         0.8        1.9              10.0   \n",
       "4               139.0         0.8        1.9              10.0   \n",
       "...               ...         ...        ...               ...   \n",
       "18512           120.0         0.8        1.7              10.0   \n",
       "18513           123.0         0.8        1.6              12.0   \n",
       "18514           123.0         0.8        1.6              12.0   \n",
       "18515           129.0         0.9        1.8               0.0   \n",
       "18516           129.0         0.9        1.8               0.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            TEXT  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [**2153-9-4**] 9:16 AM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 58785**]\\n Reason: assess lung expansion\\n Admitting Diagnosis: CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS GRAFT/SDA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n   71 year old man s/p CABG now w/chest tubes removed\\n\\n REASON FOR THIS EXAMINATION:\\n  assess lung expansion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATIONS:  Chest tubes removed.\\n\\n PORTABLE AP CHEST AT 1004:  Comparisons made to [**2153-9-3**].  The patient\\n has been extubated.  Swan-Ganz catheter has been removed and the right IJ\\n sheath remains in place.  Both left chest tubes have been removed.  There is\\n no pneumothorax.  There is bilateral lower lobe atelectasis.  There is\\n improvement in pulmonary edema.\\n\\n\\n  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [**2157-10-21**] 3:31 PM\\n CT HEAD W/O CONTRAST                                            Clip # [**Clip Number (Radiology) 58866**]\\n Reason: 75 year old man with L brain mass s/p resection, evaluate fo\\n Admitting Diagnosis: BRAIN MASS\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours.\\n REASON FOR THIS EXAMINATION:\\n  75 year old man with L brain mass s/p resection, evaluate for interval changes.\\n  Please do within 4 hours\\n No contraindications for IV contrast\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n EXAM:  CT of the head.\\n\\n CLINICAL INFORMATION:  Patient with brain mass, status post resection.\\n\\n TECHNIQUE:  Axial images of the head were obtained without contrast.\\n Correlation was made with the MRI of [**2157-10-20**].\\n\\n FINDINGS:  The patient is status post resection of extra-axial mass seen on\\n the previous MRI in the left parietal parafalcine region.  Postoperative\\n changes with craniotomy are seen.  Pneumocephalus identified.  Expected\\n post-surgical change is seen.  No hemorrhage identified.\\n\\n IMPRESSION:  Expected post-surgical changes with pneumocephalus seen in the\\n left parietal region.\\n\\n\\n  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            4:30p-7a\\nneuro: pt remained sedated on fent/versed and paralyzed with cisatracurium gtts. cisatr. gtt titrated to 2 eyebrow twitches, fent/versed titrated for sedation to vitals. +PERRL.\\n\\ncv: remained st through the shift, see flowsheet for hourly vs and detailed assessments. received 500cc bolus, hr down to 100-110's from 110-120. off ntg/neo, keeping sbp<120. chest remains open with ioban dressing. palpable pulses to all extremities. ci>2. lytes repleated prn.\\n\\nresp: ls clear bilat. see flowsheet for abg/vent setings. not overbreathing vent, remains paralyzed. chest tubes to 20cm h2o seal suctions, draining sm amts serosanguinous. o2sats >98%.\\n\\ngi/gu: abd soft, absent bowel sounds. [**Hospital1 207**] sump draining light brown to low cont suction. indwelling cath draining clear yellow urine, sufficient amts >30cc/hr.\\n\\nendo: RISS\\n\\nplan: continue to monitor hemodynamics. scheduled for the 10:30 OR, family aware, continue to keep pt paralyzed and sedated until the OR. continue to keep sbp<120. do not turn until after chest closure.\\n  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [**2131-5-24**] 9:45 AM\\n PICC LINE PLACMENT SCH                                          Clip # [**Clip Number (Radiology) 17943**]\\n Reason: PICC for IV antibiotics\\n Admitting Diagnosis: CHEST PAIN/SHORTNESS OF BREATH\\n ********************************* CPT Codes ********************************\\n * [**Numeric Identifier 413**] PICC W/O [**Numeric Identifier 932**] FLUORO GUID PLCT/REPLCT/REMOVE   *\\n * [**Numeric Identifier 375**] US GUID FOR VAS. ACCESS                                                *\\n ****************************************************************************\\n ______________________________________________________________________________\\n [**Hospital 3**] MEDICAL CONDITION:\\n   69 year old man s/p sternal rewire\\n\\n REASON FOR THIS EXAMINATION:\\n  PICC for IV antibiotics\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATION:  69-year-old status post sternal rewiring requiring IV\\n antibiotics.\\n\\n RADIOLOGISTS:  The procedure was performed by Dr. [**Last Name (STitle) 5344**], with Dr. [**Last Name (STitle) 169**],\\n the attending physician [**Name Initial (PRE) **].\\n\\n PROCEDURE AND FINDINGS:  Patient was placed supine on the angiographic table.\\n Due to prior ultrasounds demonstrating extensive thrombus within the left\\n upper extremity, the right upper extremity was chosen for the PICC line.\\n Ultrasound demonstrated an appropriate right basilic vein which was punctured\\n with a 21-gauge micropuncture needle, through which a 0.018 guide wire was\\n advanced into the SVC.  A single lumen PICC trimmed to 35 cm and was advanced\\n under fluoroscopic guidance with its tip placed in the distal SVC.  Final\\n fluoroscopic image was taken to confirm tip placement.  Hard copy ultrasound\\n images were printed before and after venous puncture to confirm patency. There\\n are no immediate post-procedure complications.\\n\\n IMPRESSION:  Successful placement of 35 cm single lumen PICC via the right\\n basilic vein with its tip in the distal SVC; line ready for use.\\n\\n\\n  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Respiratory Care\\nPt intubated on ventilatory support. Able to tol gradual decrease in FiO2 over duration of shift with support of Nitric Oxide Ventilation. ABG reveals continued mixed respiratory and metabolic acidosis. BS clear. Plan is to continue and wean vent support as tol. AM RSBI not performed due to hemodynamic instability and ventilatory requirements of INO vent.\\n  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...  \n",
       "18512                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [**2201-3-3**] 1:58 PM\\n CHEST (PA & LAT)                                                Clip # [**Clip Number (Radiology) 6762**]\\n Reason: Please assess interval change of R pleural effusion\\n Admitting Diagnosis: HYPONATREMIA\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  54-year-old male with alcohol cirrhosis, MELD score 19, and decompensation with\\n  ascites, low-grade hepatic encephalopathy, and portal hypertension with grade\\n  [**12-14**] esophageal varices, presents with hypotension, stable observation in MICU\\n  now called out to floor and with chronic kidney disease.\\n REASON FOR THIS EXAMINATION:\\n  Please assess interval change of R pleural effusion\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n HISTORY:  54-year-old male, with alcohol cirrhosis, MELD score 19.  Assess for\\n intrathoracic process.\\n\\n COMPARISON:  Multiple prior studies with the latest on [**2201-2-23**].\\n\\n PA AND LATERAL CHEST RADIOGRAPH:  The lung volumes are slightly low.\\n Bibasilar atelectasis is mild with small bilateral pleural effusions.  There\\n is no pneumothorax or definite focal airspace consolidation.  The\\n cardiomediastinal silhouette, hilar contour and pulmonary vasculature are\\n normal.  The underlying osseous structures are grossly unremarkable.\\n\\n IMPRESSION:  Mild bibasilar atelectasis with small pleural effusions.\\n\\n  \n",
       "18513                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      CVICU\\n   HPI: [**11-3**] POD 7\\n   80M s/p MVR(33mm SJ tissue valve)/CABGx4(LIMA-.LAD, SVG->OM, Diag, PDA)\\n   [**10-27**]\\n   EF: 25% Wt.: 82.6 kg Cr.: 1.3\\n   PMHx: CHF, CAD-s/p MI [**2190**], HTN, ^lipids, PVD, NIDDM, osteoporosis,\\n   GERD, NIDDM, anemia, spinal stenosis, LBP, asbestos exposure, glaucoma,\\n   renal calculi-s/p lithotripsy, colonic polyps, diverticulosis,\\n   hemorrhoids, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 1284**]\\n   [**Last Name (un) **]: Prilosec 20', Altace 10', Metformin 500 TID, Crestor 10', ASA 81',\\n   MVI, Actonel 35 mg weekly, Lasix, Timolol 0.5% to L eye\"\\n   Current medications:\\n   Amiodarone, Aspirin, Atorvastatin, Captopril, Colace, Lasix, Dilaudid\\n   prn, heparin, Toprol XL, protonix, timolol 0.5%\\n   24 Hour Events:\\n EKG - At [**2200-11-2**] 02:15 PM\\n EKG - At [**2200-11-2**] 03:45 PM\\n   awire trace=1st degree av block\\n   Post operative day:\\n   POD#7 - S/P CABG X4, MVR\\n   [**16**] hour events: started lasix gtt for diuresis, remained in ICU due to\\n   no available floor bed\\n   Allergies:\\n   Percocet (Oral) (Oxycodone Hcl/Acetaminophen)\\n   Unknown;\\n   Vicodin (Oral) (Hydrocodone Bit/Acetaminophen)\\n   Unknown;\\n   Last dose of Antibiotics:\\n   Infusions:\\n   Furosemide (Lasix) - 5 mg/hour\\n   Other ICU medications:\\n   Other medications:\\n   Flowsheet Data as of  [**2200-11-3**] 08:57 AM\\n   Vital signs\\n   Hemodynamic monitoring\\n   Fluid balance\\n                                                                  24 hours\\n                                                             Since [**04**] a.m.\\n   Tmax: 37.1\\nC (98.7\\n   T current: 36.2\\nC (97.1\\n   HR: 76 (71 - 88) bpm\\n   BP: 95/52(62) {81/42(51) - 115/75(80)} mmHg\\n   RR: 19 (17 - 28) insp/min\\n   SPO2: 98%\\n   Heart rhythm: 1st AV (First degree AV Block)\\n   Wgt (current): 91.6 kg (admission): 80.7 kg\\n   Height: 68 Inch\\n             Total In:\\n                                                                  1,017 mL\\n                                                                    315 mL\\n   PO:\\n                                                                    640 mL\\n                                                                    120 mL\\n   Tube feeding:\\n   IV Fluid:\\n                                                                    377 mL\\n                                                                    195 mL\\n   Blood products:\\n   Total out:\\n                                                                  1,517 mL\\n                                                                    760 mL\\n   Urine:\\n                                                                  1,517 mL\\n                                                                    760 mL\\n   NG:\\n   Stool:\\n   Drains:\\n   Balance:\\n                                                                   -500 mL\\n                                                                   -445 mL\\n   Respiratory support\\n   O2 Delivery Device: None\\n   SPO2: 98%\\n   ABG: ///24/\\n   Physical Examination\\n   General Appearance: No acute distress\\n   HEENT: PERRL\\n   Cardiovascular: (Rhythm: Regular)\\n   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: CTA\\n   bilateral : , Diminished: left base), (Sternum: Stable )\\n   Abdominal: Soft, Non-distended, Non-tender, Bowel sounds present, bowel\\n   movement [**11-2**]\\n   Left Extremities: (Edema: 2+), (Temperature: Warm), (Pulse - Dorsalis\\n   pedis: Diminished), (Pulse - Posterior tibial: Diminished)\\n   Right Extremities: (Edema: 2+), (Temperature: Warm), (Pulse - Dorsalis\\n   pedis: Diminished), (Pulse - Posterior tibial: Diminished)\\n   Skin: (Incision: Clean / Dry / Intact)\\n   Neurologic: (Awake / Alert / Oriented: x 3), Follows simple commands,\\n   Moves all extremities\\n   Labs / Radiology\\n   185 K/uL\\n   10.7 g/dL\\n   130 mg/dL\\n   1.0 mg/dL\\n   24 mEq/L\\n   4.1 mEq/L\\n   26 mg/dL\\n   92 mEq/L\\n   128 mEq/L\\n   30.7 %\\n   9.1 K/uL\\n        [image002.jpg]\\n                             [**2200-10-30**]  08:35 PM\\n                             [**2200-10-31**]  02:29 AM\\n                             [**2200-10-31**]  02:59 AM\\n                             [**2200-10-31**]  11:49 AM\\n                             [**2200-11-1**]  04:24 AM\\n                             [**2200-11-1**]  03:37 PM\\n                             [**2200-11-2**]  02:37 AM\\n                             [**2200-11-3**]  02:37 AM\\n                             [**2200-11-3**]  04:00 AM\\n                             [**2200-11-3**]  07:57 AM\\n   WBC\\n   10.2\\n   9.5\\n   12.1\\n   9.1\\n   Hct\\n   28.1\\n   41\\n   31.3\\n   33.2\\n   30.6\\n   30.7\\n   Plt\\n   129\\n   124\\n   153\\n   185\\n   Creatinine\\n   0.9\\n   1.0\\n   0.9\\n   1.0\\n   TCO2\\n   21\\n   Glucose\\n   146\\n   193\\n   115\\n   105\\n   59\\n   [**Telephone/Fax (3) 1515**]\\n   Other labs: PT / PTT / INR:15.1/33.8/1.3, Fibrinogen:622 mg/dL, Lactic\\n   Acid:1.5 mmol/L, Ca:8.2 mg/dL, Mg:2.2 mg/dL, PO4:3.7 mg/dL\\n   Imaging: CXR [**11-1**] left effusion\\n   Microbiology: urine culture pending\\n   Assessment and Plan\\n   Acute systolic heart failure\\n   Assessment and Plan:\\n   Neurologic: Neuro checks Q: 2 hr, Pain controlled, dilaudid prn\\n   Cardiovascular: Aspirin, Beta-blocker, Statins, Discontinue epicardial\\n   wires, captopril for acute systolic heart failure\\n   Pulmonary: IS, cough and deep breath\\n   Gastrointestinal / Abdomen:  tolerating diet\\n   Nutrition: Diabetic diet no sodium restriction, 1000 ml fluid\\n   restriction due to hyponatremia\\n   Renal: Foley, Adequate UO, continue lasix gtt for goal [**Telephone/Fax (1) 264**] ml\\n   negative in 24 hours\\n   Hematology:  stable\\n   Endocrine: RISS, Lantus (R)\\n   Infectious Disease: Check cultures, follow up on urine\\n   Lines / Tubes / Drains: Foley, Pacing wires, maintain foley to monitor\\n   urine output\\n   Wounds: Dry dressings\\n   Consults: P.T.\\n   ICU Care\\n   Glycemic Control:  Regular insulin sliding scale, Lantus (R) protocol\\n   Lines:\\n   Cordis/Introducer - [**2200-10-27**] 04:15 PM\\n   20 Gauge - [**2200-11-3**] 06:46 AM\\n   Prophylaxis:\\n   DVT: Boots, SQ UF Heparin\\n   Stress ulcer: PPI\\n   VAP bundle:\\n   Comments:\\n   Communication: Patient discussed on interdisciplinary rounds , ICU\\n   Code status: Full code\\n   Disposition: Transfer to floor\\n   ------ Protected Section ------\\n   Agree with above.   Heart failure consult with [**First Name8 (NamePattern2) 509**] [**Last Name (NamePattern1) **].\\n   ------ Protected Section Addendum Entered By:[**Name (NI) 768**] [**Last Name (NamePattern1) **], MD\\n   on:[**2200-11-3**] 14:40 ------\\n  \n",
       "18514  CVICU\\n   HPI:\\n   HD5\\n   [**10-28**] POD 1\\n   80M s/p MVR(33mm SJ tissue valve)/CABGx4(LIMA-.LAD, SVG->OM, Diag, PDA)\\n   [**10-27**]\\n   EF: 25% Wt.: 82.6 kg Cr.: 1.3\\n   PMHx: CHF, CAD-s/p MI [**2190**], HTN, ^lipids, PVD, NIDDM, osteoporosis,\\n   GERD, NIDDM, anemia, spinal stenosis, LBP, asbestos exposure, glaucoma,\\n   renal calculi-s/p lithotripsy, colonic polyps, diverticulosis,\\n   hemorrhoids, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 1284**]\\n   [**Last Name (un) **]: Prilosec 20', Altace 10', Metformin 500 TID, Crestor 10', ASA 81',\\n   MVI, Actonel 35 mg weekly, Lasix, Timolol 0.5% to L eye\"\\n   Current medications:\\n     Aspirin EC . Aspirin . Atorvastatin . . Docusate Sodium . Docusate\\n   Sodium (Liquid) . Epinephrine HCl . Insulin . Influenza Virus Vaccine .\\n   . Meperidine .\\n   . Milrinone . Morphine Sulfate . Neostigmine . Nitroglycerin,\\n   Oxycodone-Acetaminophen . Pantoprazole . Phenylephrine . Potassium\\n   Chloride . Propofol\\n   . Sucralfate . Vancomycin\\n   24 Hour Events:\\n INTUBATION - At [**2200-10-27**] 04:15 PM\\n OR RECEIVED - At [**2200-10-27**] 04:15 PM\\n CCO PAC - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n ARTERIAL LINE - START [**2200-10-27**] 04:15 PM\\n CORDIS/INTRODUCER - START [**2200-10-27**] 04:15 PM\\n INVASIVE VENTILATION - START [**2200-10-27**] 04:15 PM\\n EKG - At [**2200-10-27**] 05:00 PM\\n   Post operative day:\\n   POD#1 - S/P CABG X4, MVR\\n   Requiring multiple pressors after surgery. Improved from mmediate\\n   postop period.\\n   maintain support as necessary,wean vent as tolerated if stable\\n   Allergies:\\n   Percocet (Oral) (Oxycodone Hcl/Acetaminophen)\\n   Unknown;\\n   Vicodin (Oral) (Hydrocodone Bit/Acetaminophen)\\n   Unknown;\\n   Last dose of Antibiotics:\\n   Vancomycin - [**2200-10-28**] 08:00 AM\\n   Infusions:\\n   Epinephrine - 0.02 mcg/Kg/min\\n   Milrinone - 0.375 mcg/Kg/min\\n   Phenylephrine - 0.8 mcg/Kg/min\\n   Propofol - 25 mcg/Kg/min\\n   Other ICU medications:\\n   Carafate (Sucralfate) - [**2200-10-27**] 11:48 PM\\n   Morphine Sulfate - [**2200-10-28**] 08:00 AM\\n   Other medications:\\n   Flowsheet Data as of  [**2200-10-28**] 09:26 AM\\n   Vital signs\\n   Hemodynamic monitoring\\n   Fluid balance\\n                                                                  24 hours\\n                                                             Since [**04**] a.m.\\n   HR: 96 (82 - 96) bpm\\n   BP: 108/51(66) {83/46(56) - 115/61(76)} mmHg\\n   RR: 18 (12 - 32) insp/min\\n   SPO2: 96%\\n   Heart rhythm: A Paced\\n   Wgt (current): 92.6 kg (admission): 80.7 kg\\n   Height: 68 Inch\\n   CVP: 15 (14 - 21) mmHg\\n   PAP: (47 mmHg) / (23 mmHg)\\n   CO/CI (Fick): (7.3 L/min) / (3.8 L/min/m2)\\n   CO/CI (CCO): (4.4 L/min) / (2 L/min/m2)\\n   SvO2: 66%\\n   Mixed Venous O2% sat: 52 - 72\\n   Total In:\\n                                                                 10,697 mL\\n                                                                  1,859 mL\\n   PO:\\n   Tube feeding:\\n   IV Fluid:\\n                                                                  9,672 mL\\n                                                                  1,468 mL\\n   Blood products:\\n                                                                    975 mL\\n                                                                    361 mL\\n   Total out:\\n                                                                  1,868 mL\\n                                                                    585 mL\\n   Urine:\\n                                                                    698 mL\\n                                                                    305 mL\\n   NG:\\n                                                                     50 mL\\n   Stool:\\n   Drains:\\n   Balance:\\n                                                                  8,829 mL\\n                                                                  1,274 mL\\n   Respiratory support\\n   O2 Delivery Device: Endotracheal tube\\n   Ventilator mode: CPAP/PSV\\n   Vt (Set): 550 (550 - 550) mL\\n   Vt (Spontaneous): 560 (362 - 610) mL\\n   PS : 16 cmH2O\\n   RR (Set): 14\\n   RR (Spontaneous): 10\\n   PEEP: 5 cmH2O\\n   FiO2: 50%\\n   RSBI: 90\\n   PIP: 18 cmH2O\\n   Plateau: 17 cmH2O\\n   Compliance: 45.8 cmH2O/mL\\n   SPO2: 96%\\n   ABG: 7.44/26/109/20/-4\\n   Ve: 14 L/min\\n   PaO2 / FiO2: 218\\n   Physical Examination\\n   General Appearance: No acute distress\\n   HEENT: PERRL\\n   Cardiovascular: (Rhythm: Regular)\\n   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: CTA\\n   bilateral : ), (Sternum: Stable )\\n   Abdominal: Soft, Non-distended, Non-tender, Bowel sounds present\\n   Left Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Right Extremities: (Edema: Trace), (Temperature: Warm), (Pulse -\\n   Dorsalis pedis: Present), (Pulse - Posterior tibial: Present)\\n   Skin: (Incision: Clean / Dry / Intact)\\n   Neurologic: (Awake / Alert / Oriented: x 1), Follows simple commands,\\n   (Responds to: Verbal stimuli), Moves all extremities\\n   Labs / Radiology\\n   187 K/uL\\n   10.3 g/dL\\n   128 mg/dL\\n   0.8 mg/dL\\n   20 mEq/L\\n   4.6 mEq/L\\n   26 mg/dL\\n   105 mEq/L\\n   129 mEq/L\\n   35\\n   10.6 K/uL\\n        [image002.jpg]\\n                             [**2200-10-28**]  01:55 AM\\n                             [**2200-10-28**]  02:00 AM\\n                             [**2200-10-28**]  03:00 AM\\n                             [**2200-10-28**]  04:00 AM\\n                             [**2200-10-28**]  05:00 AM\\n                             [**2200-10-28**]  06:00 AM\\n                             [**2200-10-28**]  07:00 AM\\n                             [**2200-10-28**]  08:00 AM\\n                             [**2200-10-28**]  09:03 AM\\n                             [**2200-10-28**]  09:06 AM\\n   Hct\\n   35\\n   TCO2\\n   21\\n   18\\n   Glucose\\n   126\\n   104\\n   103\\n   92\\n   72\\n   78\\n   99\\n   128\\n   Other labs: PT / PTT / INR:16.9/50.6/1.5, Fibrinogen:324 mg/dL, Lactic\\n   Acid:1.2 mmol/L\\n   Imaging: CXR- clear.\\n   Microbiology: Blodd cx x2- pending ([**10-26**])\\n   Assessment and Plan\\n   Assessment and Plan: Milrinone/epi/neo, off propafol. CV stable on\\n   support.\\n   Wean pressors as tolerated if CV stable\\n   gentle diuresis\\n   Neurologic: Neuro checks Q: 1 hr\\n   Cardiovascular: Aspirin, Statins\\n   Pulmonary: Spontaneous breathing trial\\n   Gastrointestinal / Abdomen:\\n   Nutrition: NPO\\n   Renal: Foley, Adequate UO\\n   Endocrine: RISS\\n   Lines / Tubes / Drains: Foley, OGT, ETT, Chest tube - pleural , Chest\\n   tube - mediastinal, Pacing wires\\n   Wounds: Dry dressings\\n   Imaging: CXR today\\n   Fluids: KVO\\n   Consults: P.T.\\n   ICU Care\\n   Glycemic Control:  Regular insulin sliding scale\\n   CCO PAC - [**2200-10-27**] 04:15 PM\\n   Arterial Line - [**2200-10-27**] 04:15 PM\\n   Cordis/Introducer - [**2200-10-27**] 04:15 PM\\n   16 Gauge - [**2200-10-27**] 04:15 PM\\n   Prophylaxis:\\n   DVT: Boots\\n   Stress ulcer: PPI\\n   VAP bundle: HOB elevation, Mouth care, Daily wake up, RSBI\\n   Communication: Patient discussed on interdisciplinary rounds , ICU\\n   Code status: Full code\\n   Disposition: ICU\\n  \n",
       "18515                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [**2156-11-30**] 4:36 PM\\n CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 85322**]\\n Reason: r/o ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p TVR and ct removal\\n REASON FOR THIS EXAMINATION:\\n  r/o ptx\\n ______________________________________________________________________________\\n PROVISIONAL FINDINGS IMPRESSION (PFI): TXPb TUE [**2156-11-30**] 7:50 PM\\n  1.  Small right apical pneumothorax without evidence of tension\\n  2.  Small left pleural effusion and atelectasis.\\n  3.  Interval removal of endotracheal and orogastric tubes.\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n INDICATION:  Evaluate for pneumothorax status post chest tube removal in\\n patient recently undergone TVR.\\n\\n COMPARISONS:  Chest radiograph from [**2156-11-29**].\\n\\n PORTABLE UPRIGHT RADIOGRAPH OF THE CHEST:  There is a small right apical\\n pneumothorax with no evidence of tension.  Compared to the prior radiograph,\\n the endotracheal and orogastric tubes have been removed.  The lung volumes are\\n low.  There is left basilar volume loss due to a small pleural effusion and\\n probable associated atelectasis which may have been present on the prior\\n study, but is now layering due to upright patient position.  The sternal\\n cerclage wires are intact.  The Swan-Ganz catheter is unchanged.\\n Post-surgical cardiac and mediastinal widening is unchanged.\\n\\n IMPRESSION:\\n 1.  Small right apical pneumothorax without evidence of tension\\n 2.  Small left pleural effusion and atelectasis.\\n 3.  Interval removal of endotracheal and orogastric tubes.\\n\\n\\n  \n",
       "18516                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [**2156-11-30**] 10:02 PM\\n CHEST (PORTABLE AP); -77 BY DIFFERENT PHYSICIAN                 [**Name Initial (PRE) 7**] # [**Clip Number (Radiology) 86199**]\\n Reason: assess left apical ptx\\n Admitting Diagnosis: TVR\\n ______________________________________________________________________________\\n [**Hospital 2**] MEDICAL CONDITION:\\n  65 year old man s/p chest tube removal\\n REASON FOR THIS EXAMINATION:\\n  assess left apical ptx\\n ______________________________________________________________________________\\n                                 FINAL REPORT\\n AP CHEST, 10:08 P.M. ON [**11-30**]\\n\\n HISTORY:  Chest tube removed.\\n\\n IMPRESSION:  AP chest compared to [**11-15**] through 22:\\n\\n No appreciable residual pneumothorax.  Small bilateral pleural effusions\\n persist.  Heart size is normal.  Infrahilar atelectasis is mild and unchanged.\\n\\n Swan-Ganz catheter traverses the right jugular introducer ending in the right\\n pulmonary artery.  Heart size top normal unchanged.\\n\\n  \n",
       "\n",
       "[18517 rows x 38 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "GAu_a8y9Gkv8",
   "metadata": {
    "id": "GAu_a8y9Gkv8"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['SUBJECT_ID', 'length_of_stay_sum', 'length_of_stay_avg',\\n       'length_of_stay_min', 'length_of_stay_max', 'length_of_stay_rnd',\\n       'Platelet.Count', 'Prothrombin.time', 'WBC', 'Hemoglobin', 'PTT', 'INR',\\n       'Glucose..serum.', 'Hematocrit..serum.', 'Calcium.non.ionized',\\n       'Phosphorous', 'BUN', 'O2.saturation.pulseoxymetry',\\n       'Admission.Weight..Kg.', 'Heart.Rate', 'HCO3..serum.', 'Anion.gap',\\n       'Potassium..serum.', 'Chloride..serum.', 'Sodium..serum.', 'Creatinine',\\n       'Magnesium', 'Respiratory.Rate'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m _key_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpain.assessment.method\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpain.type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpain.cause\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeep.set\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# -> should include one for each cat and num, otherwise it will show an error saying it's empty\u001b[39;00m\n\u001b[1;32m     21\u001b[0m _sensitive_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposttib..pulses..right.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpupil.response.right\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpupil.size.right\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplateau.pressure\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m rn, rc, an, ac, t ,rn_ot, rc_ot, an_ot, ac_ot, t_ot\u001b[38;5;241m=\u001b[39m \u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_real_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key_fields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_sensitive_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_n = \u001b[39m\u001b[38;5;124m'\u001b[39m,rn)\n",
      "Cell \u001b[0;32mIn[111], line 31\u001b[0m, in \u001b[0;36mcreate_table\u001b[0;34m(real_data, synthetic_data, numerical_columns, key_fields, sensitive_fields, target_block_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m data_dict_c \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m: real_c\n\u001b[1;32m     28\u001b[0m }\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, syn_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(synthetic_data):\n\u001b[0;32m---> 31\u001b[0m     syn_n, syn_c \u001b[38;5;241m=\u001b[39m \u001b[43msplit_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msyn_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     data_dict_n[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m syn_n\n\u001b[1;32m     33\u001b[0m     data_dict_c[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m syn_c\n",
      "Cell \u001b[0;32mIn[116], line 44\u001b[0m, in \u001b[0;36msplit_table\u001b[0;34m(data_table, numerical_col)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_table\u001b[39m(data_table: pd\u001b[38;5;241m.\u001b[39mDataFrame, numerical_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m): \u001b[38;5;66;03m# for spliting the num and cat\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m numerical_col:\n\u001b[0;32m---> 44\u001b[0m         numerical_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_col\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m         categorical_data \u001b[38;5;241m=\u001b[39m data_table\u001b[38;5;241m.\u001b[39mdrop(numerical_col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m numerical_data, categorical_data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3901\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3902\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3904\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6175\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6174\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['SUBJECT_ID', 'length_of_stay_sum', 'length_of_stay_avg',\\n       'length_of_stay_min', 'length_of_stay_max', 'length_of_stay_rnd',\\n       'Platelet.Count', 'Prothrombin.time', 'WBC', 'Hemoglobin', 'PTT', 'INR',\\n       'Glucose..serum.', 'Hematocrit..serum.', 'Calcium.non.ionized',\\n       'Phosphorous', 'BUN', 'O2.saturation.pulseoxymetry',\\n       'Admission.Weight..Kg.', 'Heart.Rate', 'HCO3..serum.', 'Anion.gap',\\n       'Potassium..serum.', 'Chloride..serum.', 'Sodium..serum.', 'Creatinine',\\n       'Magnesium', 'Respiratory.Rate'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    numerical_column = col_list\n",
    "    _real_data = pd.read_csv('data/mimi3.csv')\n",
    "    synthetic_data_small = df_small\n",
    "    synthetic_data_medium = df_medium\n",
    "    synthetic_data_large = df_large\n",
    "\n",
    "    data_dict = {\n",
    "        'real': _real_data,\n",
    "        'small': synthetic_data_small,\n",
    "        'medium': synthetic_data_medium,\n",
    "        'large': synthetic_data_large,\n",
    "    }\n",
    "\n",
    "    data_dict = get_part_of_data(data_dict, len(data_dict['real']), 0) # -> second hyper para is target_block_size and it decides the size of the row.\n",
    "\n",
    "    _real_data = data_dict['real']\n",
    "    data_dict.pop('real')\n",
    "    data = data_dict.values()\n",
    "    _key_fields = ['pain.assessment.method','pain.type','pain.cause','peep.set'] # -> should include one for each cat and num, otherwise it will show an error saying it's empty\n",
    "    _sensitive_fields = ['posttib..pulses..right.', 'pupil.response.right', 'pupil.size.right', 'plateau.pressure']\n",
    "    rn, rc, an, ac, t ,rn_ot, rc_ot, an_ot, ac_ot, t_ot= create_table(_real_data, data, numerical_column, _key_fields, _sensitive_fields)\n",
    "\n",
    "    print('\\n')\n",
    "    print('result_n = ',rn)\n",
    "    print('\\n')\n",
    "    print('result_c = ',rc)\n",
    "    print('\\n')\n",
    "    print('avg_n = ',an)\n",
    "    print('\\n')\n",
    "    print('avg_c = ',ac)\n",
    "    print('\\n')\n",
    "    print('time = ',t)\n",
    "    print('\\n')\n",
    "\n",
    "    print('result of other metrics')\n",
    "    print('\\n')\n",
    "    print('result_n = ',rn_ot)\n",
    "    print('\\n')\n",
    "    print('result_c = ',rc_ot)\n",
    "    print('\\n')\n",
    "    print('avg_n = ',an_ot)\n",
    "    print('\\n')\n",
    "    print('avg_c = ',ac_ot)\n",
    "    print('\\n')\n",
    "    print('time = ',t_ot)\n",
    "    # real_data_n, real_data_c = split_table(_real_data, numerical_col=numerical_column)\n",
    "    # synthetic_data_small_n, synthetic_data_small_c = split_table(synthetic_data_small, numerical_col=numerical_column)\n",
    "    # synthetic_data_medium_n, synthetic_data_medium_c = split_table(synthetic_data_medium,\n",
    "    #                                                                numerical_col=numerical_column)\n",
    "    # synthetic_data_large_n, synthetic_data_large_c = split_table(synthetic_data_large, numerical_col=numerical_column)\n",
    "\n",
    "    # drop the error column\n",
    "    # synthetic_data_small_n = synthetic_data_small_n.drop(columns=['bill_prov_zip_cd', 'rndrng_prov_zip_cd'])\n",
    "    # synthetic_data_medium_n = synthetic_data_medium_n.drop(columns=['bill_prov_zip_cd', 'rndrng_prov_zip_cd'])\n",
    "    # synthetic_data_large_n = synthetic_data_large_n.drop(columns=['rndrng_prov_zip_cd'])\n",
    "    # real_data_c = real_data_c.drop(columns=['bill_prov_zip_cd', 'rndrng_prov_zip_cd'])\n",
    "    # synthetic_data_large_c = synthetic_data_large_c.drop(columns=['bill_prov_zip_cd'])\n",
    "\n",
    "    # group the tables\n",
    "    # synthetic_data_c = {\n",
    "    #     'real': real_data_c,\n",
    "    #     'small': synthetic_data_small_c,\n",
    "    #     'medium': synthetic_data_medium_c,\n",
    "    #     'large': synthetic_data_large_c\n",
    "    # }\n",
    "    # synthetic_data_n = {\n",
    "    #     'real': real_data_n,\n",
    "    #     'small': synthetic_data_small_n,\n",
    "    #     'medium': synthetic_data_medium_n,\n",
    "    #     'large': synthetic_data_large_n\n",
    "    # }\n",
    "    # synthetic_data_n = remove_nan_in_numerical(synthetic_data_n)\n",
    "    #\n",
    "    # mc_list_c = privacy_categorical_metrics_dict.keys()\n",
    "    # mc_list_n = privacy_numerical_metrics_dict.keys()\n",
    "    # meta_data_list_n = get_metadata(real_data_n)\n",
    "    # meta_data_list_c = get_metadata(real_data_c)\n",
    "    # total_length_n = len(real_data_n)\n",
    "    # total_length_c = len(real_data_c)\n",
    "    # num = 100\n",
    "    # partial_data_n = get_part_of_data(synthetic_data_n, num, 0)\n",
    "    # partial_data_c = get_part_of_data(synthetic_data_c, num, 0)\n",
    "    # start = time.time()\n",
    "    #\n",
    "    # preal_data_n = partial_data_n['real']\n",
    "    # partial_data_n.pop('real')\n",
    "    # numerical_1 = _create_table(mc_list_n, preal_data_n,\n",
    "    #                             partial_data_n, meta_data_list_n[0], mode='n')\n",
    "    # preal_data_c = partial_data_c['real']\n",
    "    # partial_data_c.pop('real')\n",
    "    # categorical_1 = _create_table(mc_list_c, preal_data_c,\n",
    "    #                               partial_data_c, meta_data_list_c[0], mode='c')\n",
    "    #\n",
    "    # partial_data_n = get_part_of_data(synthetic_data_n, num, 200)\n",
    "    # partial_data_c = get_part_of_data(synthetic_data_c, num, 200)\n",
    "    #\n",
    "    # preal_data_n = partial_data_n['real']\n",
    "    # partial_data_n.pop('real')\n",
    "    # numerical_2 = _create_table(mc_list_n, preal_data_n,\n",
    "    #                             partial_data_n, meta_data_list_n[0], mode='n')\n",
    "    # preal_data_c = partial_data_c['real']\n",
    "    # partial_data_c.pop('real')\n",
    "    # categorical_2 = _create_table(mc_list_c, preal_data_c,\n",
    "    #                               partial_data_c, meta_data_list_c[0], mode='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ohedaYbqRd7",
   "metadata": {
    "id": "_ohedaYbqRd7"
   },
   "outputs": [],
   "source": [
    "%pip install python==3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SBs9h541piv1",
   "metadata": {
    "id": "SBs9h541piv1"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KtjRJMdbylQr",
   "metadata": {
    "id": "KtjRJMdbylQr"
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "        'real': _real_data,\n",
    "        'small': synthetic_data_small,\n",
    "        'medium': synthetic_data_medium,\n",
    "        'large': synthetic_data_large,\n",
    "    }\n",
    "data_dict = get_part_of_data(data_dict, len(data_dict['real']),0) # change 40 to other nums\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3_WjC85xzuC-",
   "metadata": {
    "id": "3_WjC85xzuC-"
   },
   "outputs": [],
   "source": [
    "#prac ver 1\n",
    "def create_table(real_data, synthetic_data, numerical_columns, key_fields, sensitive_fields,  metric_list_n, metric_list_c, target_block_size=30): #originally the block size was 100\n",
    "    \"\"\"\n",
    "    The function to create table\n",
    "    :param real_data: The original data\n",
    "    :param synthetic_data: The synthetic data generate by tools, should be a List of pandas.DataFrame\n",
    "    :param numerical_columns: A list of string, telling the function what columns are numerical columns\n",
    "    :param key_fields: The key field that we need to calculate privacy and utility\n",
    "    :param sensitive_fields: The sensitive field that we need to calculate privacy and utility. -> outcomes\n",
    "    :param target_block_size: How many rows in each block, the final result will be average of all blocks\n",
    "    :return: result_n(c)_avg: the numerical(categorical) result for each metrics,\n",
    "    numerical(categorical)_avg: the average of all metrics, total_score: the average of numerical and categorical\n",
    "    \"\"\"\n",
    "    #total_len = len(real_data)\n",
    "    #total_len = total_len // target_block_size * target_block_size # -> why should I divide it by target_block_size?\n",
    "\n",
    "    real_n, real_c = split_table(real_data, numerical_col=numerical_columns)\n",
    "\n",
    "    key_fields_n, key_fields_c, sensitive_fields_n, sensitive_fields_c = get_meta_data(real_n,\n",
    "                                                                                       real_c,\n",
    "                                                                                       key_fields,\n",
    "                                                                                       sensitive_fields)\n",
    "\n",
    "    data_dict_n = {\n",
    "        'real': real_n\n",
    "    }\n",
    "    data_dict_c = {\n",
    "        'real': real_c\n",
    "    }\n",
    "\n",
    "    for i, syn_data in enumerate(synthetic_data):\n",
    "        syn_n, syn_c = split_table(syn_data, numerical_columns)\n",
    "        data_dict_n[f\"level{i}\"] = syn_n\n",
    "        data_dict_c[f\"level{i}\"] = syn_c\n",
    "\n",
    "    data_dict_n = remove_nan_in_numerical(data_dict_n)\n",
    "\n",
    "    meta_data_n = {\n",
    "        'key_fields': key_fields_n,\n",
    "        'sensitive_fields': sensitive_fields_n,\n",
    "    }\n",
    "    meta_data_c = {\n",
    "        'key_fields': key_fields_c,\n",
    "        'sensitive_fields': sensitive_fields_c,\n",
    "    }\n",
    "    #metric_list_c = privacy_categorical_metrics_dict.keys()\n",
    "    #metric_list_n = privacy_numerical_metrics_dict.keys()\n",
    "\n",
    "    result_n = []\n",
    "    result_c = []\n",
    "\n",
    "    #for index in range(0, total_len, target_block_size): # it is like a batch\n",
    "    partial_n = get_part_of_data(data_dict_n, target_block_size,index = 0) # 앞에서 data_dict와 같은 역할\n",
    "    partial_c = get_part_of_data(data_dict_c, target_block_size,index = 0)\n",
    "    partial_real_n = partial_n['real']\n",
    "    partial_real_c = partial_c['real']\n",
    "    partial_n.pop('real')\n",
    "    partial_c.pop('real')\n",
    "\n",
    "\n",
    "    numerical = _create_table(metric_list_n, partial_real_n,\n",
    "                              partial_n, meta_data_n, mode='n')\n",
    "    print('here')#-> just for debugging\n",
    "    categorical = _create_table(metric_list_c, partial_real_c, partial_c, meta_data_c, mode='c')\n",
    "    print('here')#-> just for debugging\n",
    "    result_n.append(numerical)\n",
    "    result_c.append(categorical) # 왜 append 되는게 없을까?\n",
    "\n",
    "\n",
    "    result_n_avg = sum(result_n) / len(result_n)\n",
    "    result_c_avg = sum(result_c) / len(result_c)\n",
    "    numerical_avg = result_n_avg.mean()\n",
    "    numerical_avg['time'] *= len(synthetic_data)\n",
    "    categorical_avg = result_c_avg.mean()\n",
    "    categorical_avg['time'] *= len(synthetic_data)\n",
    "\n",
    "    total_score = (numerical_avg + categorical_avg) / 2\n",
    "\n",
    "    return result_n_avg, result_c_avg, numerical_avg, categorical_avg, total_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Er3cmoWvy9r8",
   "metadata": {
    "id": "Er3cmoWvy9r8"
   },
   "outputs": [],
   "source": [
    "#prac ver 1\n",
    "if __name__ == '__main__':\n",
    "    numerical_column = col_list\n",
    "    _real_data = pd.read_csv('gdrive/My Drive/Colab Notebooks/SOCR/dt_new_original.csv')\n",
    "    synthetic_data_small = pd.read_csv('gdrive/My Drive/Colab Notebooks/SOCR/dt_new_small.csv')\n",
    "    synthetic_data_medium = pd.read_csv('gdrive/My Drive/Colab Notebooks/SOCR/dt_new_medium.csv')\n",
    "    synthetic_data_large = pd.read_csv('gdrive/My Drive/Colab Notebooks/SOCR/dt_new_large.csv')\n",
    "\n",
    "    data_dict = {\n",
    "        'real': _real_data,\n",
    "        'small': synthetic_data_small,\n",
    "        'medium': synthetic_data_medium,\n",
    "        'large': synthetic_data_large,\n",
    "    }\n",
    "\n",
    "    data_dict = get_part_of_data(data_dict, len(data_dict['real']), 0) # -> second hyper para is target_block_size and it decides the size of the row.\n",
    "\n",
    "    _real_data = data_dict['real']\n",
    "    data_dict.pop('real')\n",
    "    data = data_dict.values()\n",
    "    _key_fields = ['pain.assessment.method','pain.type','pain.cause','peep.set'] # -> should include one for each cat and num, otherwise it will show an error saying it's empty\n",
    "    _sensitive_fields = ['posttib..pulses..right.', 'pupil.response.right', 'pupil.size.right','plateau.pressure']\n",
    "    rn, rc, an, ac, t = create_table(_real_data, data, numerical_column, _key_fields, _sensitive_fields, {'NumericalMLP','NumericalLR','NumericalSVR'}, {'CategoricalGeneralizedCAP','CategoricalCAP','CategoricalKNN'})\n",
    "    print('\\n')\n",
    "    print('result_n = ')\n",
    "    print(rn)\n",
    "    print('\\n')\n",
    "\n",
    "    print('result_c = ')\n",
    "    print(rc)\n",
    "    print('\\n')\n",
    "\n",
    "    print('avg_n = ')\n",
    "    print(an)\n",
    "    print('\\n')\n",
    "\n",
    "    print('avg_c = ')\n",
    "    print(ac)\n",
    "    print('\\n')\n",
    "\n",
    "    print('time = ')\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Is8sIdk-WMIZ",
   "metadata": {
    "id": "Is8sIdk-WMIZ"
   },
   "outputs": [],
   "source": [
    "# This have to be done for checking whether result is proper or not. WOn't be run till everything is done.\n",
    "from sdv.evaluation.single_table import run_diagnostic\n",
    "\n",
    "diagnostic_report = run_diagnostic(\n",
    "    real_data=real_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-dU1MOV_Zu3t",
   "metadata": {
    "id": "-dU1MOV_Zu3t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13087e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a65b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c3c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887f9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
